[
  {
    "objectID": "assignment/01-taller.html",
    "href": "assignment/01-taller.html",
    "title": "Taller 1. Niveles de medición y construcción de items",
    "section": "",
    "text": "Reforzar conocimientos sobre niveles de medición y practicar la construcción de ítems."
  },
  {
    "objectID": "assignment/01-taller.html#conceptos",
    "href": "assignment/01-taller.html#conceptos",
    "title": "Taller 1. Niveles de medición y construcción de items",
    "section": "Conceptos:",
    "text": "Conceptos:\n\nTiempo dedicado a viajar de la casa al trabajo.\nIdentidad de género.\nIntención de voto en el plebiscito de salida 2023.\nGusto por el deporte.\nTiempo dedicado a estar en redes sociales virtuales.\nComposición familiar.\nIdentidad de clase.\nPercepción de seguridad.\nPercepción sobre carga académica.\nTrabajo de cuidados.\nIngresos\nSatisfacción con el barrio\nNivel de acuerdo con la educación gratuita\nResidencia"
  },
  {
    "objectID": "assignment/01-taller.html#ejemplo-de-trabajo",
    "href": "assignment/01-taller.html#ejemplo-de-trabajo",
    "title": "Taller 1. Niveles de medición y construcción de items",
    "section": "Ejemplo de trabajo",
    "text": "Ejemplo de trabajo\n\n\n\n\n\n\n\n \n  \n    Conceptos \n    Preguntas \n    Alternativas \n    Nivel de medición \n    Potencialidades \n    Limitaciones \n    Opción escogida \n  \n \n\n  \n    Concepto 1 \n    Pregunta 1 \n    a) \n    Nivel 1 \n    1, 2, …, n \n    1, 2, …, n \n    Si \n  \n  \n   \n   \n    b) \n   \n   \n   \n   \n  \n  \n   \n    Pregunta 2 \n    [0, +∞) \n    Nivel 2 \n   \n   \n    No. \n  \n  \n   \n    Pregunta 3 \n    a) \n    Nivel 3 \n   \n   \n    No \n  \n  \n   \n   \n    b) \n   \n   \n   \n   \n  \n  \n   \n   \n    c) \n   \n   \n   \n   \n  \n  \n    Concepto 2 \n    Pregunta 1 \n    a) \n    Nivel 1 \n   \n   \n    No. \n  \n  \n   \n   \n    b) \n   \n   \n   \n   \n  \n  \n   \n    Pregunta 2 \n    [0, +∞) \n    Nivel 2 \n   \n   \n    Si \n  \n  \n   \n    Pregunta 3 \n    a) \n    Nivel 3 \n   \n   \n    No \n  \n  \n   \n   \n    b) \n   \n   \n   \n   \n  \n  \n   \n   \n    c) \n   \n   \n   \n   \n  \n  \n    Concepto 3 \n    Pregunta 1 \n    a) \n    Nivel 1 \n   \n   \n    No. \n  \n  \n   \n   \n    b) \n   \n   \n   \n   \n  \n  \n   \n    Pregunta 2 \n    [0, +∞) \n    Nivel 2 \n   \n   \n    No \n  \n  \n   \n    Pregunta 3 \n    a) \n    Nivel 3 \n   \n   \n    Si \n  \n  \n   \n   \n    b) \n   \n   \n   \n   \n  \n  \n   \n   \n    c)"
  },
  {
    "objectID": "assignment/02-taller.html",
    "href": "assignment/02-taller.html",
    "title": "Taller 2",
    "section": "",
    "text": "Reforzar los procedimientos de operacionalización y construcción de indicadores sociales."
  },
  {
    "objectID": "assignment/02-taller.html#indicadores",
    "href": "assignment/02-taller.html#indicadores",
    "title": "Taller 2",
    "section": "Indicadores:",
    "text": "Indicadores:\n\nTasa de ocupación informal: porcentaje de Ocupados Informales respecto al total de los Ocupados del periodo de referencia (INE, 2021). Ello involucra a todas las personas cuyo trabajo no cuenta con características como un contrato escrito, pago a través de liquidaciones de sueldo, entre otros.\nDistribución de población indígena por comuna: porcentaje de habitantes en cada comuna que se identifican como pertenecientes a un pueblo indígena.\nConcentración de jefas de hogar según composición familiar: porcentaje de mujeres que adoptan el rol de jefas de hogar en hogares de distinta composición familiar (unipersonal, nuclear sin hij_s, nuclear con hij_s y monomaternal) respecto del total de jefas de hogar.\nÍndice de hacinamiento: razón entre el número de personas y el número de habitaciones usadas como dormitorios en una vivienda.\nTasa de atención médica ante problema de salud: porcentaje de personas que, habiendo tenido un problema de salud, pudieron recibir atención médica."
  },
  {
    "objectID": "assignment/02-taller.html#ejemplo-de-trabajo",
    "href": "assignment/02-taller.html#ejemplo-de-trabajo",
    "title": "Taller 2",
    "section": "Ejemplo de trabajo",
    "text": "Ejemplo de trabajo\nIndicador: Tasa de Inflación\nDefinición: Variación porcentual de un Índice de Precios de Consumo (IPC) respecto del periodo anterior. El IPC es un indicador que mide la variación media de bienes y servicios durante un período de tiempo determinado en una economía en específico.\nVariables necesarias: Precios de los bienes y servicios incluidos en la estimación del IPC para el periodo por analizar y el periodo anterior.\nFormalización:\n\\[TI = \\frac{IPC1-IPC0}{IPC0} * 100\\]\ndonde:\nTI = Tasa de Inflación,\nIPC1 = IPC del periodo por analizar\nIPC0 = IPC del periodo anterior\nPosibles valores: (- ∞, +∞) medidos en porcentaje (%).\nInterpretación: un valor positivo indica un aumento medio relativo del conjunto de precios de los bienes y servicios incluidos en la estimación del IPC, mientras que un valor negativo indica una disminución media relativa del conjunto de precios de los bienes y servicios incluidos en la estimación del IPC. Por ejemplo, una tasa de inflación de un 3,4% indica que, en promedio, el conjunto de los precios de bienes y servicios incluidos en la estimación del IPC aumentó en un 3.4% respecto del periodo anterior. Así, si un producto X tenía un precio de $1.000 en el periodo anterior, su precio en el periodo analizado debiese aproximarse a 1.000*1.034 = $1.034.\nLimitaciones: La definición de bienes y servicios incluidos en la estimación del IPC puede estar sujeta a lo que el gobierno o l_s funcionari_s del Estado consideren indispensable en los gastos mensuales de un hogar, dejando fuera algunos que pudiesen tener igual relevancia.\nPotencialidades: Permite medir de forma precisa los requerimientos de un hogar promedio mensual en relación a sus gastos fundamentales, por lo que hace posible conocer el estado de una economía en lo que respecta a su consumo.\nEj. de PP: Transferencias directas a hogares de bajos ingresos, para facilitar la satisfacción de necesidades básicas. Subvención gubernamental del precio de los productos con mayor aumento de precios entre ambos periodos."
  },
  {
    "objectID": "assignment/03-taller.html",
    "href": "assignment/03-taller.html",
    "title": "Taller 3",
    "section": "",
    "text": "Practicar la creación de índices sintéticos, y reforzar contenidos asociados a la validez."
  },
  {
    "objectID": "assignment/03-taller.html#constructos",
    "href": "assignment/03-taller.html#constructos",
    "title": "Taller 3",
    "section": "Constructos:",
    "text": "Constructos:\n\nÍndice de Desarrollo Humano\nÍndice de Democracia.\nÍndice de victimización.\nÍndice de calidad del empleo.\nÍndice de consumo cultural.\nÍndice de actitudes hacia la violencia.\nÍndice de actitudes hacia el deporte."
  },
  {
    "objectID": "assignment/03-taller.html#ejemplo-de-trabajo",
    "href": "assignment/03-taller.html#ejemplo-de-trabajo",
    "title": "Taller 3",
    "section": "Ejemplo de trabajo",
    "text": "Ejemplo de trabajo\nConstructo: Índice de confianza en instituciones\nUnidad de análisis: Sujetos/individuos\nDimensiones: 2 dimensiones: a) instituciones políticas; b) instituciones civiles\nVariables necesarias:\n¿Cuánto confía usted en las siguientes instituciones?\n\nPresidente (Ordinal; nada-poco-bastante-mucho)\nPartidos políticos (Ordinal; nada-poco-bastante-mucho)\nONGs (Ordinal; nada-poco-bastante-mucho)\nPoder judicial (Ordinal; nada-poco-bastante-mucho)\nBomberos (Ordinal; nada-poco-bastante-mucho)\nIglesia (Ordinal; nada-poco-bastante-mucho)\n\nOperacionalización:\n\nFormalización:\n\\[CI = CIC + CIP = C. Bomberos + C. ONGs + C. Iglesia + C. Poder judicial + C. Partidos + C. Presidente\\] \\[CI = CIC + CIP =  [0, 3]      +     [0, 3]   +     [0,3]     +          [0, 3]          +      [0, 3]     +       [0,3] \\]\nPosibles valores: [0, 18].\nNivel de medición: Intervalar (discutible)\nInterpretación: Menores valores indican nada o poca confianza en instituciones, mientras que los valores más altos indican bastante o mucha confianza en instituciones. Por un lado, una persona puede tener un grado de confianza en instituciones de 1 (al haber respondido “nada” de confianza en la mayoría de las instituciones y “Algo” de confianza en una de ellas), lo que da cuenta de un bajo grado de confianza en las instituciones. Por otro lado, una persona puede tener un grado de confianza en instituciones de 15 (al haber respondido “Mucha” confianza en 5 instituciones y “Nada” confianza en las otras tres), lo que da cuenta de un alto nivel de confianza en las instituciones.\nValidez: Dado que no se incorporan todas las posibles instituciones, el índice de Confianza en Instituciones creado no lograría cubrir el constructo totalmente, quedando fuera, por ejemplo, las instituciones militares o de fuerzas de orden. No obstante, permite medir de buena forma la confianza en las instituciones civiles y políticas."
  },
  {
    "objectID": "assignment/04-taller.html",
    "href": "assignment/04-taller.html",
    "title": "Taller 4",
    "section": "",
    "text": "Practicar la construcción de escalas y reflexionar en torno a la fiabilidad y la validez del instrumento."
  },
  {
    "objectID": "assignment/04-taller.html#constructos",
    "href": "assignment/04-taller.html#constructos",
    "title": "Taller 4",
    "section": "Constructos:",
    "text": "Constructos:\n\nFrecuencia en que se habla de política con amig_s.\nGrado de importancia otorgado a conocer a las personas indicadas para salir adelante en la vida.\nGrado de acuerdo sobre recortar los gastos gubernamentales.\nProbabilidad de mantenerse en un trabajo no satisfactorio por el beneficio de la vida familiar.\nGrado de acuerdo con la frase “En general, Chile es mejor que el resto de los países latinoamericanos”.\nGrado de importancia asignado a tener un trabajo con altos ingresos.\nGrado de acuerdo frente a la reducción de la regulación económica por parte del gobierno.\nGrado de acuerdo frente a la frase “me siento orgullos_ de ser chilen_”.\nFrecuencia en que se trabaja por un tema que le afecta a sí mism_ o alguien de su comunidad.\nGrado de importancia otorgado a venir de una familia adinerada para salir adelante en la vida.\nProbabilidad de renunciar a una buena oportunidad laboral en beneficio de la vida familiar.\nGrado de acuerdo frente a la frase “prefiero haber nacido en Chile, en lugar de cualquier otro país latinoamericano”.\nGrado de importancia de tener un alto nivel educativo para salir adelante en la vida.\nGrado de importancia otorgado a tener un trabajo seguro.\nFrecuencia en que se intenta convencer a otr_s de lo que se piensa políticamente.\nGrado de acuerdo frente a la ampliación de tratados de libre comercio firmados por el gobierno.\nProbabilidad de trabajar menos horas para trabajar en labores domésticas.\nGrado de acuerdo con la frase “El gobierno debiese apoyar más a las empresas nacionales que a las compañías internacionales”.\nFrecuencia en que se trabaja para un partido político o candidat_.\nGrado de importancia de trabajar duro para salir adelante en la vida.\nGrado de importancia otorgado a tener buenas oportunidades para hacer carrera profesional."
  },
  {
    "objectID": "assignment/index.html",
    "href": "assignment/index.html",
    "title": "Talleres",
    "section": "",
    "text": "En esta sección se encuentran los talleres prácticos realizados en el segundo bloque de clases"
  },
  {
    "objectID": "content/index.html",
    "href": "content/index.html",
    "title": "Readings, lectures, and videos",
    "section": "",
    "text": "En construcción"
  },
  {
    "objectID": "example/cace.html",
    "href": "example/cace.html",
    "title": "Complier average treatment effects",
    "section": "",
    "text": "Throughout this course, we’ve talked about the difference between the average treatment effect (ATE), or the average effect of a program for an entire population, and conditional average treatment effect (CATE), or the average effect of a program for some segment of the population. There are all sorts of CATEs: you can find the CATE for men vs. women, for people who are treated with the program (the average treatment on the treated, or ATT or TOT), for people who are not treated with the program (the average treatment on the untreated, or ATU), and so on.\nOne important type of CATE is the effect of a program on just those who comply with the program. We can call this the complier average treatment effect, but the acronym would be the same as conditional average treatment effect, so we’ll call it the complier average causal effect or CACE.\nThinking about compliance is important. You might randomly assign people to receive treatment or a program, but people might not do what you tell them. Additionally, people might do the program if assigned to do it, but they would have done it anyway. We can split the population into four types of people:\n\nCompliers: People who follow whatever their assignment is (if assigned to treatment, they do the program; if assigned to control, they don’t)\nAlways takers: People who will receive or seek out the program regardless of assignment (if assigned to treatment, they do the program; if assigned to control, they still do the program)\nNever takers: People who will not receive or seek out the program regardless of assignment (if assigned to treatment, they don’t do the program; if assigned to control, they also don’t do it)\nDefiers: People who will do the opposite of whatever their assignment is (if assigned to treatment, they don’t do the program; if assigned to control, they do the program)\n\nTo simplify things, evaluators and econometricians assume that defiers don’t exist based on the idea of monotonicity, which means that we can assume that the effect of being assigned to treatment only increases the likelihood of participating in the program (and doesn’t make it more likely).\nThe tricky part about trying to find who the compliers are in a sample is that we can’t know what people would have done in the absence of treatment. If we see that someone in the experiment was assigned to be in the treatment group and they then participated in the program, they could be a complier (since they did what they were assigned to do), or they could be an always taker (they did what they were assigned to do, but they would have done it anyway). Due to the fundamental problem of causal inference, we cannot know what each person would have done in a parallel world.\nWe can use data from a hypothetical program to see how these three types of compliers distort our outcomes, and more importantly, how we can disentangle compliers from their always- and never-taker counterparts.\nIf you want to follow along with this example, you can download these two datasets:\n\n bed_nets_time_machine.csv\n bed_nets_observed.csv"
  },
  {
    "objectID": "example/cace.html#finding-compliers-with-a-mind-reading-time-machine",
    "href": "example/cace.html#finding-compliers-with-a-mind-reading-time-machine",
    "title": "Complier average treatment effects",
    "section": "Finding compliers with a mind-reading time machine",
    "text": "Finding compliers with a mind-reading time machine\nFirst let’s load the data and reorder some of the categories:\n\n\nCode\nlibrary(tidyverse)  # ggplot(), %>%, mutate(), and friends\nlibrary(broom)  # Convert models to data frames\nlibrary(estimatr)  # Run 2SLS models in one step with iv_robust()\n\nbed_nets <- read_csv(\"data/bed_nets_observed.csv\") %>%\n  # Make \"No bed net\" (control) come first\n  mutate(bed_net = fct_relevel(bed_net, \"No bed net\"))\n\nbed_nets_time_machine <- read_csv(\"data/bed_nets_time_machine.csv\") %>%\n  # Make \"No bed net\" come first and \"Complier\" come first\n  mutate(bed_net = fct_relevel(bed_net, \"No bed net\"),\n         status = fct_relevel(status, \"Complier\"))\n\n\nThis is what we would be able to see if we could read everyone’s minds. There are always takers who will use a bed net regardless of the program, and they’ll have higher health outcomes. However, those better outcomes are because of something endogenous—there’s something else that makes these people always pursue bed nets, and that’s likely related to health. We probably want to not consider them when looking for the program effect. There are never takers who won’t ever use a bed net, and they have worse health outcomes. Again, there’s endogeneity here—something is causing them to not use the bed nets, and it likely also causes their health level. We don’t want to look at them either.\nThe first group—the compliers—are the people we want to focus on. Here we see that the program had an effect when compared to a control group.\n\n\nCode\nset.seed(1234)  # Make the jittering the same every time\n\nggplot(bed_nets_time_machine, aes(y = health, x = treatment)) +\n  geom_point(aes(shape = bed_net, color = status),\n             position = position_jitter(height = NULL, width = 0.25)) +\n  facet_wrap(vars(status)) +\n  labs(color = \"Type of person\", shape = \"Compliance\",\n       x = NULL, y = \"Health status\") +\n  scale_color_viridis_d(option = \"plasma\", end = 0.85) +\n  theme_bw()"
  },
  {
    "objectID": "example/cace.html#finding-compliers-in-actual-data",
    "href": "example/cace.html#finding-compliers-in-actual-data",
    "title": "Complier average treatment effects",
    "section": "Finding compliers in actual data",
    "text": "Finding compliers in actual data\nThis is what we actually see in the data, though. You can tell who some of the always takers are (those who used bed nets after being assigned to the control group) and who some of the never takers are (those who did not use a bed net after being assigned to the treatment group), but compliers are mixed up with the always and never takers. We have to somehow disentangle them!\n\n\nCode\nset.seed(1234)\nggplot(bed_nets_time_machine, aes(y = health, x = bed_net)) +\n  geom_point(aes(shape = bed_net, color = status),\n             position = position_jitter(height = NULL, width = 0.25)) +\n  facet_wrap(vars(treatment)) +\n  labs(color = \"Type of person\", shape = \"Compliance\",\n       x = NULL, y = \"Health status\") +\n  scale_color_viridis_d(option = \"plasma\", end = 0.85) +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nWe can do this by assuming the proportion of compliers, never takers, and always takers are equally spread across treatment and control (which we can assume through the magic of randomization). If that’s the case, we can calculate the intent to treat (ITT) effect, which is the CATE of being assigned treatment (or the effect of being assigned treatment on health status, regardless of actual compliance).\nThe ITT is actually composed of three different causal effects: the complier average causal effect (CACE), the always taker average causal effect (ATACE), and the never taker average causal effect (NTACE). In the formula below, \\(\\pi\\) stands for the proportion of people in each group. Formally, the ITT can be defined like this:\n\\[\n\\begin{aligned}\n\\text{ITT}\\ =\\ & \\color{#0D0887}{\\pi_\\text{compliers} \\times (\\text{T} - \\text{C})_\\text{compliers}} + \\\\\n&\\color{#B7318A}{\\pi_\\text{always takers} \\times (\\text{T} - \\text{C})_\\text{always takers}} + \\\\\n&\\color{#FEBA2C}{\\pi_\\text{never takers} \\times (\\text{T} - \\text{C})_\\text{never takers}}\n\\end{aligned}\n\\]\nWe can simplify this to this acronymized version:\n\\[\n\\text{ITT}\\ =\\ \\color{#0D0887}{\\pi_\\text{C} \\text{CACE}} + \\color{#B7318A}{\\pi_\\text{A} \\text{ATACE}} + \\color{#FEBA2C}{\\pi_\\text{N} \\text{NTACE}}\n\\]\nThe number we care about the most here is the CACE, which is stuck in the middle of the equation. But we can rescue it with some fun logical and algebraic trickery!\nIf we assume that assignment to treatment doesn’t make someone more likely to be an always taker or a never taker, we can set the ATACE and NTACE to zero, leaving us with just three variables to worry about: ITT, \\(\\pi_\\text{c}\\), and CACE:\n\\[\n\\begin{aligned}\n\\text{ITT}\\ =\\ & \\color{#0D0887}{\\pi_\\text{C} \\text{CACE}} + \\color{#B7318A}{\\pi_\\text{A} \\text{ATACE}} + \\color{#FEBA2C}{\\pi_\\text{N} \\text{NTACE}} \\\\[6pt]\n=\\ & \\color{#0D0887}{\\pi_\\text{C} \\text{CACE}} + \\color{#B7318A}{\\pi_\\text{A} \\times 0} + \\color{#FEBA2C}{\\pi_\\text{N} \\times 0}\\\\[6pt]\n\\text{ITT}\\ =\\ & \\color{#0D0887}{\\pi_\\text{C} \\text{CACE}}\n\\end{aligned}\n\\]\nWe can use algebra to rearrange this formula so that we’re left with an equation that starts with CACE (since that’s the value we care about):\n\\[\n\\text{CACE} = \\frac{\\text{ITT}}{\\pi_\\text{C}}\n\\]\nIf we can find the ITT and the proportion of compliers, we can find the complier average causal effect (CACE). Fortunately, both those pieces—ITT and \\(\\pi_\\text{C}\\)—are findable in the data we have!"
  },
  {
    "objectID": "example/cace.html#finding-the-itt",
    "href": "example/cace.html#finding-the-itt",
    "title": "Complier average treatment effects",
    "section": "Finding the ITT",
    "text": "Finding the ITT\nThe ITT is easy to find with a simple OLS model:\n\n\nCode\nitt_model <- lm(health ~ treatment, data = bed_nets)\n\ntidy(itt_model)\n## # A tibble: 2 × 5\n##   term               estimate std.error statistic  p.value\n##   <chr>                 <dbl>     <dbl>     <dbl>    <dbl>\n## 1 (Intercept)           40.9      0.444     92.1  0       \n## 2 treatmentTreatment     5.99     0.630      9.51 5.20e-21\n\nITT <- tidy(itt_model) %>%\n  filter(term == \"treatmentTreatment\") %>%\n  pull(estimate)\n\n\nThe ITT here is ≈6—being assigned treatment increases average health status by 5.99 health points."
  },
  {
    "objectID": "example/cace.html#finding-the-proportion-of-compliers",
    "href": "example/cace.html#finding-the-proportion-of-compliers",
    "title": "Complier average treatment effects",
    "section": "Finding the proportion of compliers",
    "text": "Finding the proportion of compliers\nThe proportion of compliers is a little trickier, but doable with some algebraic trickery. Recall from the graph above that the people who were in the treatment group and who complied are a combination of always takers and compliers. This means we can say:\n\\[\n\\begin{aligned}\n\\pi_\\text{A} + \\pi_\\text{C} =& \\text{% yes in treatment; or} \\\\\n\\pi_\\text{C} =& \\text{% yes in treatment} - \\pi_\\text{A}\n\\end{aligned}\n\\]\nWe actually know \\(\\pi_\\text{A}\\)—remember in the graph above that the people who were in the control group and who used bed nets are guaranteed to be always takers (none of them are compliers or never takers). If we assume that the proportion of always takers is the same in both treatment and control, we can use that percent here, giving us this final equation for \\(\\pi_\\text{C}\\):\n\\[\n\\begin{aligned}\n\\pi_\\text{C} =& \\text{% yes in treatment} - \\pi_\\text{A} \\\\\n=& \\text{% yes in treatment} - \\text{% yes in control}\n\\end{aligned}\n\\]\nSo, if we can find the percent of people assigned to treatment who used bed nets, find the percent of people assigned to control and used bed nets, and subtract the two percentages, we’ll have the proportion of compliers, or \\(\\pi_\\text{C}\\). We can do that with the data we have (61% - 19.5% = 41.5% compliers):\n\n\nCode\nbed_nets %>%\n  group_by(treatment, bed_net) %>%\n  summarize(n = n()) %>%\n  mutate(prop = n / sum(n))\n## # A tibble: 4 × 4\n## # Groups:   treatment [2]\n##   treatment bed_net        n  prop\n##   <chr>     <fct>      <int> <dbl>\n## 1 Control   No bed net   808 0.805\n## 2 Control   Bed net      196 0.195\n## 3 Treatment No bed net   388 0.390\n## 4 Treatment Bed net      608 0.610\n\n# pi_c = prop yes in treatment - prop yes in control\npi_c <- 0.6104418 - 0.1952191\n\n\nFinally, now that we know both the ITT and \\(\\pi_\\text{C}\\), we can find the CACE (or the LATE):\n\n\nCode\nCACE <- ITT / pi_c\nCACE\n## [1] 14.43\n\n\nIt’s 14.4, which means that using bed nets increased health by 14 health points for compliers (which is a lot bigger than the 6 that we found before). We successfully filtered out the always takers and the never takers, and we have our complier-specific causal effect."
  },
  {
    "objectID": "example/cace.html#finding-the-cacelate-with-iv2sls",
    "href": "example/cace.html#finding-the-cacelate-with-iv2sls",
    "title": "Complier average treatment effects",
    "section": "Finding the CACE/LATE with IV/2SLS",
    "text": "Finding the CACE/LATE with IV/2SLS\nDoing that is super tedious though! What if there was an easier way to find the effect of the bed net program for just the compliers? We can do this with IV/2SLS regression by using assignment to treatment as an instrument.\nAssignment to treatment works as an instrument because it’s (1) relevant, since being told to use bed nets is probably highly correlated with using bed nets, (2) exclusive, since the only way that being told to use bed nets can cause changes in health is through the actual use of the bed nets, and (3) exogenous, since being told to use bed nets probably isn’t related to other things that cause health.\nHere’s a 2SLS regression with assignment to treatment as the instrument:\n\n\nCode\nmodel_2sls <- iv_robust(health ~ bed_net | treatment, data = bed_nets)\ntidy(model_2sls)\n##             term estimate std.error statistic   p.value conf.low conf.high   df outcome\n## 1    (Intercept)    38.12    0.5151     74.01 0.000e+00    37.11     39.13 1998  health\n## 2 bed_netBed net    14.43    1.2538     11.51 1.038e-29    11.97     16.89 1998  health\n\n\nThe coefficient for bed_net is identical to the CACE that we found manually! Instrumental variables are helpful for isolated program effects to only compliers when you’re dealing with noncompliance."
  },
  {
    "objectID": "example/index.html",
    "href": "example/index.html",
    "title": "Code examples",
    "section": "",
    "text": "Visit this section after you have finished the readings and lecture videos. It contains fully annotated R code and other supplementary information and it will be indispensable as you work on your problem sets and project.\nMany sections also contain videos of me live coding the examples so you can see what it looks like to work with R in real time. You’ll notice me make all sorts of little errors, which is totally normal—everyone does!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Estrategias de investigación cuantitativa",
    "section": "",
    "text": "Estrategias de investigación cuantitativa\n        \n        \n            Sociología - Facultad de Ciencias Sociales de la Universidad de Chile\n        \n        \n            SOC01020-1 • Segundo semestre 2023Departamento de Sociología FACSOUniversidad de Chile\n        \n    \n    \n      \n        \n        \n        \n      \n    \n\n\n\n\nEquipo docente\nProfesor\n\n   Dr. Pablo Perez Ahumada\n   Departamento de Sociología N° 319\n   pabloperez@uchile.cl\n\nApoyos docente\n\n   Daniela Olivares\n   danielaolivarescollio@gmail.com\n   Kevin Carrasco\n   kevin.carrasco@ug.uchile.cl\n\n\n\nInformación del curso\n\n   Jueves\n   Agosto 10 - Diciembre 2023\n   10:15 a 11:45 y 12:00 a 13:30\n   Aulario B - Sala B01"
  },
  {
    "objectID": "news/2023-01-09_welcome.html",
    "href": "news/2023-01-09_welcome.html",
    "title": "Bienvenid_s a clases!",
    "section": "",
    "text": "← News\n\n\n\nHola a todos!"
  },
  {
    "objectID": "news/2023-08-14_infos.html",
    "href": "news/2023-08-14_infos.html",
    "title": "Informaciones de la semana",
    "section": "",
    "text": "← News\n\n\n\nActualizaciones sitio web:"
  },
  {
    "objectID": "news/index.html",
    "href": "news/index.html",
    "title": "Noticias",
    "section": "",
    "text": "Ordenar por\n       Por defecto\n         \n          Fecha - Menos reciente\n        \n         \n          Fecha - Más reciente\n        \n         \n          Título\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nFecha\n\n\nTítulo\n\n\nCategorías\n\n\n\n\n\n\nlunes agosto 7, 2023 at 12:00 AM\n\n\nBienvenid_s a clases!\n\n\ncomenzando\n\n\n\n\nlunes agosto 7, 2023 at 12:00 AM\n\n\nInformaciones de la semana\n\n\ninfo\n\n\n\n\n\n\nNo hay resultados\n\n\n\n\n\n\n\n\nSuscribirse!\n\n\n\nPuedes usar un lector de feeds como Feedly o un servicio RSS-to-email como Blogtrottr para suscribirte a cualquiera de estos mensajes. ::: {.grid}\n\n\n RSS\n\n\n\n\n\n\n\n\n\n:::"
  },
  {
    "objectID": "practicos/01-content.html",
    "href": "practicos/01-content.html",
    "title": "Práctico R 1. Construcción de índices",
    "section": "",
    "text": "El Programa de las Naciones Unidas para el Desarrollo (PNUD) es la agencia de la Organización de las Naciones Unidas encargada de promover el desarrollo sostenible a nivel mundial, y uno de sus enfoques es la erradicación de la pobreza. En este contexto, el PNUD reconoce la importancia de abordar la pobreza multidimensional para lograr un desarrollo sostenible y mejorar el bienestar de las personas en todas las dimensiones de sus vidas.\nDesde el año 2016 Chile cuenta con la medida actual de pobreza multidimensional. El propósito de esta medida es complementar la medición de la pobreza basada en ingresos con un indicador que refleje las condiciones de vida de la población en aspectos relevantes para el bienestar social y una vida digna. Desde su creación, se ha buscado obtener un diagnóstico más completo de la pobreza y contar con una herramienta útil para el diseño, implementación, monitoreo y evaluación de políticas públicas.\nInicialmente, la medida de pobreza multidimensional incluyó 4 dimensiones (Educación, Salud, Trabajo y Seguridad Social, y Vivienda) con tres indicadores por dimensión (12 indicadores en total), cada uno con igual ponderación (8,3%), por lo tanto, con dimensiones cuyo peso representan el 25% de la medida.Posteriormente, con los resultados de la encuesta Casen 2015 se incorpora una quinta dimensión de Redes y Cohesión Social y se amplía la dimensión de Vivienda para incluir el concepto de Entorno. Desde entonces, la medida ha estado compuesta por 5 dimensiones (Educación, Salud, Trabajo y Seguridad Social, Vivienda y Entorno, y Redes y Cohesión Social), manteniendo la definición de 3 indicadores por dimensión, de modo que la medida queda compuesta por 15 indicadores. Respecto del peso de las dimensiones, con el fin de favorecer cierta estabilidad de la medida, la dimensión de Redes y Cohesión Social se incorpora con un peso de 10% y se mantiene la igualdad de ponderación entre las demás dimensiones, ahora con una ponderación de 22,5%.\n\n\nEl objetivo de este ejercicio práctico es comprender y estimar el proceso de construcción de índices ponderados y no ponderados en R.\n\n\n\nComo sabemos, la lógica de R es instalar librerías (solo 1 vez, con install.packages(“librería”)), y luego cargarlas cada vez que es necesario usarlas (con library(librería)). El problema de esto es que a veces no se sabe claramente qué librerías están instaladas y cuales no, lo que va a arrojar error al cargarlas. Y, como sucede en R, existe una librería para solucionar este problema que se llama pacman (package manager). Lo que hace pacman es cargar la librería, y si no está instalada, la instala y la carga:\nPara utilizar la primera vez (si es que no está instalada):\n\n\nCódigo\ninstall.packages(\"pacman\")\n\n\nY en adelante, las librerías se cargan así pacman::p_load(libreria1,libreria2,libreriaX) :\n\n\nCódigo\npacman::p_load(tidyverse, #Conjunto de paquetes, sobre todo dplyr y ggplot2\n               car, #Para recodificar\n               haven,\n               summarytools #Para descriptivos\n               )\n\noptions(scipen = 999) # para desactivar notacion cientifica\nrm(list = ls()) # para limpiar el entorno de trabajo\n\n\n\n\n\nLa base de datos a utilizar es la CASEN 2022 (Encuesta de Caracterización Socioeconómica Nacional). La base de datos está disponible en este link y el cuestionario en este link.\nSin embargo, para realizar este ejercicio práctico utilizaremos una muestra aleatoria de esta base de datos para simplificar el proceso de construcción de índices. El código que crea este subset está disponible acá\n\n\n\n\nCódigo\nload(url(\"https://github.com/cursos-metodos-facso/investigacion-cuantitativa/raw/main/files/data/casen2022.RData\")) #Cargar base de datos\n\n\n\n\n\n\n\nCódigo\nview(dfSummary(casen2022, headings=FALSE, graph.col = FALSE))\n\n\n\n\n\n\n\n  \n    \n      No\n      Variable\n      Label\n      Stats / Values\n      Freqs (% of Valid)\n      Valid\n      Missing\n    \n  \n  \n    \n      1\n      asistencia\n[haven_labelled, vctrs_vctr, double]\n      Hogar carente en asistencia\n      Min  : 0Mean : 0Max  : 1\n      0:9849(98.5%)1:151(1.5%)\n      10000\n(100.0%)\n      0\n(0.0%)\n    \n    \n      2\n      rezago\n[haven_labelled, vctrs_vctr, double]\n      Hogar carente en rezago escolar\n      Min  : 0Mean : 0Max  : 1\n      0:9900(99.0%)1:99(1.0%)\n      9999\n(100.0%)\n      1\n(0.0%)\n    \n    \n      3\n      escolaridad\n[haven_labelled, vctrs_vctr, double]\n      Hogar carente en escolaridad\n      Min  : 0Mean : 0.3Max  : 1\n      0:6926(69.3%)1:3065(30.7%)\n      9991\n(99.9%)\n      9\n(0.1%)\n    \n    \n      4\n      malnutricion\n[haven_labelled, vctrs_vctr, double]\n      Hogar carente en malnutrición en\nniños/as\n      Min  : 0Mean : 0Max  : 1\n      0:9679(96.9%)1:307(3.1%)\n      9986\n(99.9%)\n      14\n(0.1%)\n    \n    \n      5\n      sist_salud\n[haven_labelled, vctrs_vctr, double]\n      Hogar carente en adscripción a sistema\nde salud\n      Min  : 0Mean : 0Max  : 1\n      0:9561(95.7%)1:425(4.3%)\n      9986\n(99.9%)\n      14\n(0.1%)\n    \n    \n      6\n      atencion\n[haven_labelled, vctrs_vctr, double]\n      Hogar carente en atención\n      Min  : 0Mean : 0.1Max  : 1\n      0:9471(94.8%)1:524(5.2%)\n      9995\n(100.0%)\n      5\n(0.0%)\n    \n    \n      7\n      ocupacion\n[haven_labelled, vctrs_vctr, double]\n      Hogar carente en ocupación\n      Min  : 0Mean : 0.1Max  : 1\n      0:8999(90.0%)1:1001(10.0%)\n      10000\n(100.0%)\n      0\n(0.0%)\n    \n    \n      8\n      seg_social\n[haven_labelled, vctrs_vctr, double]\n      Hogar carente en seguridad social\n      Min  : 0Mean : 0.3Max  : 1\n      0:6895(69.3%)1:3059(30.7%)\n      9954\n(99.5%)\n      46\n(0.5%)\n    \n    \n      9\n      jubilacion\n[haven_labelled, vctrs_vctr, double]\n      Hogar carente en jubilaciones\n      Min  : 0Mean : 0.1Max  : 1\n      0:8827(88.3%)1:1173(11.7%)\n      10000\n(100.0%)\n      0\n(0.0%)\n    \n    \n      10\n      habitabilidad\n[haven_labelled, vctrs_vctr, double]\n      Hogar carente en habitabilidad\n      Min  : 0Mean : 0.2Max  : 1\n      0:8412(84.2%)1:1583(15.8%)\n      9995\n(100.0%)\n      5\n(0.0%)\n    \n    \n      11\n      hacinamiento\n[haven_labelled, vctrs_vctr, double]\n      Hogar carente en hacinamiento\n      Min  : 0Mean : 0Max  : 1\n      0:9582(95.9%)1:413(4.1%)\n      9995\n(100.0%)\n      5\n(0.0%)\n    \n    \n      12\n      vivienda\n[haven_labelled, vctrs_vctr, double]\n      Hogar carente en estado de la vivienda\n      Min  : 0Mean : 0.1Max  : 1\n      0:8741(87.4%)1:1259(12.6%)\n      10000\n(100.0%)\n      0\n(0.0%)\n    \n    \n      13\n      serv_basicos\n[haven_labelled, vctrs_vctr, double]\n      Hogar carente en servicios básicos\n      Min  : 0Mean : 0.1Max  : 1\n      0:9276(92.8%)1:724(7.2%)\n      10000\n(100.0%)\n      0\n(0.0%)\n    \n    \n      14\n      entorno\n[haven_labelled, vctrs_vctr, double]\n      Hogar carente en entorno\n      Min  : 0Mean : 0.1Max  : 1\n      0:8768(88.0%)1:1193(12.0%)\n      9961\n(99.6%)\n      39\n(0.4%)\n    \n    \n      15\n      ap_part_social\n[haven_labelled, vctrs_vctr, double]\n      Hogar carente en apoyo y participación\nsocial\n      Min  : 0Mean : 0.1Max  : 1\n      0:9335(93.7%)1:629(6.3%)\n      9964\n(99.6%)\n      36\n(0.4%)\n    \n    \n      16\n      trato\n[haven_labelled, vctrs_vctr, double]\n      Hogar carente en trato igualitario\n      Min  : 0Mean : 0.2Max  : 1\n      0:8438(84.4%)1:1562(15.6%)\n      10000\n(100.0%)\n      0\n(0.0%)\n    \n    \n      17\n      seguridad\n[haven_labelled, vctrs_vctr, double]\n      Hogar carente en seguridad\n      Min  : 0Mean : 0.1Max  : 1\n      0:9145(91.4%)1:855(8.6%)\n      10000\n(100.0%)\n      0\n(0.0%)\n    \n    \n      18\n      region\n[haven_labelled, vctrs_vctr, double]\n      Región\n      Mean (sd) : 8.8 (4.2)min ≤ med ≤ max:1 ≤ 8 ≤ 16IQR (CV) : 8 (0.5)\n      16 distinct values\n      10000\n(100.0%)\n      0\n(0.0%)\n    \n    \n      19\n      area\n[haven_labelled, vctrs_vctr, double]\n      Área\n      Min  : 1Mean : 1.2Max  : 2\n      1:7934(79.3%)2:2066(20.7%)\n      10000\n(100.0%)\n      0\n(0.0%)\n    \n  \n\nGenerated by summarytools 1.0.1 (R version 4.2.2)2023-10-05\n\n\n\nEn esta base de datos, las variables de interés que están presentes (ej. asistencia, rezago, escolaridad) son variables dummy, es decir, variables que tienen como valores posibles 0 y 1. Donde 0 implica la ausencia de un atributo y 1 la presencia del mismo atributo.\nPara medir pobreza multidimensional, 1 indica la carencia de un servicio o cualidad, por ejemplo, se considera que un hogar es carente en escolaridad si al menos uno de sus integrantes mayores de 18 años ha alcanzado menos años de escolaridad que los establecidos por ley, de acuerdo a su edad. Por lo tanto, en la variable escolaridad 1) indica un hogar carente en escolaridad, que según nuestra base de datos corresponde a 3065 hogares (30.7% de nuestra sub-muestra).\n\n\n\n\n\nSeleccionamos solo los indicadores que eran utilizados hasta 2014\n\n\nCódigo\nindicadores2014 <- casen2022 %>% select(asistencia, \n                                        rezago, \n                                        escolaridad, \n                                        malnutricion, \n                                        sist_salud, \n                                        atencion, \n                                        ocupacion, \n                                        seg_social, \n                                        jubilacion, \n                                        hacinamiento, \n                                        estado_vivienda=vivienda, \n                                        serv_basicos)  %>% \n  na.omit() %>% # Eliminar Na's\n  mutate_all(~(as.numeric(.))) # Convertimos todas las variables a numéricas\n\n\nCon la función mutate creamos una nueva variable para cada dimensión, que contenga el promedio simple de los tres indicadores correspondientes.\n\n\nCódigo\nindicadores2014 = indicadores2014 %>% \n  rowwise() %>%\n  mutate(educ = mean(c(asistencia, rezago, escolaridad)),\n         salud = mean(c(malnutricion, sist_salud, atencion)),\n         trabajo= mean(c(ocupacion, seg_social, jubilacion)),\n         vivienda= mean(c(hacinamiento, estado_vivienda, serv_basicos))) %>% \n  ungroup()\n\n\nLuego, como la pobreza multidimensional consideraba cuatro dimensiones equivalentes (sin ponderar), es posible obtener el índice de pobreza multidimensional a partir del promedio de las cuatro dimensiones.\n\n\nCódigo\nindicadores2014 = indicadores2014 %>% \n  rowwise() %>%\n  mutate(pobreza = mean(c(educ, salud, trabajo, vivienda))) %>% \n  ungroup()\n\n\nLo que nos da este resultado:\n\n\nCódigo\nindicadores2014 %>% select(pobreza) %>% head(10) # Primeros 10 casos\n\n\n# A tibble: 10 × 1\n   pobreza\n     <dbl>\n 1  0.167 \n 2  0     \n 3  0.0833\n 4  0.25  \n 5  0.0833\n 6  0     \n 7  0.25  \n 8  0.167 \n 9  0.0833\n10  0.167 \n\n\nCódigo\nsummary(indicadores2014$pobreza) # Resumen\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n0.00000 0.00000 0.08333 0.10161 0.16667 0.58333 \n\n\n¿Cómo podemos conocer el porcentaje total de pobreza multidimensional del país?\nEl PNUD considera como límite para el índice de cuatro dimensiones un 25% de pobreza multidimensional (lo que equivale a tener carencia en los tres indicadores de una dimensión). Por lo tanto, podemos utilizar un condicional que indique “si” existe pobreza muldimensional cuando nuestra variable “pobreza” sea mayor o igual a 0.25 y que indique que “no” existe pobreza multidimensional cuando la variable “pobreza” sea menor a 0.25. case_when viene en dplyr.\n\n\nCódigo\nindicadores2014 <- indicadores2014 %>% mutate(pobreza = case_when(pobreza>=0.25~\"si\",\n                                                      pobreza<0.25~\"no\")\n                           )\nprop.table(table(indicadores2014$pobreza))*100\n\n\n\n      no       si \n87.02806 12.97194 \n\n\nSegún el análisis realizado con la submuestra aleatoria de la CASEN, considerando las cuatro dimensiones que se utilizaban hasta el 2014, existe un 12.97% de pobreza multidimensional en Chile\n\n\n\nVeamos ahora el mismo proceso, pero considerando la quinta dimensión que fue agregada en 2016 sobre Redes y Cohesión Social.\n\nEn esta operacionalización del índice de pobreza multidimensional las cuatro dimensiones originales equivalen a un 22.5% cada una, mientras que la nueva dimensión de redes y cohesión social equivale a un 10%.\nSeleccionemos solo los indicadores que son utilizados desde 2016.\n\n\nCódigo\nindicadores2016 <- casen2022 %>% select(asistencia, \n                                        rezago, \n                                        escolaridad, \n                                        malnutricion, \n                                        sist_salud, \n                                        atencion, \n                                        ocupacion, \n                                        seg_social, \n                                        jubilacion, \n                                        habitabilidad, \n                                        serv_basicos,\n                                        entorno,\n                                        ap_part_social,\n                                        trato,\n                                        seguridad,\n                                        area,\n                                        region) %>% \n  na.omit() %>% # Eliminar Na's\n  mutate_all(~(as.numeric(.))) # Convertimos todas las variables a numéricas\n\n\nSeguimos los mismos pasos que con el índice anterior, estimando un promedio simple para cada una de las dimensiones.\n\n\nCódigo\nindicadores2016 = indicadores2016 %>% \n  rowwise() %>%\n  mutate(educ = mean(c(asistencia, rezago, escolaridad)),\n         salud = mean(c(malnutricion, sist_salud, atencion)),\n         trabajo= mean(c(ocupacion, seg_social, jubilacion)),\n         vivienda= mean(c(habitabilidad, serv_basicos, entorno)),\n         redes_cohesion= mean(c(ap_part_social, trato, seguridad))) %>% \n  ungroup()\n\n\nSin embargo, como en esta ocasión se trata de un índice ponderado (con dimensiones con distinto peso cada una), multiplicamos cada dimensión por su peso correspondiente y las sumamos.\n\n\nCódigo\nindicadores2016 = indicadores2016 %>% \n  rowwise() %>%\n  mutate(pobreza_pond = (educ*22.5) + (salud*22.5) + (trabajo*22.5) + (vivienda*22.5) + (redes_cohesion*10)) %>%  \n  ungroup()\n\n\nLo que nos da este resultado:\n\n\nCódigo\nindicadores2016 %>% select(pobreza_pond) %>% head(10) # Primeros 10 casos\n\n\n# A tibble: 10 × 1\n   pobreza_pond\n          <dbl>\n 1         15  \n 2          7.5\n 3          7.5\n 4         25.8\n 5          7.5\n 6          0  \n 7         22.5\n 8         15  \n 9          7.5\n10         22.5\n\n\nCódigo\nsummary(indicadores2016$pobreza_pond) # Resumen\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  0.000   3.333   7.500  10.986  15.000  62.500 \n\n\n¿Cómo podemos conocer el porcentaje total de pobreza multidimensional del país?\nEl PNUD considera como límite para el índice de cinco dimensiones un 22.5% de pobreza multidimensional (lo que equivale a tener carencia en los tres indicadores de una dimensión). Por lo tanto, podemos utilizar un condicional que indique “si” existe pobreza muldimensional cuando nuestra variable “pobreza” sea mayor o igual a 22.5 y que indique que “no” existe pobreza multidimensional cuando la variable “pobreza” sea menor a 22.5.\n\n\nCódigo\nindicadores2016 <- indicadores2016 %>% mutate(pobreza = case_when(pobreza_pond>=22.5~\"si\",\n                                                      pobreza_pond<22.5~\"no\")\n                           )\n                          \nprop.table(table(indicadores2016$pobreza))*100\n\n\n\n      no       si \n84.26349 15.73651 \n\n\nSegún el análisis realizado con la submuestra aleatoria de la CASEN, considerando las cinco dimensiones que se comenzaron a utilizar en 2016, existe un 15.73% de pobreza multidimensional en Chile.\n\n\nPodemos utilizar otras variables de la CASEN para poder conocer cómo se distribuye la pobreza multidimensional en Chile. Por ejemplo, porcentaje de pobreza multidimensional por región:\n\n\nCódigo\nprop.table(table(indicadores2016$region, indicadores2016$pobreza), margin = 1)\n\n\n    \n            no        si\n  1  0.8426966 0.1573034\n  2  0.8159091 0.1840909\n  3  0.8015075 0.1984925\n  4  0.8317073 0.1682927\n  5  0.8414272 0.1585728\n  6  0.8673469 0.1326531\n  7  0.8744770 0.1255230\n  8  0.8487047 0.1512953\n  9  0.7982955 0.2017045\n  10 0.7804878 0.2195122\n  11 0.8564593 0.1435407\n  12 0.9437751 0.0562249\n  13 0.8526140 0.1473860\n  14 0.8428030 0.1571970\n  15 0.8203753 0.1796247\n  16 0.8744589 0.1255411\n\n\no pobreza multidimensional por zona geográfica 1) urbano 2) rural\n\n\nCódigo\nprop.table(table(indicadores2016$area, indicadores2016$pobreza), margin = 1)\n\n\n   \n           no        si\n  1 0.8723105 0.1276895\n  2 0.7284377 0.2715623"
  },
  {
    "objectID": "practicos/02-content.html",
    "href": "practicos/02-content.html",
    "title": "Práctico R 2. Construcción de escalas",
    "section": "",
    "text": "Para el taller práctico de hoy utilizaremos la base de datos del estudio de Martin et al. (2003). Individual differences in uses of humor and and their relation to psychological well-being. Development of the Humor Styles Questionnaire.\nEn este artículo se describe el desarrollo y la validación inicial del Cuestionario de Estilos de Humor, que evalúa cuatro dimensiones relacionadas con las diferencias individuales en el uso del humor. Estas son: usos relativamente benignos del humor para mejorar uno mismo (Autofortalecedor) y para mejorar las relaciones con otros (Afiliativo), uso del humor para mejorar uno mismo a expensas de los demás (Agresivo) y uso del humor para mejorar las relaciones a expensas de uno mismo (Autodestructivo)."
  },
  {
    "objectID": "practicos/02-content.html#cargar-librerías",
    "href": "practicos/02-content.html#cargar-librerías",
    "title": "Práctico R 2. Construcción de escalas",
    "section": "Cargar librerías",
    "text": "Cargar librerías\nLas librerías que utilizaremos esta sesión son las siguientes:\n\n\nCódigo\n# install.packages(\"pacman\") # Cargar sólo si no la tenemos instalada\nlibrary(pacman)\npacman::p_load(tidyverse, # conjunto de paquetes, sobre todo dplyr y ggplot2\n               car,       # para recodificar\n               psych,     # para Alfa de Chronbach\n               sjmisc,    # para descriptivos\n               remotes,   # para instalar paquete jogRu\n               readr)     # para cargararchivo csv\n\noptions(scipen = 999) # para desactivar notacion cientifica\nrm(list = ls())       # para limpiar el entorno de trabajo\n\n\nAdemás, instalaremos la librería jogRu desde github, que nos permitirá calculr el alfa de Chronbach para variables ordinales.\n\n\nCódigo\nremotes::install_github(\"jogrue/jogRu\", force = T)\n\n\nyaml        (2.3.6  -> 2.3.7  ) [CRAN]\nxfun        (0.34   -> 0.40   ) [CRAN]\nhighr       (0.9    -> 0.10   ) [CRAN]\nevaluate    (0.18   -> 0.22   ) [CRAN]\nfs          (1.5.2  -> 1.6.3  ) [CRAN]\nvctrs       (0.6.1  -> 0.6.4  ) [CRAN]\nstringi     (1.7.8  -> 1.7.12 ) [CRAN]\ncli         (3.4.1  -> 3.6.1  ) [CRAN]\nfastmap     (1.1.0  -> 1.1.1  ) [CRAN]\ndigest      (0.6.30 -> 0.6.33 ) [CRAN]\nsass        (0.4.2  -> 0.4.7  ) [CRAN]\nrlang       (1.1.0  -> 1.1.1  ) [CRAN]\ncachem      (1.0.6  -> 1.0.8  ) [CRAN]\ntinytex     (0.42   -> 0.48   ) [CRAN]\nknitr       (1.41   -> 1.44   ) [CRAN]\njsonlite    (1.8.4  -> 1.8.7  ) [CRAN]\nhtmltools   (0.5.5  -> 0.5.6.1) [CRAN]\nfontawesome (0.4.0  -> 0.5.2  ) [CRAN]\nbslib       (0.4.1  -> 0.5.1  ) [CRAN]\nutf8        (1.2.2  -> 1.2.3  ) [CRAN]\ncolorspace  (2.0-3  -> 2.1-0  ) [CRAN]\npillar      (1.8.1  -> 1.9.0  ) [CRAN]\nfansi       (1.0.3  -> 1.0.5  ) [CRAN]\nlabeling    (0.4.2  -> 0.4.3  ) [CRAN]\nwithr       (2.5.0  -> 2.5.1  ) [CRAN]\nisoband     (0.2.6  -> 0.2.7  ) [CRAN]\ngtable      (0.3.1  -> 0.3.4  ) [CRAN]\nggplot2     (3.4.1  -> 3.4.4  ) [CRAN]\nviridisLite (0.4.1  -> 0.4.2  ) [CRAN]\nrmarkdown   (2.18   -> 2.25   ) [CRAN]\nrstudioapi  (0.14   -> 0.15.0 ) [CRAN]\ncheckmate   (2.1.0  -> 2.2.0  ) [CRAN]\nFormula     (1.2-4  -> 1.2-5  ) [CRAN]\nviridis     (0.6.2  -> 0.6.4  ) [CRAN]\ndata.table  (1.14.4 -> 1.14.8 ) [CRAN]\nHmisc       (4.7-2  -> 5.1-1  ) [CRAN]\npsych       (2.2.9  -> 2.3.9  ) [CRAN]\npackage 'yaml' successfully unpacked and MD5 sums checked\npackage 'xfun' successfully unpacked and MD5 sums checked\npackage 'highr' successfully unpacked and MD5 sums checked\npackage 'evaluate' successfully unpacked and MD5 sums checked\npackage 'fs' successfully unpacked and MD5 sums checked\npackage 'vctrs' successfully unpacked and MD5 sums checked\npackage 'stringi' successfully unpacked and MD5 sums checked\npackage 'cli' successfully unpacked and MD5 sums checked\npackage 'fastmap' successfully unpacked and MD5 sums checked\npackage 'digest' successfully unpacked and MD5 sums checked\npackage 'sass' successfully unpacked and MD5 sums checked\npackage 'rlang' successfully unpacked and MD5 sums checked\npackage 'cachem' successfully unpacked and MD5 sums checked\npackage 'tinytex' successfully unpacked and MD5 sums checked\npackage 'jsonlite' successfully unpacked and MD5 sums checked\npackage 'htmltools' successfully unpacked and MD5 sums checked\npackage 'fontawesome' successfully unpacked and MD5 sums checked\npackage 'bslib' successfully unpacked and MD5 sums checked\npackage 'utf8' successfully unpacked and MD5 sums checked\npackage 'colorspace' successfully unpacked and MD5 sums checked\npackage 'pillar' successfully unpacked and MD5 sums checked\npackage 'fansi' successfully unpacked and MD5 sums checked\npackage 'labeling' successfully unpacked and MD5 sums checked\npackage 'withr' successfully unpacked and MD5 sums checked\npackage 'isoband' successfully unpacked and MD5 sums checked\npackage 'gtable' successfully unpacked and MD5 sums checked\npackage 'viridisLite' successfully unpacked and MD5 sums checked\npackage 'rmarkdown' successfully unpacked and MD5 sums checked\npackage 'rstudioapi' successfully unpacked and MD5 sums checked\npackage 'checkmate' successfully unpacked and MD5 sums checked\npackage 'Formula' successfully unpacked and MD5 sums checked\npackage 'viridis' successfully unpacked and MD5 sums checked\npackage 'data.table' successfully unpacked and MD5 sums checked\npackage 'Hmisc' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\kevin\\AppData\\Local\\Temp\\RtmpiuPy4M\\downloaded_packages\n* checking for file 'C:\\Users\\kevin\\AppData\\Local\\Temp\\RtmpiuPy4M\\remotes7f041be05c5d\\jogrue-jogRu-c659fcd/DESCRIPTION' ... OK\n* preparing 'jogRu':\n* checking DESCRIPTION meta-information ... OK\n* checking for LF line-endings in source and make files and shell scripts\n* checking for empty or unneeded directories\nOmitted 'LazyData' from DESCRIPTION\n* building 'jogRu_2.0.tar.gz'\n\n\n\n\n\n\n\n\n\nNota\n\n\n\nSi pregunta These packages have more recent versions available. It is recommended to update all of them.Which would you like to update? SIEMPRE PONER 3: None."
  },
  {
    "objectID": "practicos/02-content.html#datos-y-variables",
    "href": "practicos/02-content.html#datos-y-variables",
    "title": "Práctico R 2. Construcción de escalas",
    "section": "Datos y variables",
    "text": "Datos y variables\nComo mencionamos, utilizaremos la base de datos del estudio Martin et al. (2003). Individual differences in uses of humor and and their relation to psychological well-being. Development of the Humor Styles Questionnaire.\nEn estos datos podemos ver una serie de ítems que corresponden a diferentes dimensiones de la escala, donde cada ítem tiene valores entre 1 y 5. De acuerdo con el paper, los ítems se ordenan de esta forma de acuerdo con los tipos de humor:\n\nafiliativo : Q1, Q5, Q9 , Q13, Q17, Q21, Q25, Q29\nautofortalecedor : Q2, Q6, Q10, Q14, Q18, Q22, Q26, Q30\nagresivo : Q3, Q7, Q11, Q15, Q19, Q23, Q27, Q31\nautodestructivo : Q4, Q8, Q12, Q16, Q20, Q24, Q28, Q32\n\n\nCargar base de datos\n\n\nCódigo\ndata <- read.csv(url(\"https://github.com/cursos-metodos-facso/investigacion-cuantitativa/raw/main/files/data/data.csv\"))\n\n\n\n\nVisualización de datos\n\n\nCódigo\nhead(data)\n\n\n  Q1 Q2 Q3 Q4 Q5 Q6 Q7 Q8 Q9 Q10 Q11 Q12 Q13 Q14 Q15 Q16 Q17 Q18 Q19 Q20 Q21\n1  2  2  3  1  4  5  4  3  4   3   3   1   5   4   4   4   2   3   3   1   4\n2  2  3  2  2  4  4  4  3  4   3   4   3   3   4   5   4   2   2   3   2   3\n3  3  4  3  3  4  4  3  1  2   4   3   2   4   4   3   3   2   4   2   1   4\n4  3  3  3  4  3  5  4  3 -1   4   2   4   4   5   4   3   3   3   3   3   4\n5  1  4  2  2  3  5  4  1  4   4   2   2   5   4   4   4   2   3   2   1   5\n6  3  3  3  2  3  3  4  2  2   1   3   3   4   4   4   3   2   1   4   2   4\n  Q22 Q23 Q24 Q25 Q26 Q27 Q28 Q29 Q30 Q31 Q32 affiliative selfenhancing\n1   4   3   2   1   3   2   4   2   4   2   2         4.0           3.5\n2   3   4   2   2   5   1   2   4   4   3   1         3.3           3.5\n3   2   4   3   2   4   3   3   2   5   4   2         3.9           3.9\n4   3   2   4   2   4   2   2   4   5   3   3         3.6           4.0\n5   3   3   1   1   5   2   3   2   5   4   2         4.1           4.1\n6   4   4   2   2   3   2   4   3   4   3   3         3.6           2.9\n  agressive selfdefeating age gender accuracy\n1       3.0           2.3  25      2      100\n2       3.3           2.4  44      2       90\n3       3.1           2.3  50      1       75\n4       2.9           3.3  30      2       85\n5       2.9           2.0  52      1       80\n6       3.4           2.6  30      2       60\n\n\nCódigo\nstr(data)\n\n\n'data.frame':   1071 obs. of  39 variables:\n $ Q1           : int  2 2 3 3 1 3 4 2 2 4 ...\n $ Q2           : int  2 3 4 3 4 3 1 4 2 2 ...\n $ Q3           : int  3 2 3 3 2 3 2 4 1 4 ...\n $ Q4           : int  1 2 3 4 2 2 4 1 1 1 ...\n $ Q5           : int  4 4 4 3 3 3 2 5 3 3 ...\n $ Q6           : int  5 4 4 5 5 3 3 5 4 5 ...\n $ Q7           : int  4 4 3 4 4 4 3 4 3 4 ...\n $ Q8           : int  3 3 1 3 1 2 3 3 1 2 ...\n $ Q9           : int  4 4 2 -1 4 2 4 2 3 3 ...\n $ Q10          : int  3 3 4 4 4 1 4 4 3 1 ...\n $ Q11          : int  3 4 3 2 2 3 4 3 2 5 ...\n $ Q12          : int  1 3 2 4 2 3 1 3 2 3 ...\n $ Q13          : int  5 3 4 4 5 4 2 5 5 1 ...\n $ Q14          : int  4 4 4 5 4 4 1 4 3 3 ...\n $ Q15          : int  4 5 3 4 4 4 2 3 3 1 ...\n $ Q16          : int  4 4 3 3 4 3 4 3 4 5 ...\n $ Q17          : int  2 2 2 3 2 2 4 3 2 5 ...\n $ Q18          : int  3 2 4 3 3 1 1 4 2 1 ...\n $ Q19          : int  3 3 2 3 2 4 3 5 4 3 ...\n $ Q20          : int  1 2 1 3 1 2 1 3 1 1 ...\n $ Q21          : int  4 3 4 4 5 4 3 4 4 2 ...\n $ Q22          : int  4 3 2 3 3 4 2 3 4 1 ...\n $ Q23          : int  3 4 4 2 3 4 2 3 4 5 ...\n $ Q24          : int  2 2 3 4 1 2 3 1 2 2 ...\n $ Q25          : int  1 2 2 2 1 2 4 1 1 4 ...\n $ Q26          : int  3 5 4 4 5 3 3 4 3 5 ...\n $ Q27          : int  2 1 3 2 2 2 2 2 4 5 ...\n $ Q28          : int  4 2 3 2 3 4 2 4 4 2 ...\n $ Q29          : int  2 4 2 4 2 3 3 1 1 1 ...\n $ Q30          : int  4 4 5 5 5 4 3 5 5 5 ...\n $ Q31          : int  2 3 4 3 4 3 4 2 2 3 ...\n $ Q32          : int  2 1 2 3 2 3 4 2 1 2 ...\n $ affiliative  : num  4 3.3 3.9 3.6 4.1 3.6 2.3 4.4 4.1 2.4 ...\n $ selfenhancing: num  3.5 3.5 3.9 4 4.1 2.9 2.3 4.1 3.3 2.9 ...\n $ agressive    : num  3 3.3 3.1 2.9 2.9 3.4 2.8 3.3 2.9 3.8 ...\n $ selfdefeating: num  2.3 2.4 2.3 3.3 2 2.6 2.8 2.5 2 2.3 ...\n $ age          : int  25 44 50 30 52 30 27 34 30 18 ...\n $ gender       : int  2 2 1 2 1 2 1 1 2 1 ...\n $ accuracy     : int  100 90 75 85 80 60 60 88 95 85 ..."
  },
  {
    "objectID": "practicos/02-content.html#procesamiento",
    "href": "practicos/02-content.html#procesamiento",
    "title": "Práctico R 2. Construcción de escalas",
    "section": "Procesamiento",
    "text": "Procesamiento\n\nRecodificar\nPara que todas las escalas queden en el mismo orden jerárquico, es necesario invertir algunos ítems.\n\n\nCódigo\ndata = data %>% \n  mutate_at(vars(Q1, Q9, Q17, Q25, Q29, # afiliativo\n                 Q22,                   # autofortalecedor\n                 Q7, Q15, Q23, Q31,     # agresivo\n                 Q16), ~(6-.)) %>%      # autodestructivo\n  mutate(gender = car::recode(.$gender, \"0 = NA;\n                              1 = 'Hombre'; 2 = 'Mujer'; 3 = 'Otro'\")) %>% \n  mutate_at(vars(1:32), ~(ifelse(. < 1 | . > 5, NA, .))) %>% \n  na.omit()\n\n\n\n\nCrear objetos para dimensiones de la escala\nCreamos cuatro objetos que contienen los ítems de cada dimensión de la escala.\n\n\nCódigo\nafiliativo       <- data %>% select(Q1, Q5, Q9 , Q13, Q17, Q21, Q25, Q29)\nautofortalecedor <- data %>% select(Q2, Q6, Q10, Q14, Q18, Q22, Q26, Q30)\nagresivo         <- data %>% select(Q3, Q7, Q11, Q15, Q19, Q23, Q27, Q31)\nautodestructivo  <- data %>% select(Q4, Q8, Q12, Q16, Q20, Q24, Q28, Q32)"
  },
  {
    "objectID": "practicos/02-content.html#explorar-datos",
    "href": "practicos/02-content.html#explorar-datos",
    "title": "Práctico R 2. Construcción de escalas",
    "section": "Explorar datos",
    "text": "Explorar datos\n\nDescriptivos\n\n\nCódigo\n# Medias para cada dimensión\ndata %>% \n  summarise(Afiliativo = mean(affiliative),\n            Autofortalecedor = mean(selfenhancing),\n            Agresivo = mean(agressive),\n            Autodestructivo = mean(selfdefeating))\n\n\n  Afiliativo Autofortalecedor Agresivo Autodestructivo\n1   4.010628         3.392308 2.968219        2.767308\n\n\nCódigo\n# Frecuencias por género\ntable(data$gender)\n\n\n\nHombre  Mujer   Otro \n   537    443      8 \n\n\nCódigo\n# Medias para cada dimensión por género\ndata %>% group_by(gender) %>% \n  summarise(Afiliativo = mean(affiliative),\n            Autofortalecedor = mean(selfenhancing),\n            Agresivo = mean(agressive),\n            Autodestructivo = mean(selfdefeating))\n\n\n# A tibble: 3 × 5\n  gender Afiliativo Autofortalecedor Agresivo Autodestructivo\n  <chr>       <dbl>            <dbl>    <dbl>           <dbl>\n1 Hombre       4.05             3.38     2.95            2.82\n2 Mujer        3.97             3.40     2.99            2.70\n3 Otro         3.52             3.45     2.89            2.6"
  },
  {
    "objectID": "practicos/02-content.html#análisis",
    "href": "practicos/02-content.html#análisis",
    "title": "Práctico R 2. Construcción de escalas",
    "section": "Análisis",
    "text": "Análisis\n\nEstimar correlación\nSe debe estimar la correlación de cada dimensión de la escala por separado.\n\n\nCódigo\n# Afiliativo\ncor(afiliativo)\n\n\n           Q1        Q5        Q9       Q13       Q17       Q21       Q25\nQ1  1.0000000 0.4219343 0.3171529 0.4266762 0.5290245 0.4568504 0.4618863\nQ5  0.4219343 1.0000000 0.3719656 0.3715378 0.4780982 0.4521887 0.3411674\nQ9  0.3171529 0.3719656 1.0000000 0.2707130 0.4179284 0.3144385 0.3202277\nQ13 0.4266762 0.3715378 0.2707130 1.0000000 0.4546202 0.4517790 0.6102194\nQ17 0.5290245 0.4780982 0.4179284 0.4546202 1.0000000 0.5817920 0.5061191\nQ21 0.4568504 0.4521887 0.3144385 0.4517790 0.5817920 1.0000000 0.4455769\nQ25 0.4618863 0.3411674 0.3202277 0.6102194 0.5061191 0.4455769 1.0000000\nQ29 0.3706320 0.4804055 0.3019961 0.2697704 0.3851621 0.3156306 0.3451300\n          Q29\nQ1  0.3706320\nQ5  0.4804055\nQ9  0.3019961\nQ13 0.2697704\nQ17 0.3851621\nQ21 0.3156306\nQ25 0.3451300\nQ29 1.0000000\n\n\nCódigo\n# Autofortalecedor\ncor(autofortalecedor)\n\n\n           Q2        Q6       Q10       Q14       Q18       Q22       Q26\nQ2  1.0000000 0.2741238 0.4379514 0.4405901 0.4886435 0.3370991 0.4080850\nQ6  0.2741238 1.0000000 0.2979399 0.3707698 0.2519714 0.1492299 0.3772628\nQ10 0.4379514 0.2979399 1.0000000 0.4806244 0.6198183 0.2680397 0.5483005\nQ14 0.4405901 0.3707698 0.4806244 1.0000000 0.4837968 0.3347620 0.5288270\nQ18 0.4886435 0.2519714 0.6198183 0.4837968 1.0000000 0.2669016 0.4605230\nQ22 0.3370991 0.1492299 0.2680397 0.3347620 0.2669016 1.0000000 0.2640024\nQ26 0.4080850 0.3772628 0.5483005 0.5288270 0.4605230 0.2640024 1.0000000\nQ30 0.2449183 0.4615775 0.2744784 0.3193377 0.2713470 0.1709110 0.2913439\n          Q30\nQ2  0.2449183\nQ6  0.4615775\nQ10 0.2744784\nQ14 0.3193377\nQ18 0.2713470\nQ22 0.1709110\nQ26 0.2913439\nQ30 1.0000000\n\n\nCódigo\n# Agresivo\ncor(agresivo)\n\n\n           Q3        Q7       Q11       Q15       Q19       Q23       Q27\nQ3  1.0000000 0.2839415 0.2631534 0.3945511 0.2853576 0.3608919 0.3484064\nQ7  0.2839415 1.0000000 0.3208911 0.3963730 0.2809997 0.2102096 0.2953999\nQ11 0.2631534 0.3208911 1.0000000 0.3051340 0.3479591 0.1701522 0.2974286\nQ15 0.3945511 0.3963730 0.3051340 1.0000000 0.2506681 0.4130468 0.3897974\nQ19 0.2853576 0.2809997 0.3479591 0.2506681 1.0000000 0.1999011 0.2452251\nQ23 0.3608919 0.2102096 0.1701522 0.4130468 0.1999011 1.0000000 0.2566352\nQ27 0.3484064 0.2953999 0.2974286 0.3897974 0.2452251 0.2566352 1.0000000\nQ31 0.3299510 0.4019467 0.3671049 0.4480359 0.3804564 0.3925590 0.2855325\n          Q31\nQ3  0.3299510\nQ7  0.4019467\nQ11 0.3671049\nQ15 0.4480359\nQ19 0.3804564\nQ23 0.3925590\nQ27 0.2855325\nQ31 1.0000000\n\n\nCódigo\n# Autodestructivo\ncor(autodestructivo)\n\n\n           Q4        Q8       Q12       Q16       Q20       Q24       Q28\nQ4  1.0000000 0.4659424 0.4125085 0.3313143 0.4417460 0.3942768 0.2305862\nQ8  0.4659424 1.0000000 0.4461332 0.4485728 0.6668889 0.3049158 0.2667078\nQ12 0.4125085 0.4461332 1.0000000 0.4302414 0.4807727 0.2612307 0.2578115\nQ16 0.3313143 0.4485728 0.4302414 1.0000000 0.4550186 0.2174461 0.1671081\nQ20 0.4417460 0.6668889 0.4807727 0.4550186 1.0000000 0.2981969 0.2213669\nQ24 0.3942768 0.3049158 0.2612307 0.2174461 0.2981969 1.0000000 0.1520322\nQ28 0.2305862 0.2667078 0.2578115 0.1671081 0.2213669 0.1520322 1.0000000\nQ32 0.4663633 0.5203096 0.4561579 0.4193331 0.4643564 0.3624751 0.2355325\n          Q32\nQ4  0.4663633\nQ8  0.5203096\nQ12 0.4561579\nQ16 0.4193331\nQ20 0.4643564\nQ24 0.3624751\nQ28 0.2355325\nQ32 1.0000000\n\n\nPodemos observar que todas las correlaciones son positivas, por lo que no quedaron ítems invertidos.\n\n\nEstimar consistencia interna\n\nAlfa de Chronbach\nPrimero, estimaremos la consistencia interna de cada dimensión con un alfa de Chronbach. El alfa de Chronbach, es un estadístico que permite estimar la fiabilidad de un test por consistencia interna. Su ventaja es que es fácil de estimar. Sus desventajas, sin embargo, son que:\n\nPuede aumentarse artificialmente incorporando ítems parecidos;\nAsume que el constructo es unidimensional;\nEs afectado por número de ítems, el número de alternativas de respuesta y la varianza del test (Domínguez-Lara & Merino-Soto, 2015).\n\nPara interpretarlo hay que considerar:\n\nMínimo para investigación básica exploratoria: > .7\nMínimo para investigación asociativa: > .8\nInvestigación con decisiones muy importantes: > .9 (Nunnally & Bernstein, 1994).\n\nA mayor valor, más consistente es la escala:\n\nConsideraremos el 0.6 como punto de corte.\n\n\n\n\n\n\n\nNota\n\n\n\nADVERTENCIA: el alfa de Chronbarch es para variables con nivel de medición intervalar. Lo óptimo para variables ordinales es Alfa Ordinal u Omega (Ventura-León & Caycho-Rodríguez, 2017).\n\n\nAsimismo, esperamos que la correlación de cada ítem respecto del total sea al menos de .4 (media) y, ojalá, de al menos .6 (alta). Ítems con correlaciones muy bajas podrían eliminarse, especialmente si el alfa de Chronbach aumenta en caso de que el ítem sea eliminado.\n\n\nCódigo\npsych::alpha(afiliativo)\n\n\n\nReliability analysis   \nCall: psych::alpha(x = afiliativo)\n\n  raw_alpha std.alpha G6(smc) average_r S/N    ase mean  sd median_r\n      0.84      0.85    0.84      0.41 5.6 0.0077    4 0.7     0.42\n\n    95% confidence boundaries \n         lower alpha upper\nFeldt     0.82  0.84  0.85\nDuhachek  0.82  0.84  0.85\n\n Reliability if an item is dropped:\n    raw_alpha std.alpha G6(smc) average_r S/N alpha se  var.r med.r\nQ1       0.82      0.83    0.82      0.40 4.7   0.0089 0.0092  0.39\nQ5       0.82      0.83    0.82      0.41 4.8   0.0089 0.0097  0.42\nQ9       0.84      0.84    0.84      0.44 5.4   0.0078 0.0071  0.45\nQ13      0.82      0.83    0.82      0.41 4.9   0.0086 0.0065  0.42\nQ17      0.80      0.82    0.81      0.39 4.4   0.0095 0.0071  0.37\nQ21      0.82      0.83    0.82      0.40 4.7   0.0088 0.0079  0.39\nQ25      0.82      0.82    0.81      0.40 4.7   0.0088 0.0071  0.42\nQ29      0.83      0.84    0.83      0.43 5.3   0.0081 0.0078  0.45\n\n Item statistics \n      n raw.r std.r r.cor r.drop mean   sd\nQ1  988  0.72  0.72  0.66   0.60  4.0 1.06\nQ5  988  0.71  0.70  0.65   0.60  3.6 1.03\nQ9  988  0.62  0.60  0.50   0.46  3.4 1.21\nQ13 988  0.66  0.69  0.64   0.56  4.5 0.84\nQ17 988  0.79  0.78  0.76   0.69  4.1 1.10\nQ21 988  0.70  0.72  0.67   0.61  4.4 0.85\nQ25 988  0.70  0.72  0.69   0.61  4.4 0.84\nQ29 988  0.65  0.62  0.54   0.50  3.7 1.18\n\nNon missing response frequency for each item\n       1    2    3    4    5 miss\nQ1  0.03 0.08 0.16 0.35 0.37    0\nQ5  0.04 0.10 0.27 0.38 0.20    0\nQ9  0.09 0.16 0.20 0.37 0.18    0\nQ13 0.01 0.03 0.07 0.27 0.62    0\nQ17 0.04 0.07 0.14 0.30 0.45    0\nQ21 0.01 0.03 0.09 0.29 0.58    0\nQ25 0.01 0.03 0.06 0.29 0.60    0\nQ29 0.06 0.11 0.20 0.34 0.28    0\n\n\nCódigo\npsych::alpha(autofortalecedor)\n\n\n\nReliability analysis   \nCall: psych::alpha(x = autofortalecedor)\n\n  raw_alpha std.alpha G6(smc) average_r S/N    ase mean   sd median_r\n      0.82      0.82    0.82      0.36 4.5 0.0085  3.4 0.75     0.34\n\n    95% confidence boundaries \n         lower alpha upper\nFeldt      0.8  0.82  0.84\nDuhachek   0.8  0.82  0.84\n\n Reliability if an item is dropped:\n    raw_alpha std.alpha G6(smc) average_r S/N alpha se var.r med.r\nQ2       0.80      0.80    0.79      0.36 3.9   0.0098 0.016  0.32\nQ6       0.81      0.81    0.80      0.38 4.3   0.0091 0.015  0.34\nQ10      0.79      0.78    0.78      0.34 3.6   0.0103 0.011  0.33\nQ14      0.78      0.78    0.78      0.34 3.6   0.0104 0.015  0.29\nQ18      0.79      0.79    0.78      0.35 3.7   0.0102 0.012  0.33\nQ22      0.82      0.82    0.82      0.40 4.6   0.0084 0.012  0.41\nQ26      0.79      0.79    0.78      0.34 3.7   0.0102 0.014  0.32\nQ30      0.82      0.81    0.81      0.39 4.4   0.0088 0.014  0.38\n\n Item statistics \n      n raw.r std.r r.cor r.drop mean   sd\nQ2  988  0.68  0.68  0.62   0.57  3.3 1.09\nQ6  988  0.57  0.60  0.52   0.45  4.2 0.94\nQ10 988  0.75  0.74  0.71   0.64  2.9 1.18\nQ14 988  0.76  0.74  0.70   0.64  3.3 1.24\nQ18 988  0.73  0.72  0.69   0.62  2.8 1.17\nQ22 988  0.54  0.53  0.41   0.37  3.0 1.19\nQ26 988  0.73  0.73  0.69   0.62  3.6 1.13\nQ30 988  0.55  0.57  0.48   0.41  4.0 1.05\n\nNon missing response frequency for each item\n       1    2    3    4    5 miss\nQ2  0.06 0.16 0.30 0.33 0.15    0\nQ6  0.01 0.05 0.13 0.35 0.45    0\nQ10 0.14 0.25 0.29 0.23 0.09    0\nQ14 0.09 0.19 0.25 0.27 0.20    0\nQ18 0.16 0.28 0.28 0.21 0.07    0\nQ22 0.12 0.26 0.27 0.24 0.11    0\nQ26 0.06 0.12 0.26 0.35 0.22    0\nQ30 0.02 0.09 0.16 0.35 0.39    0\n\n\nCódigo\npsych::alpha(agresivo)\n\n\n\nReliability analysis   \nCall: psych::alpha(x = agresivo)\n\n  raw_alpha std.alpha G6(smc) average_r S/N  ase mean   sd median_r\n      0.79      0.79    0.78      0.32 3.7 0.01  2.9 0.78     0.31\n\n    95% confidence boundaries \n         lower alpha upper\nFeldt     0.77  0.79  0.81\nDuhachek  0.77  0.79  0.81\n\n Reliability if an item is dropped:\n    raw_alpha std.alpha G6(smc) average_r S/N alpha se  var.r med.r\nQ3       0.77      0.76    0.75      0.32 3.2    0.011 0.0061  0.31\nQ7       0.77      0.77    0.75      0.32 3.3    0.011 0.0054  0.33\nQ11      0.77      0.77    0.75      0.33 3.4    0.011 0.0053  0.33\nQ15      0.75      0.75    0.73      0.30 3.0    0.012 0.0041  0.30\nQ19      0.78      0.78    0.76      0.33 3.4    0.011 0.0051  0.33\nQ23      0.77      0.77    0.75      0.33 3.4    0.011 0.0033  0.32\nQ27      0.77      0.77    0.75      0.32 3.4    0.011 0.0059  0.33\nQ31      0.75      0.75    0.73      0.30 3.0    0.012 0.0046  0.30\n\n Item statistics \n      n raw.r std.r r.cor r.drop mean  sd\nQ3  988  0.64  0.64  0.57   0.50  3.1 1.2\nQ7  988  0.61  0.63  0.55   0.49  2.7 1.1\nQ11 988  0.61  0.60  0.52   0.46  2.7 1.2\nQ15 988  0.72  0.71  0.66   0.58  2.6 1.3\nQ19 988  0.59  0.59  0.49   0.44  3.2 1.2\nQ23 988  0.59  0.59  0.51   0.44  3.2 1.2\nQ27 988  0.62  0.61  0.53   0.47  2.3 1.3\nQ31 988  0.71  0.71  0.66   0.59  3.2 1.3\n\nNon missing response frequency for each item\n       1    2    3    4    5 miss\nQ3  0.10 0.21 0.30 0.27 0.11    0\nQ7  0.13 0.33 0.32 0.16 0.07    0\nQ11 0.17 0.32 0.19 0.22 0.09    0\nQ15 0.30 0.22 0.20 0.19 0.10    0\nQ19 0.10 0.19 0.24 0.30 0.17    0\nQ23 0.09 0.21 0.28 0.28 0.15    0\nQ27 0.36 0.28 0.15 0.13 0.07    0\nQ31 0.10 0.22 0.24 0.22 0.20    0\n\n\nCódigo\npsych::alpha(autodestructivo)\n\n\n\nReliability analysis   \nCall: psych::alpha(x = autodestructivo)\n\n  raw_alpha std.alpha G6(smc) average_r S/N    ase mean   sd median_r\n      0.82      0.82    0.82      0.37 4.6 0.0086  2.7 0.79      0.4\n\n    95% confidence boundaries \n         lower alpha upper\nFeldt      0.8  0.82  0.84\nDuhachek   0.8  0.82  0.84\n\n Reliability if an item is dropped:\n    raw_alpha std.alpha G6(smc) average_r S/N alpha se  var.r med.r\nQ4       0.79      0.80    0.79      0.36 3.9   0.0100 0.0179  0.36\nQ8       0.78      0.78    0.77      0.34 3.6   0.0107 0.0122  0.36\nQ12      0.79      0.80    0.79      0.36 3.9   0.0100 0.0175  0.36\nQ16      0.80      0.81    0.80      0.37 4.1   0.0096 0.0161  0.39\nQ20      0.78      0.79    0.77      0.35 3.7   0.0104 0.0123  0.36\nQ24      0.82      0.82    0.81      0.39 4.6   0.0089 0.0151  0.44\nQ28      0.83      0.83    0.82      0.42 5.0   0.0081 0.0096  0.44\nQ32      0.79      0.79    0.78      0.35 3.8   0.0104 0.0166  0.33\n\n Item statistics \n      n raw.r std.r r.cor r.drop mean  sd\nQ4  988  0.70  0.70  0.64   0.58  2.8 1.2\nQ8  988  0.77  0.77  0.76   0.67  2.5 1.2\nQ12 988  0.70  0.70  0.64   0.58  3.0 1.2\nQ16 988  0.65  0.65  0.57   0.52  2.9 1.2\nQ20 988  0.75  0.75  0.73   0.65  2.1 1.1\nQ24 988  0.55  0.56  0.45   0.41  2.4 1.1\nQ28 988  0.49  0.47  0.34   0.31  3.2 1.3\nQ32 988  0.74  0.73  0.69   0.63  2.8 1.2\n\nNon missing response frequency for each item\n       1    2    3    4    5 miss\nQ4  0.14 0.28 0.29 0.21 0.08    0\nQ8  0.23 0.31 0.22 0.19 0.06    0\nQ12 0.14 0.23 0.27 0.26 0.10    0\nQ16 0.14 0.28 0.25 0.24 0.09    0\nQ20 0.37 0.34 0.16 0.10 0.03    0\nQ24 0.21 0.36 0.25 0.12 0.06    0\nQ28 0.13 0.18 0.22 0.28 0.19    0\nQ32 0.18 0.22 0.29 0.23 0.09    0\n\n\nCódigo\n# Para toda la escala \npsych::alpha(data %>% select(1:32))\n\n\n\nReliability analysis   \nCall: psych::alpha(x = data %>% select(1:32))\n\n  raw_alpha std.alpha G6(smc) average_r S/N    ase mean  sd median_r\n      0.86      0.87     0.9      0.17 6.4 0.0063  3.2 0.5     0.14\n\n    95% confidence boundaries \n         lower alpha upper\nFeldt     0.85  0.86  0.87\nDuhachek  0.85  0.86  0.87\n\n Reliability if an item is dropped:\n    raw_alpha std.alpha G6(smc) average_r S/N alpha se var.r med.r\nQ1       0.86      0.86     0.9      0.17 6.1   0.0066 0.019  0.14\nQ2       0.86      0.86     0.9      0.17 6.2   0.0065 0.019  0.14\nQ3       0.86      0.86     0.9      0.17 6.2   0.0066 0.020  0.13\nQ4       0.86      0.86     0.9      0.17 6.3   0.0065 0.019  0.15\nQ5       0.86      0.86     0.9      0.16 6.1   0.0066 0.019  0.13\nQ6       0.86      0.86     0.9      0.17 6.2   0.0065 0.019  0.14\nQ7       0.86      0.87     0.9      0.17 6.4   0.0063 0.019  0.15\nQ8       0.86      0.86     0.9      0.17 6.2   0.0065 0.019  0.14\nQ9       0.86      0.86     0.9      0.17 6.2   0.0065 0.020  0.13\nQ10      0.86      0.86     0.9      0.17 6.1   0.0066 0.019  0.13\nQ11      0.86      0.87     0.9      0.17 6.4   0.0063 0.019  0.15\nQ12      0.86      0.86     0.9      0.17 6.2   0.0065 0.019  0.14\nQ13      0.86      0.86     0.9      0.17 6.1   0.0065 0.019  0.14\nQ14      0.86      0.86     0.9      0.16 6.1   0.0066 0.019  0.13\nQ15      0.86      0.86     0.9      0.17 6.3   0.0065 0.019  0.14\nQ16      0.86      0.86     0.9      0.17 6.2   0.0065 0.019  0.14\nQ17      0.86      0.86     0.9      0.16 6.1   0.0066 0.018  0.13\nQ18      0.86      0.86     0.9      0.17 6.2   0.0065 0.019  0.14\nQ19      0.86      0.86     0.9      0.16 6.1   0.0066 0.020  0.13\nQ20      0.86      0.86     0.9      0.17 6.2   0.0065 0.018  0.14\nQ21      0.86      0.86     0.9      0.17 6.2   0.0065 0.018  0.13\nQ22      0.86      0.86     0.9      0.17 6.3   0.0064 0.020  0.14\nQ23      0.86      0.86     0.9      0.17 6.3   0.0064 0.019  0.15\nQ24      0.86      0.87     0.9      0.17 6.5   0.0063 0.018  0.15\nQ25      0.86      0.86     0.9      0.17 6.2   0.0065 0.018  0.14\nQ26      0.86      0.86     0.9      0.16 6.1   0.0066 0.019  0.13\nQ27      0.86      0.86     0.9      0.17 6.4   0.0064 0.019  0.15\nQ28      0.86      0.86     0.9      0.17 6.2   0.0065 0.020  0.13\nQ29      0.86      0.86     0.9      0.17 6.3   0.0064 0.019  0.14\nQ30      0.86      0.87     0.9      0.17 6.4   0.0063 0.019  0.15\nQ31      0.86      0.86     0.9      0.17 6.3   0.0064 0.019  0.15\nQ32      0.86      0.86     0.9      0.17 6.2   0.0066 0.019  0.13\n\n Item statistics \n      n raw.r std.r r.cor r.drop mean   sd\nQ1  988  0.49  0.51  0.49   0.44  4.0 1.06\nQ2  988  0.47  0.47  0.45   0.41  3.3 1.09\nQ3  988  0.49  0.48  0.45   0.43  3.1 1.16\nQ4  988  0.43  0.42  0.39   0.36  2.8 1.16\nQ5  988  0.52  0.53  0.52   0.47  3.6 1.03\nQ6  988  0.45  0.48  0.45   0.41  4.2 0.94\nQ7  988  0.30  0.28  0.24   0.23  2.7 1.09\nQ8  988  0.49  0.48  0.47   0.43  2.5 1.19\nQ9  988  0.44  0.45  0.42   0.38  3.4 1.21\nQ10 988  0.51  0.51  0.50   0.45  2.9 1.18\nQ11 988  0.31  0.29  0.25   0.24  2.7 1.24\nQ12 988  0.45  0.45  0.43   0.39  3.0 1.21\nQ13 988  0.48  0.51  0.50   0.44  4.5 0.84\nQ14 988  0.52  0.53  0.52   0.46  3.3 1.24\nQ15 988  0.44  0.41  0.39   0.36  2.6 1.34\nQ16 988  0.45  0.44  0.42   0.39  2.9 1.19\nQ17 988  0.54  0.56  0.56   0.49  4.1 1.10\nQ18 988  0.45  0.45  0.44   0.39  2.8 1.17\nQ19 988  0.54  0.54  0.52   0.49  3.2 1.23\nQ20 988  0.45  0.44  0.43   0.40  2.1 1.09\nQ21 988  0.46  0.49  0.48   0.42  4.4 0.85\nQ22 988  0.38  0.38  0.34   0.31  3.0 1.19\nQ23 988  0.37  0.36  0.32   0.30  3.2 1.18\nQ24 988  0.23  0.22  0.18   0.16  2.4 1.12\nQ25 988  0.46  0.49  0.48   0.42  4.4 0.84\nQ26 988  0.52  0.52  0.51   0.46  3.6 1.13\nQ27 988  0.35  0.33  0.29   0.28  2.3 1.27\nQ28 988  0.49  0.48  0.45   0.42  3.2 1.30\nQ29 988  0.38  0.39  0.36   0.31  3.7 1.18\nQ30 988  0.29  0.30  0.26   0.22  4.0 1.05\nQ31 988  0.40  0.38  0.36   0.33  3.2 1.28\nQ32 988  0.50  0.49  0.47   0.44  2.8 1.22\n\nNon missing response frequency for each item\n       1    2    3    4    5 miss\nQ1  0.03 0.08 0.16 0.35 0.37    0\nQ2  0.06 0.16 0.30 0.33 0.15    0\nQ3  0.10 0.21 0.30 0.27 0.11    0\nQ4  0.14 0.28 0.29 0.21 0.08    0\nQ5  0.04 0.10 0.27 0.38 0.20    0\nQ6  0.01 0.05 0.13 0.35 0.45    0\nQ7  0.13 0.33 0.32 0.16 0.07    0\nQ8  0.23 0.31 0.22 0.19 0.06    0\nQ9  0.09 0.16 0.20 0.37 0.18    0\nQ10 0.14 0.25 0.29 0.23 0.09    0\nQ11 0.17 0.32 0.19 0.22 0.09    0\nQ12 0.14 0.23 0.27 0.26 0.10    0\nQ13 0.01 0.03 0.07 0.27 0.62    0\nQ14 0.09 0.19 0.25 0.27 0.20    0\nQ15 0.30 0.22 0.20 0.19 0.10    0\nQ16 0.14 0.28 0.25 0.24 0.09    0\nQ17 0.04 0.07 0.14 0.30 0.45    0\nQ18 0.16 0.28 0.28 0.21 0.07    0\nQ19 0.10 0.19 0.24 0.30 0.17    0\nQ20 0.37 0.34 0.16 0.10 0.03    0\nQ21 0.01 0.03 0.09 0.29 0.58    0\nQ22 0.12 0.26 0.27 0.24 0.11    0\nQ23 0.09 0.21 0.28 0.28 0.15    0\nQ24 0.21 0.36 0.25 0.12 0.06    0\nQ25 0.01 0.03 0.06 0.29 0.60    0\nQ26 0.06 0.12 0.26 0.35 0.22    0\nQ27 0.36 0.28 0.15 0.13 0.07    0\nQ28 0.13 0.18 0.22 0.28 0.19    0\nQ29 0.06 0.11 0.20 0.34 0.28    0\nQ30 0.02 0.09 0.16 0.35 0.39    0\nQ31 0.10 0.22 0.24 0.22 0.20    0\nQ32 0.18 0.22 0.29 0.23 0.09    0\n\n\n\n\nAlfa Ordinal\nComo se señaló, el alfa de Chronbach está diseñado para variables continuas. Por ello, podemos calcular el alfa ordinal para las puntuaciones de cada ítem. Para esto, utilizaremos la función ordinal_alpha()de jogRu, que estima el alfa ordinal a partir de correlación policórica (según lo propuesto por Zumbo et al.(2007)).\n\n\nCódigo\njogRu::ordinal_alpha(afiliativo)\n\n\n\nReliability analysis   \nCall: psych::alpha(x = psych::polychoric(x)$rho)\n\n  raw_alpha std.alpha G6(smc) average_r S/N median_r\n      0.89      0.89    0.89       0.5   8     0.49\n\n    95% confidence boundaries \n      lower alpha upper\nFeldt  0.71  0.89  0.97\n\n Reliability if an item is dropped:\n    raw_alpha std.alpha G6(smc) average_r S/N  var.r med.r\nQ1       0.87      0.87    0.87      0.49 6.8 0.0120  0.47\nQ5       0.88      0.88    0.87      0.50 7.0 0.0133  0.49\nQ9       0.89      0.89    0.89      0.53 7.9 0.0090  0.55\nQ13      0.87      0.87    0.87      0.50 6.9 0.0085  0.49\nQ17      0.86      0.86    0.86      0.48 6.3 0.0100  0.45\nQ21      0.87      0.87    0.87      0.49 6.7 0.0104  0.47\nQ25      0.87      0.87    0.86      0.48 6.5 0.0086  0.49\nQ29      0.88      0.88    0.88      0.52 7.7 0.0106  0.55\n\n Item statistics \n       r r.cor r.drop\nQ1  0.77  0.72   0.68\nQ5  0.74  0.69   0.65\nQ9  0.63  0.55   0.52\nQ13 0.76  0.73   0.67\nQ17 0.83  0.81   0.77\nQ21 0.79  0.76   0.71\nQ25 0.81  0.79   0.73\nQ29 0.67  0.60   0.56\n\n\nCódigo\njogRu::ordinal_alpha(autofortalecedor)\n\n\n\nReliability analysis   \nCall: psych::alpha(x = psych::polychoric(x)$rho)\n\n  raw_alpha std.alpha G6(smc) average_r S/N median_r\n      0.85      0.85    0.85      0.41 5.5     0.37\n\n    95% confidence boundaries \n      lower alpha upper\nFeldt   0.6  0.85  0.96\n\n Reliability if an item is dropped:\n    raw_alpha std.alpha G6(smc) average_r S/N var.r med.r\nQ2       0.83      0.83    0.83      0.40 4.7 0.019  0.37\nQ6       0.84      0.84    0.83      0.42 5.1 0.016  0.37\nQ10      0.82      0.82    0.81      0.39 4.4 0.014  0.37\nQ14      0.81      0.81    0.82      0.38 4.4 0.018  0.34\nQ18      0.82      0.82    0.81      0.39 4.5 0.014  0.37\nQ22      0.85      0.85    0.85      0.45 5.6 0.013  0.45\nQ26      0.82      0.82    0.82      0.39 4.4 0.016  0.37\nQ30      0.84      0.84    0.84      0.43 5.3 0.016  0.43\n\n Item statistics \n       r r.cor r.drop\nQ2  0.71  0.65   0.60\nQ6  0.64  0.57   0.51\nQ10 0.77  0.74   0.67\nQ14 0.77  0.74   0.68\nQ18 0.75  0.72   0.65\nQ22 0.54  0.43   0.40\nQ26 0.76  0.73   0.67\nQ30 0.61  0.53   0.47\n\n\nCódigo\njogRu::ordinal_alpha(agresivo)\n\n\n\nReliability analysis   \nCall: psych::alpha(x = psych::polychoric(x)$rho)\n\n  raw_alpha std.alpha G6(smc) average_r S/N median_r\n      0.82      0.82    0.81      0.36 4.5     0.35\n\n    95% confidence boundaries \n      lower alpha upper\nFeldt  0.53  0.82  0.96\n\n Reliability if an item is dropped:\n    raw_alpha std.alpha G6(smc) average_r S/N  var.r med.r\nQ3       0.80      0.80    0.78      0.36 3.9 0.0078  0.35\nQ7       0.80      0.80    0.79      0.36 4.0 0.0068  0.37\nQ11      0.80      0.80    0.79      0.37 4.0 0.0067  0.37\nQ15      0.78      0.78    0.77      0.34 3.6 0.0051  0.34\nQ19      0.81      0.81    0.79      0.37 4.1 0.0065  0.37\nQ23      0.81      0.81    0.79      0.37 4.1 0.0040  0.36\nQ27      0.80      0.80    0.79      0.36 4.0 0.0076  0.37\nQ31      0.78      0.78    0.77      0.34 3.6 0.0062  0.34\n\n Item statistics \n       r r.cor r.drop\nQ3  0.67  0.60   0.54\nQ7  0.65  0.58   0.52\nQ11 0.63  0.55   0.49\nQ15 0.74  0.71   0.64\nQ19 0.61  0.52   0.47\nQ23 0.61  0.53   0.47\nQ27 0.65  0.57   0.52\nQ31 0.74  0.70   0.63\n\n\nCódigo\njogRu::ordinal_alpha(autodestructivo)\n\n\n\nReliability analysis   \nCall: psych::alpha(x = psych::polychoric(x)$rho)\n\n  raw_alpha std.alpha G6(smc) average_r S/N median_r\n      0.85      0.85    0.85      0.41 5.6     0.45\n\n    95% confidence boundaries \n      lower alpha upper\nFeldt  0.61  0.85  0.96\n\n Reliability if an item is dropped:\n    raw_alpha std.alpha G6(smc) average_r S/N var.r med.r\nQ4       0.83      0.83    0.82      0.40 4.8 0.022  0.42\nQ8       0.81      0.81    0.80      0.38 4.4 0.015  0.42\nQ12      0.83      0.83    0.82      0.40 4.8 0.022  0.42\nQ16      0.83      0.83    0.83      0.42 5.0 0.020  0.44\nQ20      0.81      0.81    0.80      0.39 4.4 0.015  0.42\nQ24      0.85      0.85    0.84      0.44 5.5 0.019  0.50\nQ28      0.86      0.86    0.85      0.47 6.2 0.011  0.50\nQ32      0.82      0.82    0.82      0.39 4.6 0.021  0.37\n\n Item statistics \n       r r.cor r.drop\nQ4  0.73  0.68   0.62\nQ8  0.80  0.80   0.73\nQ12 0.73  0.68   0.63\nQ16 0.68  0.61   0.56\nQ20 0.80  0.79   0.72\nQ24 0.59  0.49   0.45\nQ28 0.49  0.36   0.33\nQ32 0.77  0.73   0.67\n\n\nCódigo\n# Para toda la escala \njogRu::ordinal_alpha(data %>% select(1:32))\n\n\n\nReliability analysis   \nCall: psych::alpha(x = psych::polychoric(x)$rho)\n\n  raw_alpha std.alpha G6(smc) average_r S/N median_r\n      0.88      0.88    0.93      0.19 7.7     0.16\n\n    95% confidence boundaries \n      lower alpha upper\nFeldt  0.82  0.88  0.94\n\n Reliability if an item is dropped:\n    raw_alpha std.alpha G6(smc) average_r S/N var.r med.r\nQ1       0.88      0.88    0.92      0.19 7.3 0.025  0.16\nQ2       0.88      0.88    0.92      0.19 7.4 0.026  0.16\nQ3       0.88      0.88    0.92      0.19 7.4 0.027  0.16\nQ4       0.88      0.88    0.92      0.19 7.5 0.026  0.17\nQ5       0.88      0.88    0.92      0.19 7.3 0.026  0.16\nQ6       0.88      0.88    0.92      0.19 7.3 0.026  0.16\nQ7       0.89      0.89    0.93      0.20 7.7 0.025  0.17\nQ8       0.88      0.88    0.92      0.19 7.4 0.025  0.16\nQ9       0.88      0.88    0.92      0.19 7.4 0.026  0.16\nQ10      0.88      0.88    0.92      0.19 7.3 0.026  0.16\nQ11      0.88      0.88    0.93      0.20 7.7 0.026  0.17\nQ12      0.88      0.88    0.92      0.19 7.4 0.026  0.16\nQ13      0.88      0.88    0.92      0.19 7.2 0.025  0.16\nQ14      0.88      0.88    0.92      0.19 7.3 0.025  0.16\nQ15      0.88      0.88    0.92      0.19 7.5 0.026  0.17\nQ16      0.88      0.88    0.92      0.19 7.4 0.026  0.16\nQ17      0.88      0.88    0.92      0.19 7.2 0.025  0.16\nQ18      0.88      0.88    0.92      0.19 7.4 0.026  0.16\nQ19      0.88      0.88    0.92      0.19 7.3 0.027  0.15\nQ20      0.88      0.88    0.92      0.19 7.4 0.025  0.17\nQ21      0.88      0.88    0.92      0.19 7.3 0.025  0.16\nQ22      0.88      0.88    0.93      0.20 7.5 0.027  0.17\nQ23      0.88      0.88    0.92      0.20 7.6 0.026  0.17\nQ24      0.89      0.89    0.93      0.20 7.8 0.025  0.17\nQ25      0.88      0.88    0.92      0.19 7.3 0.024  0.16\nQ26      0.88      0.88    0.92      0.19 7.3 0.026  0.16\nQ27      0.88      0.88    0.93      0.20 7.6 0.026  0.17\nQ28      0.88      0.88    0.92      0.19 7.4 0.027  0.16\nQ29      0.88      0.88    0.92      0.19 7.5 0.025  0.16\nQ30      0.88      0.88    0.92      0.20 7.6 0.026  0.17\nQ31      0.88      0.88    0.92      0.20 7.5 0.026  0.17\nQ32      0.88      0.88    0.92      0.19 7.4 0.026  0.16\n\n Item statistics \n       r r.cor r.drop\nQ1  0.56  0.55   0.51\nQ2  0.49  0.47   0.44\nQ3  0.51  0.49   0.46\nQ4  0.43  0.41   0.38\nQ5  0.56  0.55   0.51\nQ6  0.52  0.51   0.47\nQ7  0.29  0.25   0.22\nQ8  0.50  0.49   0.45\nQ9  0.48  0.45   0.43\nQ10 0.53  0.52   0.48\nQ11 0.31  0.28   0.25\nQ12 0.46  0.44   0.41\nQ13 0.58  0.58   0.53\nQ14 0.56  0.55   0.51\nQ15 0.43  0.41   0.37\nQ16 0.46  0.44   0.40\nQ17 0.62  0.62   0.58\nQ18 0.47  0.46   0.42\nQ19 0.57  0.55   0.52\nQ20 0.46  0.45   0.40\nQ21 0.56  0.56   0.51\nQ22 0.39  0.36   0.33\nQ23 0.37  0.34   0.31\nQ24 0.22  0.19   0.16\nQ25 0.57  0.58   0.53\nQ26 0.55  0.54   0.50\nQ27 0.34  0.31   0.28\nQ28 0.50  0.47   0.45\nQ29 0.42  0.39   0.36\nQ30 0.32  0.29   0.26\nQ31 0.40  0.38   0.34\nQ32 0.51  0.50   0.46"
  },
  {
    "objectID": "practicos/03-content.html",
    "href": "practicos/03-content.html",
    "title": "Práctico R 3. Repaso construcción de indices y escalas",
    "section": "",
    "text": "Para el taller práctico de hoy utilizaremos la base de datos del estudio Longitudinal Social de Chile, realizado por el Centro de estudios del conflicto y la cohesión social COES.\nEl Estudio Longitudinal Social del Chile ELSOC, único en Chile y América Latina, consiste en encuestar a casi 3.000 chilenos, anualmente, a lo largo de una década. ELSOC ha sido diseñado para evaluar la manera cómo piensan, sienten y se comportan los chilenos en torno a un conjunto de temas referidos al conflicto y la cohesión social en Chile. La población objetivo son hombres y mujeres entre 15 y 75 años de edad con un alcance nacional, donde se obtuvo una muestra inicial de 2927 casos en el año 2016 y mantiene 1728 en 2022."
  },
  {
    "objectID": "practicos/03-content.html#cargar-librerías",
    "href": "practicos/03-content.html#cargar-librerías",
    "title": "Práctico R 3. Repaso construcción de indices y escalas",
    "section": "Cargar librerías",
    "text": "Cargar librerías\nLas librerías que utilizaremos esta sesión son las siguientes:\n\n\nCódigo\n# install.packages(\"pacman\") # Cargar sólo si no la tenemos instalada\n#library(pacman)\npacman::p_load(tidyverse, # conjunto de paquetes, sobre todo dplyr y ggplot2\n               car,       # para recodificar\n               psych,     # para Alfa de Chronbach\n               sjmisc    # para descriptivos\n               )\n\noptions(scipen = 999) # para desactivar notacion cientifica\nrm(list = ls())       # para limpiar el entorno de trabajo"
  },
  {
    "objectID": "practicos/03-content.html#datos-y-variables",
    "href": "practicos/03-content.html#datos-y-variables",
    "title": "Práctico R 3. Repaso construcción de indices y escalas",
    "section": "Datos y variables",
    "text": "Datos y variables\nComo mencionamos, utilizaremos la base de datos de ELSOC, específicamente el módulo de Satisfacción residencial. Este módulo incluye dos conceptos:\n\nSatisfacción con la vivienda (2 items)\n\n\nTamaño de la vivienda\nCalidad de la vivienda\n\n\nsatisfacción con el barrio (8 items):\n\n\nconectividad del barrio\nproximidad con el comercio\nproximidad con colegios\nproximidad con familiares\nproximidad con la principal actividad de trabajo\nlimpieza del barrio\ncantidad de áreas verdes\nseguridad del barrio.\n\n\nCargar base de datos\n\n\nCódigo\nload(url(\"https://dataverse.harvard.edu/api/access/datafile/7245118\")) #Cargar base de datos\n\n\n\n\nVisualización de datos\n\n\nCódigo\ndim(elsoc_long_2016_2022.2)\n\n\n[1] 18035   750\n\n\nDebido a la naturaleza longitudinal de ELSOC, la base de datos contiene 18035 casos (las mismas personas durante 6 años) y 750 variables (las mismas variables en 6 periodos distintos). Por lo tanto, para simplificar el proceso de análisis de este práctico trabajaremos solo con los casos y variables de quienes participaron en la primera ola (2016)"
  },
  {
    "objectID": "practicos/03-content.html#filtrar-base-de-datos",
    "href": "practicos/03-content.html#filtrar-base-de-datos",
    "title": "Práctico R 3. Repaso construcción de indices y escalas",
    "section": "Filtrar base de datos",
    "text": "Filtrar base de datos\n\n\nCódigo\ntable(elsoc_long_2016_2022.2$ola)\n\n\n\n   1    2    3    4    5    6 \n2927 2473 3748 3417 2740 2730 \n\n\nCódigo\ndata <- elsoc_long_2016_2022.2 %>% filter(ola==1) %>%  # Seleccionamos solo los casos de la ola 1\n  select(t06_01, t06_02, t06_03, t06_04, t06_05, t06_06, t06_07, t06_07, t06_08, #satisfacción con el barrio\n         t07_01, t07_02) # satisfacción con la vivienda\n\nhead(data)\n\n\n  t06_01 t06_02 t06_03 t06_04 t06_05 t06_06 t06_07 t06_08 t07_01 t07_02\n1      2      5      1      1      3      4      3      5      4      4\n2      3      3      2      3      4      4      4      4      4      4\n3      3      2      3      3      3      3      4      1      4      4\n4      1      3      2      2      2      3      4      4      4      4\n5      1      3      2      2      2      4      3      3      4      4\n6      1      2      2      3      4      4      4      4      3      3\n\n\nCódigo\ntable(data$t06_01)\n\n\n\n-888    1    2    3    4    5 \n   1  218  722  505 1306  175 \n\n\nCódigo\ntable(data$t06_05)\n\n\n\n-999 -888    1    2    3    4    5 \n  20   13  119  537  338 1649  251 \n\n\nCódigo\ntable(data$t07_01)\n\n\n\n-888    1    2    3    4    5 \n   1   98  539  190 1753  346 \n\n\nPodemos ver que tenemos valores de 1 a 5, que según el libro de códigos corresponden a: Totalmente insatisfecho | Insatisfecho | Ni satisfecho ni insatisfecho | Satisfecho | Totalmente satisfecho.\nY además valores -999 y -888 que corresponde a “No sabe” y “No responde”.\n\nRecodificar\nRecodificamos los valores -888 en NA\n\n\nCódigo\ndata = data %>% \n  set_na(., na = c(-888, -999)) %>% \n  na.omit()"
  },
  {
    "objectID": "practicos/03-content.html#medición-de-satisfacción-residencial-con-índice-no-ponderado",
    "href": "practicos/03-content.html#medición-de-satisfacción-residencial-con-índice-no-ponderado",
    "title": "Práctico R 3. Repaso construcción de indices y escalas",
    "section": "Medición de satisfacción residencial con índice no ponderado",
    "text": "Medición de satisfacción residencial con índice no ponderado\nCon la función mutate creamos una nueva variable que contenga el promedio simple de indicadores (suponinendo que cada item tiene el mismo peso).\n\n\nCódigo\ndata = data %>% \n  rowwise() %>%\n  mutate(satisfaccion_nopond = mean(c(t06_01, t06_02, t06_03, t06_04, t06_05, t06_06, t06_07, t06_07, t06_08, \n                                      t07_01, t07_02))\n         ) %>% \n  ungroup()\n\n\n\n\nCódigo\nsummary(data$satisfaccion_nopond)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.000   3.182   3.545   3.489   3.909   5.000"
  },
  {
    "objectID": "practicos/03-content.html#medición-de-satisfacción-residencial-con-índice-ponderado",
    "href": "practicos/03-content.html#medición-de-satisfacción-residencial-con-índice-ponderado",
    "title": "Práctico R 3. Repaso construcción de indices y escalas",
    "section": "Medición de satisfacción residencial con índice ponderado",
    "text": "Medición de satisfacción residencial con índice ponderado\nsi consideramos la dimensión de satisfacción con la vivienda como un indicador de mayor relevancia, podríamos suponer que ambos items de esta dimensión (tamaño y calidad) tienen el mismo peso que los 8 items de satisfacción con el barrio (es decir, que mientras cada item de satisfacción con el barrio equivale a un 6.25%, los items de satisfacción con la vivienda equivalen a un 25% cada uno).\nPara estimar este índnice, primero separamos los items por dimensión:\n\n\nCódigo\ndata = data %>% \n  rowwise() %>%\n  mutate(barrio = mean(c(t06_01, t06_02, t06_03, t06_04, t06_05, t06_06, t06_07, t06_07, t06_08)),\n         vivienda = mean(c(t07_01, t07_02))\n         ) %>% \n  ungroup()\n\n\nLuego, estimamos el índice otorgándole un 50% de peso a cada dimensión:\n\n\nCódigo\ndata = data %>% \n  rowwise() %>%\n  mutate(satisfaccion_pond = (barrio*0.5) + (vivienda*0.5)) %>%  \n  ungroup()\n\n\n\n\nCódigo\nsummary(data$satisfaccion_pond)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.000   3.194   3.667   3.537   3.944   5.000 \n\n\nPodemos comparar:\nindice ponderado:\n\n\nCódigo\nsummary(data$satisfaccion_pond)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.000   3.194   3.667   3.537   3.944   5.000 \n\n\nindice no ponderado:\n\n\nCódigo\nsummary(data$satisfaccion_nopond)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.000   3.182   3.545   3.489   3.909   5.000"
  },
  {
    "objectID": "practicos/index.html",
    "href": "practicos/index.html",
    "title": "Actividades en R",
    "section": "",
    "text": "En construcción"
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Planificación",
    "section": "",
    "text": "Los tres componentes centrales del curso son las clases teóricas, los talleres y los prácticos en R. Las clases se realizarán los días jueves 10:15 a 11:45 en sala B01 del aulario B. Los talleres y actividades en R se realizarán el mismo día en el horario de 12:00 a 13:30.\n\nClases ( ): Lecturas, documentos de presentación y sesiones teóricas\nTalleres y actividades en R (): Actividades prácticas a desarrollar en el segundo bloque de la clase, según programación al final de esta página.\nLecturas (): Llegar a la clase con los textos leídos.\n\n\n\n\n\n Clases\n Talleres y prácticos en R\n Lecturas y material adicional\n\n\n\n\n Agosto \n\n\n\n\n\nJueves 10\nUnidad 1: Formulación y diseño; Definición de conceptos y medición\n\n- Leer detalladamente programa del curso\n\n\nJueves 17\nNo hay clases\n\n\n\n\nJueves 24\nUnidad 1: instrumentos; tipos de investigaciones; limitaciones y potencialidad de inv. cuantitativa\nTaller 1\n\n\n\nJueves 31\nUnidad 2: conceptos e indicadores sociales; construcción de indicadores.\n-\n\n\n\n Septiembre \n\n\n\n\n\nJueves 07\nUnidad 2: Ejemplo concretos: indicadores de género (presentadora invitada: Jacinta Girardi ODEGI)\nTaller 2\n\n\n\nJueves 14\nReceso\n\n\n\n\nJueves 21\nUnidad 3: fundamentos construcción de índices; ponderación\nTaller 3\n\n\n\nJueves 28\nPrueba 1\n\n\n\n\n Octubre \n\n\n\n\n\nJueves 05\nUnidad 3: confiabilidad y validez; ejemplos de índices.\nActividad en R 1\n\n\n\nJueves 12\nUnidad 4: fundamentos en la construcción de escalas; Escala de Likert.\nTaller 4\n\n\n\nJueves 19\nUnidad 4: Escalas sumatorias; confiabilidad y validez\nActividad en R 2\n\n\n\nJueves 26\nUnidad 4: Ejemplos construcción de escalas sumatorias.\nActividad en R 3\n\n\n\n Noviembre \n\n\n\n\n\nJueves 02\nReceso. Semana de trabajo autónomo\n\n\n\n\nJueves 09\nUnidad 5: Encuestas y cuestionarios: usos, potencialidades y limitaciones.\nTaller 5\nEntrega de trabajo 1: Martes 7 de noviembre 18:00\n\n\nJueves 16\nTipos de encuestas; tipos de preguntas; ejemplos.\nActividad de avance trabajo 2\n\n\n\nJueves 23\nTipos de encuestas; tipos de preguntas; ejemplos.\nTaller 6\n\n\n\nJueves 30\nPrueba recuperativa\n\nEntrega de trabajo 2: Jueves 30 de noviembre 18:00"
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Programa",
    "section": "",
    "text": "Dr. Pablo Perez Ahumada\n   Departamento de Sociología N° 319\n   pabloperez@uchile.cl\n   pablo_perez_a\n\n\n\n\n\n   Jueves\n   Agosto 10 - Diciembre 2023\n   10:15 a 11:45 y 12:00 a 13:30\n   Aulario B - Sala B01"
  },
  {
    "objectID": "syllabus.html#propósito-general-del-curso",
    "href": "syllabus.html#propósito-general-del-curso",
    "title": "Programa",
    "section": "Propósito general del curso",
    "text": "Propósito general del curso\nAl finalizar el curso, los/as estudiantes conocerán estrategias de investigación cuantitativa que les permitirán identificar y construir problemas y objetos de investigación factibles de ser abordados a través de cuestionarios, índices o escalas de medición.\nSe espera que los/as estudiantes: conozcan distintas experiencias de investigación cuantitativa, a partir de la revisión de ejemplos actuales y de calidad académica; articulen y fundamenten las decisiones adoptadas para abordar y analizar un problema de investigación a través de técnicas cuantitativas; integren en la definición de problemas y de decisiones metodológicas fundamentos teóricos de carácter sociológico; conozcan, diseñen y validen cuestionarios y escalas en el marco de la investigación social; conozcan, construyan y validen índices de medición de diferentes constructos sociales.\nAdemás, se espera que los/as estudiantes adquieran herramientas que les permitan comunicar diseños y resultados de investigación en contextos sociales, profesionales y académicos."
  },
  {
    "objectID": "syllabus.html#competencias-a-las-que-contribuye-el-curso",
    "href": "syllabus.html#competencias-a-las-que-contribuye-el-curso",
    "title": "Programa",
    "section": "Competencias a las que contribuye el curso",
    "text": "Competencias a las que contribuye el curso\n\nDiseñar y desarrollar estrategias de investigación social cuantitativa.\nComunicar los saberes disciplinares de manera pertinente a las características de distintos contextos y audiencias, utilizando diversas estrategias y formatos."
  },
  {
    "objectID": "syllabus.html#sub-competencias",
    "href": "syllabus.html#sub-competencias",
    "title": "Programa",
    "section": "Sub competencias",
    "text": "Sub competencias\n\nDelimitar y conceptualizar objetos de investigación, a partir del manejo de paradigmas y enfoques teóricos, del análisis de estudios e investigaciones afines, así como de la observación directa de procesos, fenómenos y/o problemas sociales.\nDiseñar y aplicar diversas técnicas de recolección y producción de información empírica, pertinentes al objeto de estudio.\nDiseñar estrategias para comunicar los saberes disciplinares considerando las características de distintos contextos y audiencias.\nComunicar en forma oral y escrita los saberes disciplinares considerando distintos contextos y audiencias, haciendo un uso creativo de distintas estrategias."
  },
  {
    "objectID": "syllabus.html#resultados-de-aprendizaje",
    "href": "syllabus.html#resultados-de-aprendizaje",
    "title": "Programa",
    "section": "Resultados de aprendizaje",
    "text": "Resultados de aprendizaje\nEl presente curso se propone desarrollar en las y los estudiantes las habilidades necesarias para:\n\nReconocer, comprender y explicar las potencialidades y limitaciones de la investigación social cuantitativa.\nOperacionalizar conceptos simples y complejos, definiendo y delimitando dimensiones, subdimensiones e indicadores observables para la medición de variables en ciencias sociales.\nSeleccionar, evaluar, y construir instrumentos de medición cuantitativa (cuestionarios, índices y escalas) posibles de utilizar en investigación por encuestas."
  },
  {
    "objectID": "syllabus.html#saberes-contenidos",
    "href": "syllabus.html#saberes-contenidos",
    "title": "Programa",
    "section": "Saberes / contenidos",
    "text": "Saberes / contenidos\nPrimera unidad. Características generales de la investigación cuantitativa\n\nFormulación y diseño en la investigación cuantitativa: problema, objetivos, hipótesis, relevancias y tipos de diseño (transversal, longitudinal, experimentales, etc.)\nDefinición conceptual, real y operacional\nMedición en ciencias sociales y sociología: Proceso y concepto de medición; tipos y niveles de medición\nInstrumentos y tipos de investigaciones cuantitativas\nLimitaciones y potencialidades de la investigación cuantitativa\nContexto general de investigación (ética, financiamiento, rol del investigador, tipos de productos de investigación, proceso de producción científica académica, comunicación académica)\n\nSegunda unidad. Construcción de indicadores sociales\n\nConceptos e indicadores sociales\nFundamentos de la construcción de indicadores sociales\nIndicadores de brechas\nEjemplos concretos (brechas de género, desigualdad, etc.)\n\nTercera unidad: Construcción de índices\n\nFundamentos de la construcción de índices\nPonderación de los componentes del índice\nConfiabilidad y validez en la construcción de índices\nEjemplos concretos (índices de calidad del empleo, de derechos laborales, etc.)\n\nCuarta unidad: Construcción de escalas\n\nFundamentos de la construcción de escalas\nEscala de Likert\nEscalas sumatorias\nConfiabilidad y validez en la construcción de índices\nEjemplos concretos (escala de percepción de conflictos, escala de control laboral, etc.)\n\nQuinta unidad. Encuestas y cuestionarios\n\nLa investigación por encuestas e investigación con cuestionarios: usos, potencialidades y limitaciones\nTipos de encuestas: tipos de cuestionarios y formas de aplicación.\nFundamentos de la construcción de cuestionarios: tipos de preguntas\nEjemplos concretos (encuestas de opinión y encuestas sociales)"
  },
  {
    "objectID": "syllabus.html#metodología",
    "href": "syllabus.html#metodología",
    "title": "Programa",
    "section": "Metodología",
    "text": "Metodología\nEl curso se desarrollará a través de las siguientes actividades:\n\nDiscusiones semanales con los estudiantes.\nClases teóricas expositivas desarrolladas por el profesor del curso.\nTalleres prácticos grupales de aplicación de contenidos del curso a situaciones de investigación cuantitativa en sociología.\nLecturas y estudio individual semanal de parte de las y los estudiantes"
  },
  {
    "objectID": "syllabus.html#evaluación",
    "href": "syllabus.html#evaluación",
    "title": "Programa",
    "section": "Evaluación",
    "text": "Evaluación\nLa evaluación de los aprendizajes del curso será realizada a través de:\n\nUna prueba individual (25% de la nota final)\nUn trabajo en grupos de a 4 estudiantes sobre construcción de índices/escalas (40% nota final)\nUn trabajo en grupos de a 4 estudiantes sobre construcción de cuestionarios. Este trabajo deberá ser presentado al final de curso (25% de la nota final)\nParticipación en talleres realizados en horario de clase (10% de la nota final). En estos talleres son actividades prácticas que se realizarán en algunas sesiones del semestre (ver programación).\n\nPrueba recuperativa\nQuienes no puedan rendir la prueba, y presenten debida justificación médica ante la coordinación de la carrera, podrán dar una prueba recuperativa al final del semestre (ver calendarización).\nLa prueba recuperativa es oral e incluye toda la materia del semestre.\nRequisitos de aprobación\n\nNota de aprobación mínima (Escala de 1,0 a 7,0): 4,0.\nLos estudiantes podrán eximirse si:\n\n\ntienen un promedio igual o superior a 5,5 y\nasistieron al menos al 60% de las clases (quienes tengan menos asistencia pasan directamente a examen en segunda oportunidad)\n\n\nRequisitos para presentación a examen en primera oportunidad:\no Tener nota de presentación igual o superior a 3,5\no Haber asistido al menos al 60% de las clases\nPara dar el examen en segunda oportunidad no hay requisitos\nAmbos exámenes serán orales."
  },
  {
    "objectID": "trabajos.html",
    "href": "trabajos.html",
    "title": "Trabajos",
    "section": "",
    "text": "Proximamente…"
  }
]