[
  {
    "objectID": "trabajos.html",
    "href": "trabajos.html",
    "title": "Trabajos",
    "section": "",
    "text": "Proximamente…"
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Planificación",
    "section": "",
    "text": "Los tres componentes centrales del curso son las clases teóricas, los prácticos en R y los trabajos. Las clases se realizarán los días Martes 16:00 a 17:20 en sala E67. Los prácticos en R se realizarán el mismo día en el horario de 17:30 a 18:50.\n\nClases ( ): Lecturas, documentos de presentación y sesiones teóricas\nTalleres y actividades en R (): Actividades prácticas a desarrollar en el segundo bloque de la clase, según programación al final de esta página.\nLecturas (): Llegar a la clase con los textos leídos.\n\n\n\n\n\n Clases\n Talleres y prácticos en R\n Lecturas y material adicional\n\n\n\n\n Marzo \n\n\n\n\n\nMartes 12\nUnidad 1: Elementos y herramientas de R\nPráctico 1\n- Leer detalladamente programa del curso\n\n\nMartes 19\nUnidad 1: Elementos y herramientas de R\nPráctico 2\n\n\n\nMartes 26\nUnidad 2: Operacionalización y análisis descriptivo de datos\nPráctico 3\n\n\n\n Abril \n\n\n\n\n\nMartes 02\nUnidad 2: Operacionalización y análisis descriptivo de datos\nPráctico 4\n\n\n\nMartes 09\nUnidad 2: Operacionalización y análisis descriptivo de datos\nPráctico 5\n\n\n\nMartes 16\nSesión de apoyo Trabajo N°2\nTrabajo 2 (18/04)\n\n\n\nMartes 23\nUnidad 3: . Análisis estadístico inferencial en R\nPráctico 6\n\n\n\nMartes 30\nUnidad 3: . Análisis estadístico inferencial en R\nPráctico 7\n\n\n\n Mayo \n\n\n\n\n\nMartes 07\nSesión de apoyo Trabajo N°3\nTrabajo 3\n\n\n\nMartes 14\nUnidad 4: Regresión lineal y regresión logística\nPráctico 8\n\n\n\nMartes 21\nFeriado\n\n\n\n\nMartes 28\nUnidad 4: Regresión lineal y regresión logística\nPráctico 9\n\n\n\n Junio \n\n\n\n\n\nMartes 04\nSesión de apoyo Trabajo N°4\nTrabajo N°4\n\n\n\nMartes 11\nTrabajo de investigación\nPráctico 10\n\n\n\nMartes 18\nTrabajo de investigación\nPresentaciones\n\n\n\nMartes 25\nSesión de apoyo evaluación final.\n\n\n\n\n Julio \n\n\n\n\n\nMartes 02\nExamen final"
  },
  {
    "objectID": "practicos/03-content.html",
    "href": "practicos/03-content.html",
    "title": "Práctico R 3. Repaso construcción de indices y escalas",
    "section": "",
    "text": "Para el taller práctico de hoy utilizaremos la base de datos del Estudio Longitudinal Social de Chile, realizado por el Centro de estudios del conflicto y la cohesión social COES.\nEl Estudio Longitudinal Social del Chile ELSOC, único en Chile y América Latina, consiste en encuestar a casi 3.000 chilenos, anualmente, a lo largo de una década. ELSOC ha sido diseñado para evaluar la manera cómo piensan, sienten y se comportan los chilenos en torno a un conjunto de temas referidos al conflicto y la cohesión social en Chile. La población objetivo son hombres y mujeres entre 15 y 75 años de edad, tiene una representación de la población nacional urbana, donde se obtuvo una muestra original de 2927 casos en el año 2016 y mantiene 1728 en 2022, además de una muestra de refresco en 2018."
  },
  {
    "objectID": "practicos/03-content.html#cargar-librerías",
    "href": "practicos/03-content.html#cargar-librerías",
    "title": "Práctico R 3. Repaso construcción de indices y escalas",
    "section": "Cargar librerías",
    "text": "Cargar librerías\nLas librerías que utilizaremos esta sesión son las siguientes:\n\n\nCódigo\n# install.packages(\"pacman\") # Cargar sólo si no la tenemos instalada\nlibrary(pacman)\npacman::p_load(tidyverse, # conjunto de paquetes, sobre todo dplyr y ggplot2\n               car,       # para recodificar\n               psych,     # para Alfa de Chronbach\n               sjmisc)    # para descriptivos\n\noptions(scipen = 999) # para desactivar notacion cientifica\nrm(list = ls())       # para limpiar el entorno de trabajo"
  },
  {
    "objectID": "practicos/03-content.html#datos-y-variables",
    "href": "practicos/03-content.html#datos-y-variables",
    "title": "Práctico R 3. Repaso construcción de indices y escalas",
    "section": "Datos y variables",
    "text": "Datos y variables\nPara el ejercicio de índices, utilizaremos la base de datos de ELSOC, específicamente el módulo de Satisfacción residencial. Este módulo incluye dos conceptos:\n\nSatisfacción con la vivienda (2 items)\n\n\nTamaño de la vivienda\nCalidad de la vivienda\n\n\nsatisfacción con el barrio (8 items):\n\n\nconectividad del barrio\nproximidad con el comercio\nproximidad con colegios\nproximidad con familiares\nproximidad con la principal actividad de trabajo\nlimpieza del barrio\ncantidad de áreas verdes\nseguridad del barrio.\n\n\nCargar base de datos\n\n\nCódigo\nload(url(\"https://dataverse.harvard.edu/api/access/datafile/7245118\")) #Cargar base de datos\n\n\n\n\nVisualización de datos\n\n\nCódigo\ndim(elsoc_long_2016_2022.2)\n\n\n[1] 18035   750\n\n\nDebido a la naturaleza longitudinal de ELSOC, la base de datos contiene 18035 casos (las mismas personas durante 6 años) y 750 variables (las mismas variables en 6 periodos distintos). Por lo tanto, para simplificar el proceso de análisis de este práctico trabajaremos solo con los casos y variables de quienes participaron en la primera ola (2016)"
  },
  {
    "objectID": "practicos/03-content.html#filtrar-base-de-datos",
    "href": "practicos/03-content.html#filtrar-base-de-datos",
    "title": "Práctico R 3. Repaso construcción de indices y escalas",
    "section": "Filtrar base de datos",
    "text": "Filtrar base de datos\n\n\nCódigo\ntable(elsoc_long_2016_2022.2$ola)\n\n\n\n   1    2    3    4    5    6 \n2927 2473 3748 3417 2740 2730 \n\n\nCódigo\ndata &lt;- elsoc_long_2016_2022.2 %&gt;% filter(ola==1) %&gt;%  # Seleccionamos solo los casos de la ola 1\n  select(t06_01, t06_02, t06_03, t06_04, t06_05, t06_06, t06_07, t06_07, t06_08, #satisfacción con el barrio\n         t07_01, t07_02) # satisfacción con la vivienda\n\nhead(data)\n\n\n  t06_01 t06_02 t06_03 t06_04 t06_05 t06_06 t06_07 t06_08 t07_01 t07_02\n1      2      5      1      1      3      4      3      5      4      4\n2      3      3      2      3      4      4      4      4      4      4\n3      3      2      3      3      3      3      4      1      4      4\n4      1      3      2      2      2      3      4      4      4      4\n5      1      3      2      2      2      4      3      3      4      4\n6      1      2      2      3      4      4      4      4      3      3\n\n\nCódigo\ntable(data$t06_01)\n\n\n\n-888    1    2    3    4    5 \n   1  218  722  505 1306  175 \n\n\nCódigo\ntable(data$t06_05)\n\n\n\n-999 -888    1    2    3    4    5 \n  20   13  119  537  338 1649  251 \n\n\nCódigo\ntable(data$t07_01)\n\n\n\n-888    1    2    3    4    5 \n   1   98  539  190 1753  346 \n\n\nPodemos ver que tenemos valores de 1 a 5, que según el libro de códigos corresponden a: Totalmente insatisfecho | Insatisfecho | Ni satisfecho ni insatisfecho | Satisfecho | Totalmente satisfecho.\nY además valores -999 y -888 que corresponde a “No sabe” y “No responde”.\n\nRecodificar\nRecodificamos los valores -888 en NA\n\n\nCódigo\ndata = data %&gt;% \n  set_na(., na = c(-888, -999)) %&gt;% \n  na.omit()"
  },
  {
    "objectID": "practicos/03-content.html#medición-de-satisfacción-residencial-con-índice-no-ponderado",
    "href": "practicos/03-content.html#medición-de-satisfacción-residencial-con-índice-no-ponderado",
    "title": "Práctico R 3. Repaso construcción de indices y escalas",
    "section": "Medición de satisfacción residencial con índice no ponderado",
    "text": "Medición de satisfacción residencial con índice no ponderado\nCon la función mutate creamos una nueva variable que contenga el promedio simple de indicadores (suponinendo que cada item tiene el mismo peso).\n\n\nCódigo\ndata = data %&gt;% \n  rowwise() %&gt;%\n  mutate(satisfaccion_nopond = mean(c(t06_01, t06_02, t06_03, t06_04, t06_05, t06_06, t06_07, t06_07, t06_08, \n                                      t07_01, t07_02))\n         ) %&gt;% \n  ungroup()\n\n\n\n\nCódigo\nsummary(data$satisfaccion_nopond)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.000   3.182   3.545   3.489   3.909   5.000"
  },
  {
    "objectID": "practicos/03-content.html#medición-de-satisfacción-residencial-con-índice-ponderado",
    "href": "practicos/03-content.html#medición-de-satisfacción-residencial-con-índice-ponderado",
    "title": "Práctico R 3. Repaso construcción de indices y escalas",
    "section": "Medición de satisfacción residencial con índice ponderado",
    "text": "Medición de satisfacción residencial con índice ponderado\nsi consideramos la dimensión de satisfacción con la vivienda como un indicador de mayor relevancia, podríamos suponer que ambos ítems de esta dimensión (tamaño y calidad) tienen el mismo peso que los 8 ítems de satisfacción con el barrio (es decir, que mientras cada ítem de satisfacción con el barrio equivale a un 6.25%, los items de satisfacción con la vivienda equivalen a un 25% cada uno).\nPara estimar este índnice, primero separamos los items por dimensión:\n\n\nCódigo\ndata = data %&gt;% \n  rowwise() %&gt;%\n  mutate(barrio = mean(c(t06_01, t06_02, t06_03, t06_04, t06_05, t06_06, t06_07, t06_07, t06_08)),\n         vivienda = mean(c(t07_01, t07_02))\n         ) %&gt;% \n  ungroup()\n\n\nLuego, estimamos el índice otorgándole un 50% de peso a cada dimensión:\n\n\nCódigo\ndata = data %&gt;% \n  rowwise() %&gt;%\n  mutate(satisfaccion_pond = (barrio*0.5) + (vivienda*0.5)) %&gt;%  \n  ungroup()\n\n\n\n\nCódigo\nsummary(data$satisfaccion_pond)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.000   3.194   3.667   3.537   3.944   5.000 \n\n\nPodemos comparar:\nindice ponderado:\n\n\nCódigo\nsummary(data$satisfaccion_pond)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.000   3.194   3.667   3.537   3.944   5.000 \n\n\nindice no ponderado:\n\n\nCódigo\nsummary(data$satisfaccion_nopond)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.000   3.182   3.545   3.489   3.909   5.000"
  },
  {
    "objectID": "practicos/03-content.html#cargar-librerías-1",
    "href": "practicos/03-content.html#cargar-librerías-1",
    "title": "Práctico R 3. Repaso construcción de indices y escalas",
    "section": "Cargar librerías",
    "text": "Cargar librerías\nLas librerías que utilizaremos este ejercicio son las siguientes:\n\n\nCódigo\n# install.packages(\"pacman\") # Cargar sólo si no la tenemos instalada\n# library(pacman)\npacman::p_load(# tidyverse, # conjunto de paquetes, sobre todo dplyr y ggplot2\n               # car,       # para recodificar\n               # psych,     # para Alfa de Chronbach\n               # sjmisc,    # para descriptivos\n               remotes)   # para instalar paquete jogRu  \n\n# options(scipen = 999) # para desactivar notacion cientifica\n# rm(list = ls())       # para limpiar el entorno de trabajo\n\n\nAdemás, instalaremos la librería jogRu desde github, que nos permitirá calcular el alfa de Chronbach para variables ordinales.\n\n\nCódigo\nremotes::install_github(\"jogrue/jogRu\", force = T)\n\n\nyaml     (2.3.7  -&gt; 2.3.8 ) [CRAN]\nxfun     (0.41   -&gt; 0.42  ) [CRAN]\nglue     (1.6.2  -&gt; 1.7.0 ) [CRAN]\ncli      (3.6.1  -&gt; 3.6.2 ) [CRAN]\ndigest   (0.6.33 -&gt; 0.6.34) [CRAN]\nrlang    (1.1.2  -&gt; 1.1.3 ) [CRAN]\njsonlite (1.8.7  -&gt; 1.8.8 ) [CRAN]\nfansi    (1.0.5  -&gt; 1.0.6 ) [CRAN]\nvctrs    (0.6.4  -&gt; 0.6.5 ) [CRAN]\nggplot2  (3.4.4  -&gt; 3.5.0 ) [CRAN]\nstringi  (1.8.2  -&gt; 1.8.3 ) [CRAN]\npsych    (2.3.9  -&gt; 2.4.1 ) [CRAN]\npackage 'yaml' successfully unpacked and MD5 sums checked\npackage 'xfun' successfully unpacked and MD5 sums checked\npackage 'glue' successfully unpacked and MD5 sums checked\npackage 'cli' successfully unpacked and MD5 sums checked\npackage 'digest' successfully unpacked and MD5 sums checked\npackage 'rlang' successfully unpacked and MD5 sums checked\npackage 'jsonlite' successfully unpacked and MD5 sums checked\npackage 'fansi' successfully unpacked and MD5 sums checked\npackage 'vctrs' successfully unpacked and MD5 sums checked\npackage 'stringi' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\kevin\\AppData\\Local\\Temp\\RtmpQ51yBY\\downloaded_packages\n── R CMD build ─────────────────────────────────────────────────────────────────\n* checking for file 'C:\\Users\\kevin\\AppData\\Local\\Temp\\RtmpQ51yBY\\remotes697c37fa7f59\\jogrue-jogRu-c659fcd/DESCRIPTION' ... OK\n* preparing 'jogRu':\n* checking DESCRIPTION meta-information ... OK\n* checking for LF line-endings in source and make files and shell scripts\n* checking for empty or unneeded directories\nOmitted 'LazyData' from DESCRIPTION\n* building 'jogRu_2.0.tar.gz'\n\n\n\n\n\n\n\n\n\nNota\n\n\n\nSi pregunta These packages have more recent versions available. It is recommended to update all of them.Which would you like to update? SIEMPRE PONER 3: None."
  },
  {
    "objectID": "practicos/03-content.html#datos-y-variables-1",
    "href": "practicos/03-content.html#datos-y-variables-1",
    "title": "Práctico R 3. Repaso construcción de indices y escalas",
    "section": "Datos y variables",
    "text": "Datos y variables\nPara el ejercicio de escalas, utilizaremos nuevamente la base de datos de ELSOC (que ya se enceuntra cargada), específicamente el módulo de Salud y Bienestar. De este módulo utilizaremos un concepto en particular llamado Estado de ánimo: sintomatología depresiva con los ítems:\n\nFrecuencia: Poco interés o alegría\nFrecuencia: Decaimiento, pesadez o desesperanza\nFrecuencia: Dificultad para dormir o exceso de sueño\nFrecuencia: Cansancio o sensación de falta de energía\nFrecuencia: Apetito disminuido o aumentado\nFrecuencia: Dificultad para concentrarse\nFrecuencia: Mala opinión de sí mismo\nFrecuencia: Enlentecimiento físico\nFrecuencia: Pensamiento de muerte o dañarse\n\nEsta escala tiene solamente una dimensión, por lo que no es necesario crear objetos que contengan a cada dimensión (como vimos la clase pasada)."
  },
  {
    "objectID": "practicos/03-content.html#filtrar-base-de-datos-1",
    "href": "practicos/03-content.html#filtrar-base-de-datos-1",
    "title": "Práctico R 3. Repaso construcción de indices y escalas",
    "section": "Filtrar base de datos",
    "text": "Filtrar base de datos\nAl igual que en el ejercicio anterior, filtraremos la base de datos para quedarnos con las observaciones correspondientes solamente a la ola 1, y además seleccionaremos los ítems de interés.\n\n\nCódigo\ndata2 &lt;- elsoc_long_2016_2022.2 %&gt;% filter(ola==1) %&gt;%  # seleccionamos solo los casos de la ola 1\n  select(s11_01,s11_02,s11_03,s11_04,s11_05,s11_06,s11_07,s11_08,s11_09) # items sintomatologia depresiva\n\nhead(data2)\n\n\n  s11_01 s11_02 s11_03 s11_04 s11_05 s11_06 s11_07 s11_08 s11_09\n1      5      3      3      5      4      3      3      3      1\n2      2      2      3      2      3      4      3      4      2\n3      2      2      3      3      4      5      4      1      2\n4      1      3      3      1      1      2      3      5      1\n5      1      1      1      2      1      3      1      2      1\n6      1      1      1      1      1      1      1      1      1\n\n\nCódigo\ntable(data2$s11_01)\n\n\n\n-999 -888    1    2    3    4    5 \n   5    1 1279 1196  158  192   96 \n\n\nCódigo\ntable(data2$s11_02)\n\n\n\n-999 -888    1    2    3    4    5 \n   5    1 1302 1316  135  120   48 \n\n\nCódigo\ntable(data2$s11_03)\n\n\n\n-999 -888    1    2    3    4    5 \n   3    1 1336 1014  179  265  129 \n\n\nCódigo\ntable(data2$s11_04)\n\n\n\n-999 -888    1    2    3    4    5 \n   1    1  887 1414  223  261  140 \n\n\nCódigo\ntable(data2$s11_05)\n\n\n\n-999 -888    1    2    3    4    5 \n   4    5 1474  968  161  206  109 \n\n\nCódigo\ntable(data2$s11_06)\n\n\n\n-999 -888    1    2    3    4    5 \n   5    3 1819  752  138  131   79 \n\n\nCódigo\ntable(data2$s11_07)\n\n\n\n-999 -888    1    2    3    4    5 \n   4    4 2093  613   85   85   43 \n\n\nCódigo\ntable(data2$s11_08)\n\n\n\n-999 -888    1    2    3    4    5 \n   5    9 2110  563   92   95   53 \n\n\nCódigo\ntable(data2$s11_09)\n\n\n\n-999 -888    1    2    3    4    5 \n   3    3 2508  307   46   35   25 \n\n\nEstos ítems cuentan con las mismas categorías de respuesta: (1) Nunca, (2) Algunos dias, (3) Mas de la mitad de los dias, (4) Casi todos los dias, y (5) Todos los dias. Además de los valores codificados como -888 y -999.\n\nRecodificar\nRecodificamos los valores -888 y -999 en NA y eliminamos los NAs.\n\n\nCódigo\ndata2 &lt;- data2 %&gt;% \n  set_na(., na = c(-888, -999)) %&gt;% \n  na.omit()"
  },
  {
    "objectID": "practicos/03-content.html#análisis",
    "href": "practicos/03-content.html#análisis",
    "title": "Práctico R 3. Repaso construcción de indices y escalas",
    "section": "Análisis",
    "text": "Análisis\n\nEstimar correlación\nDado que la escala tiene solamente una dimensión, estimaremos la correlación de toda la escala.\n\n\nCódigo\ncor(data2)\n\n\n          s11_01    s11_02    s11_03    s11_04    s11_05    s11_06    s11_07\ns11_01 1.0000000 0.4853523 0.3737498 0.3725855 0.3574690 0.3049018 0.3021299\ns11_02 0.4853523 1.0000000 0.4994332 0.5552978 0.4226467 0.4138983 0.4251018\ns11_03 0.3737498 0.4994332 1.0000000 0.5592702 0.4858813 0.3902507 0.3691240\ns11_04 0.3725855 0.5552978 0.5592702 1.0000000 0.5169337 0.4585532 0.4035490\ns11_05 0.3574690 0.4226467 0.4858813 0.5169337 1.0000000 0.4119218 0.3685431\ns11_06 0.3049018 0.4138983 0.3902507 0.4585532 0.4119218 1.0000000 0.4286404\ns11_07 0.3021299 0.4251018 0.3691240 0.4035490 0.3685431 0.4286404 1.0000000\ns11_08 0.3007859 0.3936463 0.3492633 0.3940693 0.3572599 0.4228090 0.5060767\ns11_09 0.2347939 0.3884992 0.3026768 0.3330739 0.3040960 0.3445456 0.5080698\n          s11_08    s11_09\ns11_01 0.3007859 0.2347939\ns11_02 0.3936463 0.3884992\ns11_03 0.3492633 0.3026768\ns11_04 0.3940693 0.3330739\ns11_05 0.3572599 0.3040960\ns11_06 0.4228090 0.3445456\ns11_07 0.5060767 0.5080698\ns11_08 1.0000000 0.4560839\ns11_09 0.4560839 1.0000000\n\n\nPodemos observar que todas las correlaciones son positivas, por lo que no quedaron ítems invertidos.\n\n\nEstimar consistencia interna\n\nAlfa de Chronbach\nPrimero, estimaremos la consistencia interna de cada dimensión con un Alfa de Chronbach.\n\n\nCódigo\npsych::alpha(data2)\n\n\n\nReliability analysis   \nCall: psych::alpha(x = data2)\n\n  raw_alpha std.alpha G6(smc) average_r S/N    ase mean   sd median_r\n      0.85      0.86    0.85       0.4 6.1 0.0039  1.7 0.64     0.39\n\n    95% confidence boundaries \n         lower alpha upper\nFeldt     0.85  0.85  0.86\nDuhachek  0.85  0.85  0.86\n\n Reliability if an item is dropped:\n       raw_alpha std.alpha G6(smc) average_r S/N alpha se  var.r med.r\ns11_01      0.85      0.85    0.85      0.42 5.8   0.0041 0.0050  0.41\ns11_02      0.83      0.84    0.83      0.39 5.1   0.0046 0.0062  0.37\ns11_03      0.84      0.84    0.83      0.40 5.3   0.0045 0.0058  0.40\ns11_04      0.83      0.84    0.83      0.39 5.1   0.0047 0.0051  0.39\ns11_05      0.84      0.84    0.84      0.40 5.4   0.0044 0.0065  0.39\ns11_06      0.84      0.84    0.84      0.40 5.4   0.0044 0.0072  0.39\ns11_07      0.84      0.84    0.83      0.40 5.3   0.0044 0.0065  0.39\ns11_08      0.84      0.84    0.84      0.40 5.4   0.0043 0.0067  0.40\ns11_09      0.85      0.85    0.84      0.42 5.7   0.0042 0.0051  0.41\n\n Item statistics \n          n raw.r std.r r.cor r.drop mean   sd\ns11_01 2888  0.62  0.61  0.53   0.49  1.8 1.01\ns11_02 2888  0.74  0.74  0.71   0.66  1.7 0.85\ns11_03 2888  0.73  0.70  0.66   0.62  1.9 1.13\ns11_04 2888  0.77  0.75  0.72   0.67  2.1 1.07\ns11_05 2888  0.71  0.69  0.63   0.59  1.8 1.07\ns11_06 2888  0.68  0.68  0.62   0.57  1.6 0.96\ns11_07 2888  0.67  0.70  0.65   0.58  1.4 0.80\ns11_08 2888  0.66  0.68  0.62   0.56  1.4 0.85\ns11_09 2888  0.58  0.63  0.56   0.50  1.2 0.61\n\nNon missing response frequency for each item\n          1    2    3    4    5 miss\ns11_01 0.44 0.41 0.05 0.06 0.03    0\ns11_02 0.45 0.45 0.05 0.04 0.02    0\ns11_03 0.46 0.35 0.06 0.09 0.04    0\ns11_04 0.31 0.48 0.08 0.09 0.05    0\ns11_05 0.51 0.33 0.05 0.07 0.04    0\ns11_06 0.63 0.26 0.05 0.05 0.03    0\ns11_07 0.72 0.21 0.03 0.03 0.01    0\ns11_08 0.73 0.19 0.03 0.03 0.02    0\ns11_09 0.86 0.10 0.02 0.01 0.01    0\n\n\n\n\nAlfa Ordinal\nAhora, estimaremos la consistencia interna de cada dimensión con un Alfa Ordinal, ya que en estricto rigor estamos trabajando con una variable ordinal.\n\n\nCódigo\njogRu::ordinal_alpha(data2)\n\n\n\nReliability analysis   \nCall: psych::alpha(x = psych::polychoric(x)$rho)\n\n  raw_alpha std.alpha G6(smc) average_r S/N median_r\n      0.91      0.91    0.91      0.53  10     0.51\n\n    95% confidence boundaries \n      lower alpha upper\nFeldt  0.78  0.91  0.98\n\n Reliability if an item is dropped:\n       raw_alpha std.alpha G6(smc) average_r S/N  var.r med.r\ns11_01      0.90      0.90    0.90      0.54 9.5 0.0042  0.53\ns11_02      0.89      0.89    0.89      0.51 8.5 0.0050  0.49\ns11_03      0.90      0.90    0.90      0.53 9.0 0.0052  0.51\ns11_04      0.90      0.90    0.89      0.52 8.7 0.0049  0.51\ns11_05      0.90      0.90    0.90      0.53 9.1 0.0057  0.52\ns11_06      0.90      0.90    0.90      0.53 9.0 0.0059  0.50\ns11_07      0.90      0.90    0.89      0.52 8.7 0.0044  0.51\ns11_08      0.90      0.90    0.90      0.53 8.9 0.0050  0.51\ns11_09      0.90      0.90    0.90      0.53 9.0 0.0040  0.51\n\n Item statistics \n          r r.cor r.drop\ns11_01 0.70  0.65   0.61\ns11_02 0.81  0.79   0.75\ns11_03 0.75  0.72   0.68\ns11_04 0.79  0.76   0.73\ns11_05 0.74  0.70   0.66\ns11_06 0.75  0.71   0.68\ns11_07 0.78  0.76   0.72\ns11_08 0.76  0.72   0.69\ns11_09 0.76  0.73   0.68"
  },
  {
    "objectID": "practicos/01-content.html",
    "href": "practicos/01-content.html",
    "title": "Práctico 1. Aproximación inicial a R",
    "section": "",
    "text": "Esta práctica tiene dos objetivos: 1) Generar un primer acercamiento al uso de R y Rstudio, conociendo su interfaz y sus principales funcionalidades y 2) revisar algunos procedimientos básicos de la preparación de datos con R, que son necesarios para luego poder aplicar los contenidos más específicos de este curso.\n\n\n\n\n\n\nAcceder a la página de posit, desarrollador del software desde octubre de 2022. Link directo a la descarga acá.\nInstalar R y Rstudio\n\n\n\nDescargar R\n\n\nSeleccionamos sistema operativo según corresponda\n\n\n\nDescargar R por primera vez y seguir instrucciones. En esta oportunidad trabajaremos con la última versión de R 4.2.2\n\n\n\nDescargar RStudio\n\n\nDescarga directa en la página de inicio\n\n\nInstalar ambos archivos siguiendo las instrucciones de instalación\n\n\nAbrir RStudio. Se debería ver similar a esto:\n\n\n\nRecomendaciones generales:\n\n\nevitar uso de tilde, ñ, espacios y mayúsculas tanto en carpetas y archivos, así como también en los nombres de las variables\nal momento de hacer consultas sobre problemas en la ejecución del código, adjuntar la siguiente información:\n\n\nCódigo completo hasta que se produce el problema\nIndicar línea del código donde se produce el problema\nAdjuntar el resultado del output de la información de la sesión (sessionInfo())\n\n\n\n\n\nEn primer lugar vamos a abrir un archivo de R (script). Esto se puede hacer manualmente con File -&gt; new file -&gt; R script o directamente con ctrl + shift + N\nEsta es nuestra hoja de código, que utilizaremos para procesar bases de datos, modificar variables y crear tablas y gráficos.\n\n\nR puede ser una calculadora\n\n\nCódigo\n10 + 5 # ¿cuánto es 10 + 5?\n\n\n[1] 15\n\n\n\n\nCódigo\n10 * 5 # ¿cuánto es 10 * 5?\n\n\n[1] 50\n\n\nSe pueden crear objetos y asignarles valores\n\n\nCódigo\na &lt;- 28\nb &lt;- 8\n\na + b\n\n\n[1] 36\n\n\nO asignar operaciones a un objeto\n\n\nCódigo\nc &lt;- a + b\n\n\nSin embargo, la mayor parte del tiempo usamos funciones que ya existen en R\n\n\nCódigo\nsum(28,8)\n\n\n[1] 36\n\n\n\n\nCódigo\nround(10.14536) #aproximar\n\n\n[1] 10\n\n\nY muchas de estas funciones que utilizamos en R están contenidas en librerías o paquetes (packages)\n\n\n\nLa lógica de R es instalar librerías (solo 1 vez, con install.packages(\"librería\")), y luego cargarlas cada vez que es necesario usarlas (con library(librería)). El problema de esto es que a veces no se sabe claramente qué librerías están instaladas y cuales no, lo que va a arrojar error al cargarlas. Y, como sucede en R, existe una librería para solucionar este problema que se llama pacman (package manager). Lo que hace pacman es cargar la librería, y si no está instalada, la instala y la carga:\nPara utilizar la primera vez (si es que no está instalada):\n\n\nCódigo\ninstall.packages(\"pacman\")\n\n\nY en adelante, las librerías se cargan así  pacman::p_load(libreria1,libreria2,libreriaX) :\n\n\nCódigo\npacman::p_load(dplyr, guaguas)\n\n\nPara esta sesión las librerías que vamos a utilizar son:\n\ndplyr: ajuste general de datos\nguaguas: Paquete que contiene los datos de nombres de guaguas (bebés) registrados en Chile entre 1920 y 2021 según el Registro Civil e Identificación\n\n\n\n\nAjustar espacio de trabajo\nPrevio a la carga de nuestra base de datos, se recomienda ejecutar los siguientes comandos:\n\n\nCódigo\nrm(list=ls())       # borrar todos los objetos en el espacio de trabajo\noptions(scipen=999) # valores sin notación científica\n\n\nLa función rm(list=ls()) permite comenzar con un espacio de trabajo (environment) vacío y sin otros objetos. Así también, la función options(scipen=999) desactiva la notación científica, es decir, veremos los valores numéricos con todos sus decimales.\nDatos\nCargamos la base de datos desde el paquete (para otras bases de datos se deben importar de otra forma, esto es solo como ejemplo)\n\n\nCódigo\nbase &lt;- guaguas\n\n\nConocemos las dimensiones de la base de datos\n\n\nCódigo\ndim(base)\n\n\n[1] 858782      5\n\n\nSon 858782 casos y 5 variables. Los nombres de estas variables son:\n\n\nCódigo\nnames(base)\n\n\n[1] \"anio\"       \"nombre\"     \"sexo\"       \"n\"          \"proporcion\"\n\n\nY la base se ve así:\n\n\nCódigo\nhead(base)\n\n\n# A tibble: 6 × 5\n   anio nombre sexo      n proporcion\n  &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt;      &lt;dbl&gt;\n1  1920 María  F      2130     0.104 \n2  1920 José   M       984     0.0483\n3  1920 Juan   M       636     0.0312\n4  1920 Luis   M       631     0.0310\n5  1920 Rosa   F       426     0.0209\n6  1920 Ana    F       340     0.0167\n\n\nAhora probemos algunas funciones para seguir explorando la base\n\n\nCódigo\ntable(base$sexo)\n\n\n\n     F      I      M \n531038    318 327426 \n\n\nPodemos ver la cantidad de nombres “F” (femenino), “M” (masculino) e “I” (indefinido) inscritos entre 1920 y 2021.\nPueden buscar sus nombres y probar, utilizamos la funcion filter del paquete dplyr\n\n\nCódigo\nfilter(base, nombre==\"Kevin\")\n\n\n# A tibble: 63 × 5\n    anio nombre sexo      n proporcion\n   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt;      &lt;dbl&gt;\n 1  1931 Kevin  M         1 0.0000120 \n 2  1963 Kevin  M         1 0.0000035 \n 3  1964 Kevin  M         1 0.00000344\n 4  1967 Kevin  M         4 0.0000131 \n 5  1970 Kevin  M         6 0.0000210 \n 6  1971 Kevin  M         3 0.00000936\n 7  1972 Kevin  M         3 0.00000945\n 8  1973 Kevin  M         2 0.00000633\n 9  1974 Kevin  M         5 0.0000163 \n10  1976 Kevin  M         2 0.00000724\n# ℹ 53 more rows\n\n\nE incluso pueden ver la cantidad de personas con su nombre, en el mismo año que ustedes nacieron\n\n\nCódigo\nd &lt;- filter(base, nombre==\"Kevin\" & anio==1996)\nsum(d$n)\n\n\n[1] 1312"
  },
  {
    "objectID": "practicos/01-content.html#objetivos-de-la-práctica",
    "href": "practicos/01-content.html#objetivos-de-la-práctica",
    "title": "Práctico 1. Aproximación inicial a R",
    "section": "",
    "text": "Esta práctica tiene dos objetivos: 1) Generar un primer acercamiento al uso de R y Rstudio, conociendo su interfaz y sus principales funcionalidades y 2) revisar algunos procedimientos básicos de la preparación de datos con R, que son necesarios para luego poder aplicar los contenidos más específicos de este curso."
  },
  {
    "objectID": "practicos/01-content.html#r-y-rstudio",
    "href": "practicos/01-content.html#r-y-rstudio",
    "title": "Práctico 1. Aproximación inicial a R",
    "section": "",
    "text": "Acceder a la página de posit, desarrollador del software desde octubre de 2022. Link directo a la descarga acá.\nInstalar R y Rstudio\n\n\n\nDescargar R\n\n\nSeleccionamos sistema operativo según corresponda\n\n\n\nDescargar R por primera vez y seguir instrucciones. En esta oportunidad trabajaremos con la última versión de R 4.2.2\n\n\n\nDescargar RStudio\n\n\nDescarga directa en la página de inicio\n\n\nInstalar ambos archivos siguiendo las instrucciones de instalación\n\n\nAbrir RStudio. Se debería ver similar a esto:\n\n\n\nRecomendaciones generales:\n\n\nevitar uso de tilde, ñ, espacios y mayúsculas tanto en carpetas y archivos, así como también en los nombres de las variables\nal momento de hacer consultas sobre problemas en la ejecución del código, adjuntar la siguiente información:\n\n\nCódigo completo hasta que se produce el problema\nIndicar línea del código donde se produce el problema\nAdjuntar el resultado del output de la información de la sesión (sessionInfo())"
  },
  {
    "objectID": "practicos/01-content.html#primeros-pasos",
    "href": "practicos/01-content.html#primeros-pasos",
    "title": "Práctico 1. Aproximación inicial a R",
    "section": "",
    "text": "En primer lugar vamos a abrir un archivo de R (script). Esto se puede hacer manualmente con File -&gt; new file -&gt; R script o directamente con ctrl + shift + N\nEsta es nuestra hoja de código, que utilizaremos para procesar bases de datos, modificar variables y crear tablas y gráficos.\n\n\nR puede ser una calculadora\n\n\nCódigo\n10 + 5 # ¿cuánto es 10 + 5?\n\n\n[1] 15\n\n\n\n\nCódigo\n10 * 5 # ¿cuánto es 10 * 5?\n\n\n[1] 50\n\n\nSe pueden crear objetos y asignarles valores\n\n\nCódigo\na &lt;- 28\nb &lt;- 8\n\na + b\n\n\n[1] 36\n\n\nO asignar operaciones a un objeto\n\n\nCódigo\nc &lt;- a + b\n\n\nSin embargo, la mayor parte del tiempo usamos funciones que ya existen en R\n\n\nCódigo\nsum(28,8)\n\n\n[1] 36\n\n\n\n\nCódigo\nround(10.14536) #aproximar\n\n\n[1] 10\n\n\nY muchas de estas funciones que utilizamos en R están contenidas en librerías o paquetes (packages)\n\n\n\nLa lógica de R es instalar librerías (solo 1 vez, con install.packages(\"librería\")), y luego cargarlas cada vez que es necesario usarlas (con library(librería)). El problema de esto es que a veces no se sabe claramente qué librerías están instaladas y cuales no, lo que va a arrojar error al cargarlas. Y, como sucede en R, existe una librería para solucionar este problema que se llama pacman (package manager). Lo que hace pacman es cargar la librería, y si no está instalada, la instala y la carga:\nPara utilizar la primera vez (si es que no está instalada):\n\n\nCódigo\ninstall.packages(\"pacman\")\n\n\nY en adelante, las librerías se cargan así  pacman::p_load(libreria1,libreria2,libreriaX) :\n\n\nCódigo\npacman::p_load(dplyr, guaguas)\n\n\nPara esta sesión las librerías que vamos a utilizar son:\n\ndplyr: ajuste general de datos\nguaguas: Paquete que contiene los datos de nombres de guaguas (bebés) registrados en Chile entre 1920 y 2021 según el Registro Civil e Identificación\n\n\n\n\nAjustar espacio de trabajo\nPrevio a la carga de nuestra base de datos, se recomienda ejecutar los siguientes comandos:\n\n\nCódigo\nrm(list=ls())       # borrar todos los objetos en el espacio de trabajo\noptions(scipen=999) # valores sin notación científica\n\n\nLa función rm(list=ls()) permite comenzar con un espacio de trabajo (environment) vacío y sin otros objetos. Así también, la función options(scipen=999) desactiva la notación científica, es decir, veremos los valores numéricos con todos sus decimales.\nDatos\nCargamos la base de datos desde el paquete (para otras bases de datos se deben importar de otra forma, esto es solo como ejemplo)\n\n\nCódigo\nbase &lt;- guaguas\n\n\nConocemos las dimensiones de la base de datos\n\n\nCódigo\ndim(base)\n\n\n[1] 858782      5\n\n\nSon 858782 casos y 5 variables. Los nombres de estas variables son:\n\n\nCódigo\nnames(base)\n\n\n[1] \"anio\"       \"nombre\"     \"sexo\"       \"n\"          \"proporcion\"\n\n\nY la base se ve así:\n\n\nCódigo\nhead(base)\n\n\n# A tibble: 6 × 5\n   anio nombre sexo      n proporcion\n  &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt;      &lt;dbl&gt;\n1  1920 María  F      2130     0.104 \n2  1920 José   M       984     0.0483\n3  1920 Juan   M       636     0.0312\n4  1920 Luis   M       631     0.0310\n5  1920 Rosa   F       426     0.0209\n6  1920 Ana    F       340     0.0167\n\n\nAhora probemos algunas funciones para seguir explorando la base\n\n\nCódigo\ntable(base$sexo)\n\n\n\n     F      I      M \n531038    318 327426 \n\n\nPodemos ver la cantidad de nombres “F” (femenino), “M” (masculino) e “I” (indefinido) inscritos entre 1920 y 2021.\nPueden buscar sus nombres y probar, utilizamos la funcion filter del paquete dplyr\n\n\nCódigo\nfilter(base, nombre==\"Kevin\")\n\n\n# A tibble: 63 × 5\n    anio nombre sexo      n proporcion\n   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt;      &lt;dbl&gt;\n 1  1931 Kevin  M         1 0.0000120 \n 2  1963 Kevin  M         1 0.0000035 \n 3  1964 Kevin  M         1 0.00000344\n 4  1967 Kevin  M         4 0.0000131 \n 5  1970 Kevin  M         6 0.0000210 \n 6  1971 Kevin  M         3 0.00000936\n 7  1972 Kevin  M         3 0.00000945\n 8  1973 Kevin  M         2 0.00000633\n 9  1974 Kevin  M         5 0.0000163 \n10  1976 Kevin  M         2 0.00000724\n# ℹ 53 more rows\n\n\nE incluso pueden ver la cantidad de personas con su nombre, en el mismo año que ustedes nacieron\n\n\nCódigo\nd &lt;- filter(base, nombre==\"Kevin\" & anio==1996)\nsum(d$n)\n\n\n[1] 1312"
  },
  {
    "objectID": "news/2023-08-14_infos.html",
    "href": "news/2023-08-14_infos.html",
    "title": "Informaciones de la semana",
    "section": "",
    "text": "← News\n\n\n\nActualizaciones sitio web:"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "\n            R para análisis estadístico\n        ",
    "section": "",
    "text": "R para análisis estadístico\n        \n        \n            Departamento de Sociología - Facultad de Ciencias Sociales de la Universidad Alberto Hurtado\n        \n        \n            CSSOCIAL 6607-SOC1(1052) • Primer semestre 2024Departamento de SociologíaUniversidad Alberto Hurtado\n        \n    \n    \n      \n        \n        \n        \n      \n    \n\n\n\n\nEquipo docente\nProfesor\n\n   Kevin Carrasco\n   ?var:instructor.office\n   kevin.carrasco@ug.uchile.cl\n\nAyudante\n\n   Javiera Whomper\n   kevin.carrasco@ug.uchile.cl\n\n\n\nInformación del curso\n\n   Martes\n   Marzo 12 - Julio 15 2024\n   16:00 a 17:20 y 17:30 a 18:50\n   Sala E67"
  },
  {
    "objectID": "example/cace.html",
    "href": "example/cace.html",
    "title": "Complier average treatment effects",
    "section": "",
    "text": "Throughout this course, we’ve talked about the difference between the average treatment effect (ATE), or the average effect of a program for an entire population, and conditional average treatment effect (CATE), or the average effect of a program for some segment of the population. There are all sorts of CATEs: you can find the CATE for men vs. women, for people who are treated with the program (the average treatment on the treated, or ATT or TOT), for people who are not treated with the program (the average treatment on the untreated, or ATU), and so on.\nOne important type of CATE is the effect of a program on just those who comply with the program. We can call this the complier average treatment effect, but the acronym would be the same as conditional average treatment effect, so we’ll call it the complier average causal effect or CACE.\nThinking about compliance is important. You might randomly assign people to receive treatment or a program, but people might not do what you tell them. Additionally, people might do the program if assigned to do it, but they would have done it anyway. We can split the population into four types of people:\n\nCompliers: People who follow whatever their assignment is (if assigned to treatment, they do the program; if assigned to control, they don’t)\nAlways takers: People who will receive or seek out the program regardless of assignment (if assigned to treatment, they do the program; if assigned to control, they still do the program)\nNever takers: People who will not receive or seek out the program regardless of assignment (if assigned to treatment, they don’t do the program; if assigned to control, they also don’t do it)\nDefiers: People who will do the opposite of whatever their assignment is (if assigned to treatment, they don’t do the program; if assigned to control, they do the program)\n\nTo simplify things, evaluators and econometricians assume that defiers don’t exist based on the idea of monotonicity, which means that we can assume that the effect of being assigned to treatment only increases the likelihood of participating in the program (and doesn’t make it more likely).\nThe tricky part about trying to find who the compliers are in a sample is that we can’t know what people would have done in the absence of treatment. If we see that someone in the experiment was assigned to be in the treatment group and they then participated in the program, they could be a complier (since they did what they were assigned to do), or they could be an always taker (they did what they were assigned to do, but they would have done it anyway). Due to the fundamental problem of causal inference, we cannot know what each person would have done in a parallel world.\nWe can use data from a hypothetical program to see how these three types of compliers distort our outcomes, and more importantly, how we can disentangle compliers from their always- and never-taker counterparts.\nIf you want to follow along with this example, you can download these two datasets:\n\n bed_nets_time_machine.csv\n bed_nets_observed.csv"
  },
  {
    "objectID": "example/cace.html#compliance-and-treatment-effects",
    "href": "example/cace.html#compliance-and-treatment-effects",
    "title": "Complier average treatment effects",
    "section": "",
    "text": "Throughout this course, we’ve talked about the difference between the average treatment effect (ATE), or the average effect of a program for an entire population, and conditional average treatment effect (CATE), or the average effect of a program for some segment of the population. There are all sorts of CATEs: you can find the CATE for men vs. women, for people who are treated with the program (the average treatment on the treated, or ATT or TOT), for people who are not treated with the program (the average treatment on the untreated, or ATU), and so on.\nOne important type of CATE is the effect of a program on just those who comply with the program. We can call this the complier average treatment effect, but the acronym would be the same as conditional average treatment effect, so we’ll call it the complier average causal effect or CACE.\nThinking about compliance is important. You might randomly assign people to receive treatment or a program, but people might not do what you tell them. Additionally, people might do the program if assigned to do it, but they would have done it anyway. We can split the population into four types of people:\n\nCompliers: People who follow whatever their assignment is (if assigned to treatment, they do the program; if assigned to control, they don’t)\nAlways takers: People who will receive or seek out the program regardless of assignment (if assigned to treatment, they do the program; if assigned to control, they still do the program)\nNever takers: People who will not receive or seek out the program regardless of assignment (if assigned to treatment, they don’t do the program; if assigned to control, they also don’t do it)\nDefiers: People who will do the opposite of whatever their assignment is (if assigned to treatment, they don’t do the program; if assigned to control, they do the program)\n\nTo simplify things, evaluators and econometricians assume that defiers don’t exist based on the idea of monotonicity, which means that we can assume that the effect of being assigned to treatment only increases the likelihood of participating in the program (and doesn’t make it more likely).\nThe tricky part about trying to find who the compliers are in a sample is that we can’t know what people would have done in the absence of treatment. If we see that someone in the experiment was assigned to be in the treatment group and they then participated in the program, they could be a complier (since they did what they were assigned to do), or they could be an always taker (they did what they were assigned to do, but they would have done it anyway). Due to the fundamental problem of causal inference, we cannot know what each person would have done in a parallel world.\nWe can use data from a hypothetical program to see how these three types of compliers distort our outcomes, and more importantly, how we can disentangle compliers from their always- and never-taker counterparts.\nIf you want to follow along with this example, you can download these two datasets:\n\n bed_nets_time_machine.csv\n bed_nets_observed.csv"
  },
  {
    "objectID": "example/cace.html#finding-compliers-with-a-mind-reading-time-machine",
    "href": "example/cace.html#finding-compliers-with-a-mind-reading-time-machine",
    "title": "Complier average treatment effects",
    "section": "Finding compliers with a mind-reading time machine",
    "text": "Finding compliers with a mind-reading time machine\nFirst let’s load the data and reorder some of the categories:\n\n\nCode\nlibrary(tidyverse)  # ggplot(), %&gt;%, mutate(), and friends\nlibrary(broom)  # Convert models to data frames\nlibrary(estimatr)  # Run 2SLS models in one step with iv_robust()\n\nbed_nets &lt;- read_csv(\"data/bed_nets_observed.csv\") %&gt;%\n  # Make \"No bed net\" (control) come first\n  mutate(bed_net = fct_relevel(bed_net, \"No bed net\"))\n\nbed_nets_time_machine &lt;- read_csv(\"data/bed_nets_time_machine.csv\") %&gt;%\n  # Make \"No bed net\" come first and \"Complier\" come first\n  mutate(bed_net = fct_relevel(bed_net, \"No bed net\"),\n         status = fct_relevel(status, \"Complier\"))\n\n\nThis is what we would be able to see if we could read everyone’s minds. There are always takers who will use a bed net regardless of the program, and they’ll have higher health outcomes. However, those better outcomes are because of something endogenous—there’s something else that makes these people always pursue bed nets, and that’s likely related to health. We probably want to not consider them when looking for the program effect. There are never takers who won’t ever use a bed net, and they have worse health outcomes. Again, there’s endogeneity here—something is causing them to not use the bed nets, and it likely also causes their health level. We don’t want to look at them either.\nThe first group—the compliers—are the people we want to focus on. Here we see that the program had an effect when compared to a control group.\n\n\nCode\nset.seed(1234)  # Make the jittering the same every time\n\nggplot(bed_nets_time_machine, aes(y = health, x = treatment)) +\n  geom_point(aes(shape = bed_net, color = status),\n             position = position_jitter(height = NULL, width = 0.25)) +\n  facet_wrap(vars(status)) +\n  labs(color = \"Type of person\", shape = \"Compliance\",\n       x = NULL, y = \"Health status\") +\n  scale_color_viridis_d(option = \"plasma\", end = 0.85) +\n  theme_bw()"
  },
  {
    "objectID": "example/cace.html#finding-compliers-in-actual-data",
    "href": "example/cace.html#finding-compliers-in-actual-data",
    "title": "Complier average treatment effects",
    "section": "Finding compliers in actual data",
    "text": "Finding compliers in actual data\nThis is what we actually see in the data, though. You can tell who some of the always takers are (those who used bed nets after being assigned to the control group) and who some of the never takers are (those who did not use a bed net after being assigned to the treatment group), but compliers are mixed up with the always and never takers. We have to somehow disentangle them!\n\n\nCode\nset.seed(1234)\nggplot(bed_nets_time_machine, aes(y = health, x = bed_net)) +\n  geom_point(aes(shape = bed_net, color = status),\n             position = position_jitter(height = NULL, width = 0.25)) +\n  facet_wrap(vars(treatment)) +\n  labs(color = \"Type of person\", shape = \"Compliance\",\n       x = NULL, y = \"Health status\") +\n  scale_color_viridis_d(option = \"plasma\", end = 0.85) +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nWe can do this by assuming the proportion of compliers, never takers, and always takers are equally spread across treatment and control (which we can assume through the magic of randomization). If that’s the case, we can calculate the intent to treat (ITT) effect, which is the CATE of being assigned treatment (or the effect of being assigned treatment on health status, regardless of actual compliance).\nThe ITT is actually composed of three different causal effects: the complier average causal effect (CACE), the always taker average causal effect (ATACE), and the never taker average causal effect (NTACE). In the formula below, \\(\\pi\\) stands for the proportion of people in each group. Formally, the ITT can be defined like this:\n\\[\n\\begin{aligned}\n\\text{ITT}\\ =\\ & \\color{#0D0887}{\\pi_\\text{compliers} \\times (\\text{T} - \\text{C})_\\text{compliers}} + \\\\\n&\\color{#B7318A}{\\pi_\\text{always takers} \\times (\\text{T} - \\text{C})_\\text{always takers}} + \\\\\n&\\color{#FEBA2C}{\\pi_\\text{never takers} \\times (\\text{T} - \\text{C})_\\text{never takers}}\n\\end{aligned}\n\\]\nWe can simplify this to this acronymized version:\n\\[\n\\text{ITT}\\ =\\ \\color{#0D0887}{\\pi_\\text{C} \\text{CACE}} + \\color{#B7318A}{\\pi_\\text{A} \\text{ATACE}} + \\color{#FEBA2C}{\\pi_\\text{N} \\text{NTACE}}\n\\]\nThe number we care about the most here is the CACE, which is stuck in the middle of the equation. But we can rescue it with some fun logical and algebraic trickery!\nIf we assume that assignment to treatment doesn’t make someone more likely to be an always taker or a never taker, we can set the ATACE and NTACE to zero, leaving us with just three variables to worry about: ITT, \\(\\pi_\\text{c}\\), and CACE:\n\\[\n\\begin{aligned}\n\\text{ITT}\\ =\\ & \\color{#0D0887}{\\pi_\\text{C} \\text{CACE}} + \\color{#B7318A}{\\pi_\\text{A} \\text{ATACE}} + \\color{#FEBA2C}{\\pi_\\text{N} \\text{NTACE}} \\\\[6pt]\n=\\ & \\color{#0D0887}{\\pi_\\text{C} \\text{CACE}} + \\color{#B7318A}{\\pi_\\text{A} \\times 0} + \\color{#FEBA2C}{\\pi_\\text{N} \\times 0}\\\\[6pt]\n\\text{ITT}\\ =\\ & \\color{#0D0887}{\\pi_\\text{C} \\text{CACE}}\n\\end{aligned}\n\\]\nWe can use algebra to rearrange this formula so that we’re left with an equation that starts with CACE (since that’s the value we care about):\n\\[\n\\text{CACE} = \\frac{\\text{ITT}}{\\pi_\\text{C}}\n\\]\nIf we can find the ITT and the proportion of compliers, we can find the complier average causal effect (CACE). Fortunately, both those pieces—ITT and \\(\\pi_\\text{C}\\)—are findable in the data we have!"
  },
  {
    "objectID": "example/cace.html#finding-the-itt",
    "href": "example/cace.html#finding-the-itt",
    "title": "Complier average treatment effects",
    "section": "Finding the ITT",
    "text": "Finding the ITT\nThe ITT is easy to find with a simple OLS model:\n\n\nCode\nitt_model &lt;- lm(health ~ treatment, data = bed_nets)\n\ntidy(itt_model)\n## # A tibble: 2 × 5\n##   term               estimate std.error statistic  p.value\n##   &lt;chr&gt;                 &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n## 1 (Intercept)           40.9      0.444     92.1  0       \n## 2 treatmentTreatment     5.99     0.630      9.51 5.20e-21\n\nITT &lt;- tidy(itt_model) %&gt;%\n  filter(term == \"treatmentTreatment\") %&gt;%\n  pull(estimate)\n\n\nThe ITT here is ≈6—being assigned treatment increases average health status by 5.99 health points."
  },
  {
    "objectID": "example/cace.html#finding-the-proportion-of-compliers",
    "href": "example/cace.html#finding-the-proportion-of-compliers",
    "title": "Complier average treatment effects",
    "section": "Finding the proportion of compliers",
    "text": "Finding the proportion of compliers\nThe proportion of compliers is a little trickier, but doable with some algebraic trickery. Recall from the graph above that the people who were in the treatment group and who complied are a combination of always takers and compliers. This means we can say:\n\\[\n\\begin{aligned}\n\\pi_\\text{A} + \\pi_\\text{C} =& \\text{% yes in treatment; or} \\\\\n\\pi_\\text{C} =& \\text{% yes in treatment} - \\pi_\\text{A}\n\\end{aligned}\n\\]\nWe actually know \\(\\pi_\\text{A}\\)—remember in the graph above that the people who were in the control group and who used bed nets are guaranteed to be always takers (none of them are compliers or never takers). If we assume that the proportion of always takers is the same in both treatment and control, we can use that percent here, giving us this final equation for \\(\\pi_\\text{C}\\):\n\\[\n\\begin{aligned}\n\\pi_\\text{C} =& \\text{% yes in treatment} - \\pi_\\text{A} \\\\\n=& \\text{% yes in treatment} - \\text{% yes in control}\n\\end{aligned}\n\\]\nSo, if we can find the percent of people assigned to treatment who used bed nets, find the percent of people assigned to control and used bed nets, and subtract the two percentages, we’ll have the proportion of compliers, or \\(\\pi_\\text{C}\\). We can do that with the data we have (61% - 19.5% = 41.5% compliers):\n\n\nCode\nbed_nets %&gt;%\n  group_by(treatment, bed_net) %&gt;%\n  summarize(n = n()) %&gt;%\n  mutate(prop = n / sum(n))\n## # A tibble: 4 × 4\n## # Groups:   treatment [2]\n##   treatment bed_net        n  prop\n##   &lt;chr&gt;     &lt;fct&gt;      &lt;int&gt; &lt;dbl&gt;\n## 1 Control   No bed net   808 0.805\n## 2 Control   Bed net      196 0.195\n## 3 Treatment No bed net   388 0.390\n## 4 Treatment Bed net      608 0.610\n\n# pi_c = prop yes in treatment - prop yes in control\npi_c &lt;- 0.6104418 - 0.1952191\n\n\nFinally, now that we know both the ITT and \\(\\pi_\\text{C}\\), we can find the CACE (or the LATE):\n\n\nCode\nCACE &lt;- ITT / pi_c\nCACE\n## [1] 14.43\n\n\nIt’s 14.4, which means that using bed nets increased health by 14 health points for compliers (which is a lot bigger than the 6 that we found before). We successfully filtered out the always takers and the never takers, and we have our complier-specific causal effect."
  },
  {
    "objectID": "example/cace.html#finding-the-cacelate-with-iv2sls",
    "href": "example/cace.html#finding-the-cacelate-with-iv2sls",
    "title": "Complier average treatment effects",
    "section": "Finding the CACE/LATE with IV/2SLS",
    "text": "Finding the CACE/LATE with IV/2SLS\nDoing that is super tedious though! What if there was an easier way to find the effect of the bed net program for just the compliers? We can do this with IV/2SLS regression by using assignment to treatment as an instrument.\nAssignment to treatment works as an instrument because it’s (1) relevant, since being told to use bed nets is probably highly correlated with using bed nets, (2) exclusive, since the only way that being told to use bed nets can cause changes in health is through the actual use of the bed nets, and (3) exogenous, since being told to use bed nets probably isn’t related to other things that cause health.\nHere’s a 2SLS regression with assignment to treatment as the instrument:\n\n\nCode\nmodel_2sls &lt;- iv_robust(health ~ bed_net | treatment, data = bed_nets)\ntidy(model_2sls)\n##             term estimate std.error statistic   p.value conf.low conf.high   df outcome\n## 1    (Intercept)    38.12    0.5151     74.01 0.000e+00    37.11     39.13 1998  health\n## 2 bed_netBed net    14.43    1.2538     11.51 1.038e-29    11.97     16.89 1998  health\n\n\nThe coefficient for bed_net is identical to the CACE that we found manually! Instrumental variables are helpful for isolated program effects to only compliers when you’re dealing with noncompliance."
  },
  {
    "objectID": "assignment/05-taller.html",
    "href": "assignment/05-taller.html",
    "title": "Taller 5",
    "section": "",
    "text": "Objetivo del taller\nIniciar el desarrollo del segundo trabajo grupal asociado a construcción de cuestionarios.\n\n\nInstrucciones:\nEn sus grupos de trabajo, ustedes deben:\n\nDefinir un tema principal a partir del cual elaborarán el cuestionario (por ejemplo: condiciones y estrategias de estudio, actitudes y prácticas deportivas, entre otros). La elección del tema es libre y depende de los intereses de quienes conformen el grupo.\nBuscar en internet al menos tres encuestas o cuestionarios que aborden temas similares al que han elegido. En base a sus respectivos documentos metodológicos, deben especificar:\n\n\nNombre de la encuesta;\nAño(s) y país(es) en que se ha levantado;\nInstitución/organismo/etc. encargado de su ejecución;\nObjetivos de la encuesta;\nPoblación objetivo;\nPrincipales variables del estudio; y\nRecuento de los módulos del cuestionario, junto a un breve resumen que dé cuenta de los temas abordados en cada uno.\n\n\nPara cada cuestionario revisado, señalar al menos dos variables que puedan ser útiles para el cuestionario que elaborarán en el transcurso del segundo trabajo. Deben incluir el enunciado y sus respectivas alternativas de respuesta.\nEn base a lo revisado anteriormente, y pensando en el cuestionario que elaborarán en el marco del trabajo, definan:\n\n\nObjetivo de su estudio;\nPoblación objetivo a la cual está dirigido; y\nPrincipales variables a considerar.\n\n\nEn una hoja deben especificar el título Taller 5, el nombre de l_s integrantes del equipo que están presentes en el taller, y sus respectivas respuestas. Tendrán hasta las 13:25 para realizar el taller."
  },
  {
    "objectID": "assignment/03-taller.html",
    "href": "assignment/03-taller.html",
    "title": "Taller 3",
    "section": "",
    "text": "Practicar la creación de índices sintéticos, y reforzar contenidos asociados a la validez."
  },
  {
    "objectID": "assignment/03-taller.html#constructos",
    "href": "assignment/03-taller.html#constructos",
    "title": "Taller 3",
    "section": "Constructos:",
    "text": "Constructos:\n\nÍndice de Desarrollo Humano\nÍndice de Democracia.\nÍndice de victimización.\nÍndice de calidad del empleo.\nÍndice de consumo cultural.\nÍndice de actitudes hacia la violencia.\nÍndice de actitudes hacia el deporte."
  },
  {
    "objectID": "assignment/03-taller.html#ejemplo-de-trabajo",
    "href": "assignment/03-taller.html#ejemplo-de-trabajo",
    "title": "Taller 3",
    "section": "Ejemplo de trabajo",
    "text": "Ejemplo de trabajo\nConstructo: Índice de confianza en instituciones\nUnidad de análisis: Sujetos/individuos\nDimensiones: 2 dimensiones: a) instituciones políticas; b) instituciones civiles\nVariables necesarias:\n¿Cuánto confía usted en las siguientes instituciones?\n\nPresidente (Ordinal; nada-poco-bastante-mucho)\nPartidos políticos (Ordinal; nada-poco-bastante-mucho)\nONGs (Ordinal; nada-poco-bastante-mucho)\nPoder judicial (Ordinal; nada-poco-bastante-mucho)\nBomberos (Ordinal; nada-poco-bastante-mucho)\nIglesia (Ordinal; nada-poco-bastante-mucho)\n\nOperacionalización:\n\nFormalización:\n\\[CI = CIC + CIP = C. Bomberos + C. ONGs + C. Iglesia + C. Poder judicial + C. Partidos + C. Presidente\\] \\[CI = CIC + CIP =  [0, 3]      +     [0, 3]   +     [0,3]     +          [0, 3]          +      [0, 3]     +       [0,3] \\]\nPosibles valores: [0, 18].\nNivel de medición: Intervalar (discutible)\nInterpretación: Menores valores indican nada o poca confianza en instituciones, mientras que los valores más altos indican bastante o mucha confianza en instituciones. Por un lado, una persona puede tener un grado de confianza en instituciones de 1 (al haber respondido “nada” de confianza en la mayoría de las instituciones y “Algo” de confianza en una de ellas), lo que da cuenta de un bajo grado de confianza en las instituciones. Por otro lado, una persona puede tener un grado de confianza en instituciones de 15 (al haber respondido “Mucha” confianza en 5 instituciones y “Nada” confianza en las otras tres), lo que da cuenta de un alto nivel de confianza en las instituciones.\nValidez: Dado que no se incorporan todas las posibles instituciones, el índice de Confianza en Instituciones creado no lograría cubrir el constructo totalmente, quedando fuera, por ejemplo, las instituciones militares o de fuerzas de orden. No obstante, permite medir de buena forma la confianza en las instituciones civiles y políticas."
  },
  {
    "objectID": "assignment/01-taller.html",
    "href": "assignment/01-taller.html",
    "title": "Práctico 1. Aproximación inicial a R",
    "section": "",
    "text": "Esta práctica tiene dos objetivos: 1) Generar un primer acercamiento al uso de R y Rstudio, conociendo su interfaz y sus principales funcionalidades y 2) revisar algunos procedimientos básicos de la preparación de datos con R, que son necesarios para luego poder aplicar los contenidos más específicos de este curso.\n\n\n\n\n\n\nAcceder a la página de posit, desarrollador del software desde octubre de 2022. Link directo a la descarga acá.\nInstalar R y Rstudio\n\n\n\nDescargar R\n\n\nSeleccionamos sistema operativo según corresponda\n\n\n\nDescargar R por primera vez y seguir instrucciones. En esta oportunidad trabajaremos con la última versión de R 4.2.2\n\n\n\nDescargar RStudio\n\n\nDescarga directa en la página de inicio\n\n\nInstalar ambos archivos siguiendo las instrucciones de instalación\n\n\nAbrir RStudio. Se debería ver similar a esto:\n\n\n\nRecomendaciones generales:\n\n\nevitar uso de tilde, ñ, espacios y mayúsculas tanto en carpetas y archivos, así como también en los nombres de las variables\nal momento de hacer consultas sobre problemas en la ejecución del código, adjuntar la siguiente información:\n\n\nCódigo completo hasta que se produce el problema\nIndicar línea del código donde se produce el problema\nAdjuntar el resultado del output de la información de la sesión (sessionInfo())\n\n\n\n\n\nEn primer lugar vamos a abrir un archivo de R (script). Esto se puede hacer manualmente con File -&gt; new file -&gt; R script o directamente con ctrl + shift + N\nEsta es nuestra hoja de código, que utilizaremos para procesar bases de datos, modificar variables y crear tablas y gráficos.\n\n\nR puede ser una calculadora\n\n10 + 5 # ¿cuánto es 10 + 5?\n\n[1] 15\n\n\n\n10 * 5 # ¿cuánto es 10 * 5?\n\n[1] 50\n\n\nSe pueden crear objetos y asignarles valores\n\na &lt;- 28\nb &lt;- 8\n\na + b\n\n[1] 36\n\n\nO asignar operaciones a un objeto\n\nc &lt;- a + b\n\nSin embargo, la mayor parte del tiempo usamos funciones que ya existen en R\n\nsum(28,8)\n\n[1] 36\n\n\n\nround(10.14536) #aproximar\n\n[1] 10\n\n\nY muchas de estas funciones que utilizamos en R están contenidas en librerías o paquetes (packages)\n\n\n\nLa lógica de R es instalar librerías (solo 1 vez, con install.packages(\"librería\")), y luego cargarlas cada vez que es necesario usarlas (con library(librería)). El problema de esto es que a veces no se sabe claramente qué librerías están instaladas y cuales no, lo que va a arrojar error al cargarlas. Y, como sucede en R, existe una librería para solucionar este problema que se llama pacman (package manager). Lo que hace pacman es cargar la librería, y si no está instalada, la instala y la carga:\nPara utilizar la primera vez (si es que no está instalada):\n\ninstall.packages(\"pacman\")\n\nY en adelante, las librerías se cargan así  pacman::p_load(libreria1,libreria2,libreriaX) :\n\npacman::p_load(dplyr, guaguas)\n\nInstalling package into 'C:/Users/kevin/AppData/Local/R/win-library/4.3'\n(as 'lib' is unspecified)\n\n\nWarning: unable to access index for repository http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.3:\n  no fue posible abrir la URL 'http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.3/PACKAGES'\n\n\npackage 'guaguas' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\kevin\\AppData\\Local\\Temp\\RtmpsnpiZD\\downloaded_packages\n\n\n\nguaguas installed\n\n\nWarning: package 'guaguas' was built under R version 4.3.3\n\n\nPara esta sesión las librerías que vamos a utilizar son:\n\ndplyr: ajuste general de datos\nguaguas: Paquete que contiene los datos de nombres de guaguas (bebés) registrados en Chile entre 1920 y 2021 según el Registro Civil e Identificación\n\n\n\n\nAjustar espacio de trabajo\nPrevio a la carga de nuestra base de datos, se recomienda ejecutar los siguientes comandos:\n\nrm(list=ls())       # borrar todos los objetos en el espacio de trabajo\noptions(scipen=999) # valores sin notación científica\n\nLa función rm(list=ls()) permite comenzar con un espacio de trabajo (environment) vacío y sin otros objetos. Así también, la función options(scipen=999) desactiva la notación científica, es decir, veremos los valores numéricos con todos sus decimales.\nDatos\nCargamos la base de datos desde el paquete (para otras bases de datos se deben importar de otra forma, esto es solo como ejemplo)\n\nbase &lt;- guaguas\n\nConocemos las dimensiones de la base de datos\n\ndim(base)\n\n[1] 858782      5\n\n\nSon 858782 casos y 5 variables. Los nombres de estas variables son:\n\nnames(base)\n\n[1] \"anio\"       \"nombre\"     \"sexo\"       \"n\"          \"proporcion\"\n\n\nY la base se ve así:\n\nhead(base)\n\n# A tibble: 6 × 5\n   anio nombre sexo      n proporcion\n  &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt;      &lt;dbl&gt;\n1  1920 María  F      2130     0.104 \n2  1920 José   M       984     0.0483\n3  1920 Juan   M       636     0.0312\n4  1920 Luis   M       631     0.0310\n5  1920 Rosa   F       426     0.0209\n6  1920 Ana    F       340     0.0167\n\n\nAhora probemos algunas funciones para seguir explorando la base\n\ntable(base$sexo)\n\n\n     F      I      M \n531038    318 327426 \n\n\nPodemos ver la cantidad de nombres “F” (femenino), “M” (masculino) e “I” (indefinido) inscritos entre 1920 y 2021.\nPueden buscar sus nombres y probar, utilizamos la funcion filter del paquete dplyr\n\nfilter(base, nombre==\"Kevin\")\n\n# A tibble: 63 × 5\n    anio nombre sexo      n proporcion\n   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt;      &lt;dbl&gt;\n 1  1931 Kevin  M         1 0.0000120 \n 2  1963 Kevin  M         1 0.0000035 \n 3  1964 Kevin  M         1 0.00000344\n 4  1967 Kevin  M         4 0.0000131 \n 5  1970 Kevin  M         6 0.0000210 \n 6  1971 Kevin  M         3 0.00000936\n 7  1972 Kevin  M         3 0.00000945\n 8  1973 Kevin  M         2 0.00000633\n 9  1974 Kevin  M         5 0.0000163 \n10  1976 Kevin  M         2 0.00000724\n# ℹ 53 more rows\n\n\nE incluso pueden ver la cantidad de personas con su nombre, en el mismo año que ustedes nacieron\n\nd &lt;- filter(base, nombre==\"Kevin\" & anio==1996)\nsum(d$n)\n\n[1] 1312"
  },
  {
    "objectID": "assignment/01-taller.html#objetivos-de-la-práctica",
    "href": "assignment/01-taller.html#objetivos-de-la-práctica",
    "title": "Práctico 1. Aproximación inicial a R",
    "section": "",
    "text": "Esta práctica tiene dos objetivos: 1) Generar un primer acercamiento al uso de R y Rstudio, conociendo su interfaz y sus principales funcionalidades y 2) revisar algunos procedimientos básicos de la preparación de datos con R, que son necesarios para luego poder aplicar los contenidos más específicos de este curso."
  },
  {
    "objectID": "assignment/01-taller.html#r-y-rstudio",
    "href": "assignment/01-taller.html#r-y-rstudio",
    "title": "Práctico 1. Aproximación inicial a R",
    "section": "",
    "text": "Acceder a la página de posit, desarrollador del software desde octubre de 2022. Link directo a la descarga acá.\nInstalar R y Rstudio\n\n\n\nDescargar R\n\n\nSeleccionamos sistema operativo según corresponda\n\n\n\nDescargar R por primera vez y seguir instrucciones. En esta oportunidad trabajaremos con la última versión de R 4.2.2\n\n\n\nDescargar RStudio\n\n\nDescarga directa en la página de inicio\n\n\nInstalar ambos archivos siguiendo las instrucciones de instalación\n\n\nAbrir RStudio. Se debería ver similar a esto:\n\n\n\nRecomendaciones generales:\n\n\nevitar uso de tilde, ñ, espacios y mayúsculas tanto en carpetas y archivos, así como también en los nombres de las variables\nal momento de hacer consultas sobre problemas en la ejecución del código, adjuntar la siguiente información:\n\n\nCódigo completo hasta que se produce el problema\nIndicar línea del código donde se produce el problema\nAdjuntar el resultado del output de la información de la sesión (sessionInfo())"
  },
  {
    "objectID": "assignment/01-taller.html#primeros-pasos",
    "href": "assignment/01-taller.html#primeros-pasos",
    "title": "Práctico 1. Aproximación inicial a R",
    "section": "",
    "text": "En primer lugar vamos a abrir un archivo de R (script). Esto se puede hacer manualmente con File -&gt; new file -&gt; R script o directamente con ctrl + shift + N\nEsta es nuestra hoja de código, que utilizaremos para procesar bases de datos, modificar variables y crear tablas y gráficos.\n\n\nR puede ser una calculadora\n\n10 + 5 # ¿cuánto es 10 + 5?\n\n[1] 15\n\n\n\n10 * 5 # ¿cuánto es 10 * 5?\n\n[1] 50\n\n\nSe pueden crear objetos y asignarles valores\n\na &lt;- 28\nb &lt;- 8\n\na + b\n\n[1] 36\n\n\nO asignar operaciones a un objeto\n\nc &lt;- a + b\n\nSin embargo, la mayor parte del tiempo usamos funciones que ya existen en R\n\nsum(28,8)\n\n[1] 36\n\n\n\nround(10.14536) #aproximar\n\n[1] 10\n\n\nY muchas de estas funciones que utilizamos en R están contenidas en librerías o paquetes (packages)\n\n\n\nLa lógica de R es instalar librerías (solo 1 vez, con install.packages(\"librería\")), y luego cargarlas cada vez que es necesario usarlas (con library(librería)). El problema de esto es que a veces no se sabe claramente qué librerías están instaladas y cuales no, lo que va a arrojar error al cargarlas. Y, como sucede en R, existe una librería para solucionar este problema que se llama pacman (package manager). Lo que hace pacman es cargar la librería, y si no está instalada, la instala y la carga:\nPara utilizar la primera vez (si es que no está instalada):\n\ninstall.packages(\"pacman\")\n\nY en adelante, las librerías se cargan así  pacman::p_load(libreria1,libreria2,libreriaX) :\n\npacman::p_load(dplyr, guaguas)\n\nInstalling package into 'C:/Users/kevin/AppData/Local/R/win-library/4.3'\n(as 'lib' is unspecified)\n\n\nWarning: unable to access index for repository http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.3:\n  no fue posible abrir la URL 'http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.3/PACKAGES'\n\n\npackage 'guaguas' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\kevin\\AppData\\Local\\Temp\\RtmpsnpiZD\\downloaded_packages\n\n\n\nguaguas installed\n\n\nWarning: package 'guaguas' was built under R version 4.3.3\n\n\nPara esta sesión las librerías que vamos a utilizar son:\n\ndplyr: ajuste general de datos\nguaguas: Paquete que contiene los datos de nombres de guaguas (bebés) registrados en Chile entre 1920 y 2021 según el Registro Civil e Identificación\n\n\n\n\nAjustar espacio de trabajo\nPrevio a la carga de nuestra base de datos, se recomienda ejecutar los siguientes comandos:\n\nrm(list=ls())       # borrar todos los objetos en el espacio de trabajo\noptions(scipen=999) # valores sin notación científica\n\nLa función rm(list=ls()) permite comenzar con un espacio de trabajo (environment) vacío y sin otros objetos. Así también, la función options(scipen=999) desactiva la notación científica, es decir, veremos los valores numéricos con todos sus decimales.\nDatos\nCargamos la base de datos desde el paquete (para otras bases de datos se deben importar de otra forma, esto es solo como ejemplo)\n\nbase &lt;- guaguas\n\nConocemos las dimensiones de la base de datos\n\ndim(base)\n\n[1] 858782      5\n\n\nSon 858782 casos y 5 variables. Los nombres de estas variables son:\n\nnames(base)\n\n[1] \"anio\"       \"nombre\"     \"sexo\"       \"n\"          \"proporcion\"\n\n\nY la base se ve así:\n\nhead(base)\n\n# A tibble: 6 × 5\n   anio nombre sexo      n proporcion\n  &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt;      &lt;dbl&gt;\n1  1920 María  F      2130     0.104 \n2  1920 José   M       984     0.0483\n3  1920 Juan   M       636     0.0312\n4  1920 Luis   M       631     0.0310\n5  1920 Rosa   F       426     0.0209\n6  1920 Ana    F       340     0.0167\n\n\nAhora probemos algunas funciones para seguir explorando la base\n\ntable(base$sexo)\n\n\n     F      I      M \n531038    318 327426 \n\n\nPodemos ver la cantidad de nombres “F” (femenino), “M” (masculino) e “I” (indefinido) inscritos entre 1920 y 2021.\nPueden buscar sus nombres y probar, utilizamos la funcion filter del paquete dplyr\n\nfilter(base, nombre==\"Kevin\")\n\n# A tibble: 63 × 5\n    anio nombre sexo      n proporcion\n   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt;      &lt;dbl&gt;\n 1  1931 Kevin  M         1 0.0000120 \n 2  1963 Kevin  M         1 0.0000035 \n 3  1964 Kevin  M         1 0.00000344\n 4  1967 Kevin  M         4 0.0000131 \n 5  1970 Kevin  M         6 0.0000210 \n 6  1971 Kevin  M         3 0.00000936\n 7  1972 Kevin  M         3 0.00000945\n 8  1973 Kevin  M         2 0.00000633\n 9  1974 Kevin  M         5 0.0000163 \n10  1976 Kevin  M         2 0.00000724\n# ℹ 53 more rows\n\n\nE incluso pueden ver la cantidad de personas con su nombre, en el mismo año que ustedes nacieron\n\nd &lt;- filter(base, nombre==\"Kevin\" & anio==1996)\nsum(d$n)\n\n[1] 1312"
  },
  {
    "objectID": "assignment/02-taller.html",
    "href": "assignment/02-taller.html",
    "title": "Taller 2",
    "section": "",
    "text": "Reforzar los procedimientos de operacionalización y construcción de indicadores sociales."
  },
  {
    "objectID": "assignment/02-taller.html#indicadores",
    "href": "assignment/02-taller.html#indicadores",
    "title": "Taller 2",
    "section": "Indicadores:",
    "text": "Indicadores:\n\nTasa de ocupación informal: porcentaje de Ocupados Informales respecto al total de los Ocupados del periodo de referencia (INE, 2021). Ello involucra a todas las personas cuyo trabajo no cuenta con características como un contrato escrito, pago a través de liquidaciones de sueldo, entre otros.\nDistribución de población indígena por comuna: porcentaje de habitantes en cada comuna que se identifican como pertenecientes a un pueblo indígena.\nConcentración de jefas de hogar según composición familiar: porcentaje de mujeres que adoptan el rol de jefas de hogar en hogares de distinta composición familiar (unipersonal, nuclear sin hij_s, nuclear con hij_s y monomaternal) respecto del total de jefas de hogar.\nÍndice de hacinamiento: razón entre el número de personas y el número de habitaciones usadas como dormitorios en una vivienda.\nTasa de atención médica ante problema de salud: porcentaje de personas que, habiendo tenido un problema de salud, pudieron recibir atención médica."
  },
  {
    "objectID": "assignment/02-taller.html#ejemplo-de-trabajo",
    "href": "assignment/02-taller.html#ejemplo-de-trabajo",
    "title": "Taller 2",
    "section": "Ejemplo de trabajo",
    "text": "Ejemplo de trabajo\nIndicador: Tasa de Inflación\nDefinición: Variación porcentual de un Índice de Precios de Consumo (IPC) respecto del periodo anterior. El IPC es un indicador que mide la variación media de bienes y servicios durante un período de tiempo determinado en una economía en específico.\nVariables necesarias: Precios de los bienes y servicios incluidos en la estimación del IPC para el periodo por analizar y el periodo anterior.\nFormalización:\n\\[TI = \\frac{IPC1-IPC0}{IPC0} * 100\\]\ndonde:\nTI = Tasa de Inflación,\nIPC1 = IPC del periodo por analizar\nIPC0 = IPC del periodo anterior\nPosibles valores: (- ∞, +∞) medidos en porcentaje (%).\nInterpretación: un valor positivo indica un aumento medio relativo del conjunto de precios de los bienes y servicios incluidos en la estimación del IPC, mientras que un valor negativo indica una disminución media relativa del conjunto de precios de los bienes y servicios incluidos en la estimación del IPC. Por ejemplo, una tasa de inflación de un 3,4% indica que, en promedio, el conjunto de los precios de bienes y servicios incluidos en la estimación del IPC aumentó en un 3.4% respecto del periodo anterior. Así, si un producto X tenía un precio de $1.000 en el periodo anterior, su precio en el periodo analizado debiese aproximarse a 1.000*1.034 = $1.034.\nLimitaciones: La definición de bienes y servicios incluidos en la estimación del IPC puede estar sujeta a lo que el gobierno o l_s funcionari_s del Estado consideren indispensable en los gastos mensuales de un hogar, dejando fuera algunos que pudiesen tener igual relevancia.\nPotencialidades: Permite medir de forma precisa los requerimientos de un hogar promedio mensual en relación a sus gastos fundamentales, por lo que hace posible conocer el estado de una economía en lo que respecta a su consumo.\nEj. de PP: Transferencias directas a hogares de bajos ingresos, para facilitar la satisfacción de necesidades básicas. Subvención gubernamental del precio de los productos con mayor aumento de precios entre ambos periodos."
  },
  {
    "objectID": "assignment/04-taller.html",
    "href": "assignment/04-taller.html",
    "title": "Taller 4",
    "section": "",
    "text": "Practicar la construcción de escalas y reflexionar en torno a la fiabilidad y la validez del instrumento."
  },
  {
    "objectID": "assignment/04-taller.html#constructos",
    "href": "assignment/04-taller.html#constructos",
    "title": "Taller 4",
    "section": "Constructos:",
    "text": "Constructos:\n\nFrecuencia en que se habla de política con amig_s.\nGrado de importancia otorgado a conocer a las personas indicadas para salir adelante en la vida.\nGrado de acuerdo sobre recortar los gastos gubernamentales.\nProbabilidad de mantenerse en un trabajo no satisfactorio por el beneficio de la vida familiar.\nGrado de acuerdo con la frase “En general, Chile es mejor que el resto de los países latinoamericanos”.\nGrado de importancia asignado a tener un trabajo con altos ingresos.\nGrado de acuerdo frente a la reducción de la regulación económica por parte del gobierno.\nGrado de acuerdo frente a la frase “me siento orgullos_ de ser chilen_”.\nFrecuencia en que se trabaja por un tema que le afecta a sí mism_ o alguien de su comunidad.\nGrado de importancia otorgado a venir de una familia adinerada para salir adelante en la vida.\nProbabilidad de renunciar a una buena oportunidad laboral en beneficio de la vida familiar.\nGrado de acuerdo frente a la frase “prefiero haber nacido en Chile, en lugar de cualquier otro país latinoamericano”.\nGrado de importancia de tener un alto nivel educativo para salir adelante en la vida.\nGrado de importancia otorgado a tener un trabajo seguro.\nFrecuencia en que se intenta convencer a otr_s de lo que se piensa políticamente.\nGrado de acuerdo frente a la ampliación de tratados de libre comercio firmados por el gobierno.\nProbabilidad de trabajar menos horas para trabajar en labores domésticas.\nGrado de acuerdo con la frase “El gobierno debiese apoyar más a las empresas nacionales que a las compañías internacionales”.\nFrecuencia en que se trabaja para un partido político o candidat_.\nGrado de importancia de trabajar duro para salir adelante en la vida.\nGrado de importancia otorgado a tener buenas oportunidades para hacer carrera profesional."
  },
  {
    "objectID": "assignment/index.html",
    "href": "assignment/index.html",
    "title": "Talleres",
    "section": "",
    "text": "En esta sección se encuentran los talleres prácticos realizados en el segundo bloque de clases"
  },
  {
    "objectID": "content/index.html",
    "href": "content/index.html",
    "title": "Readings, lectures, and videos",
    "section": "",
    "text": "En construcción"
  },
  {
    "objectID": "example/index.html",
    "href": "example/index.html",
    "title": "Code examples",
    "section": "",
    "text": "Visit this section after you have finished the readings and lecture videos. It contains fully annotated R code and other supplementary information and it will be indispensable as you work on your problem sets and project.\nMany sections also contain videos of me live coding the examples so you can see what it looks like to work with R in real time. You’ll notice me make all sorts of little errors, which is totally normal—everyone does!"
  },
  {
    "objectID": "news/2023-01-09_welcome.html",
    "href": "news/2023-01-09_welcome.html",
    "title": "Bienvenid_s a clases!",
    "section": "",
    "text": "← News\n\n\n\nHola a todos!"
  },
  {
    "objectID": "news/index.html",
    "href": "news/index.html",
    "title": "Noticias",
    "section": "",
    "text": "Ordenar por\n       Por defecto\n         \n          Fecha - Menos reciente\n        \n         \n          Fecha - Más reciente\n        \n         \n          Título\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nFecha\n\n\nTítulo\n\n\nCategorías\n\n\n\n\n\n\nlunes agosto 7, 2023 at 12:00 AM\n\n\nBienvenid_s a clases!\n\n\ncomenzando\n\n\n\n\nlunes agosto 7, 2023 at 12:00 AM\n\n\nInformaciones de la semana\n\n\ninfo\n\n\n\n\n\n\nNo hay resultados\n\n\n\n\n\n\n\n\nSuscribirse!\n\n\n\nPuedes usar un lector de feeds como Feedly o un servicio RSS-to-email como Blogtrottr para suscribirte a cualquiera de estos mensajes. ::: {.grid}\n\n\n RSS\n\n\n\n\n\n\n\n\n\n:::"
  },
  {
    "objectID": "practicos/02-content.html",
    "href": "practicos/02-content.html",
    "title": "Práctico R 2. Construcción de escalas",
    "section": "",
    "text": "Para el taller práctico de hoy utilizaremos la base de datos del estudio de Martin et al. (2003). Individual differences in uses of humor and and their relation to psychological well-being. Development of the Humor Styles Questionnaire.\nEn este artículo se describe el desarrollo y la validación inicial del Cuestionario de Estilos de Humor, que evalúa cuatro dimensiones relacionadas con las diferencias individuales en el uso del humor. Estas son: usos relativamente benignos del humor para mejorar uno mismo (Autofortalecedor) y para mejorar las relaciones con otros (Afiliativo), uso del humor para mejorar uno mismo a expensas de los demás (Agresivo) y uso del humor para mejorar las relaciones a expensas de uno mismo (Autodestructivo)."
  },
  {
    "objectID": "practicos/02-content.html#cargar-librerías",
    "href": "practicos/02-content.html#cargar-librerías",
    "title": "Práctico R 2. Construcción de escalas",
    "section": "Cargar librerías",
    "text": "Cargar librerías\nLas librerías que utilizaremos esta sesión son las siguientes:\n\n\nCódigo\n# install.packages(\"pacman\") # Cargar sólo si no la tenemos instalada\nlibrary(pacman)\npacman::p_load(tidyverse, # conjunto de paquetes, sobre todo dplyr y ggplot2\n               car,       # para recodificar\n               psych,     # para Alfa de Chronbach\n               sjmisc,    # para descriptivos\n               remotes,   # para instalar paquete jogRu\n               readr)     # para cargararchivo csv\n\noptions(scipen = 999) # para desactivar notacion cientifica\nrm(list = ls())       # para limpiar el entorno de trabajo\n\n\nAdemás, instalaremos la librería jogRu desde github, que nos permitirá calcular el alfa de Chronbach para variables ordinales.\n\n\nCódigo\nremotes::install_github(\"jogrue/jogRu\", force = T)\n\n\nyaml       (2.3.7  -&gt; 2.3.8 ) [CRAN]\nxfun       (0.41   -&gt; 0.42  ) [CRAN]\nglue       (1.6.2  -&gt; 1.7.0 ) [CRAN]\ncli        (3.6.1  -&gt; 3.6.2 ) [CRAN]\ndigest     (0.6.33 -&gt; 0.6.34) [CRAN]\nsass       (0.4.7  -&gt; 0.4.8 ) [CRAN]\nrlang      (1.1.2  -&gt; 1.1.3 ) [CRAN]\njsonlite   (1.8.7  -&gt; 1.8.8 ) [CRAN]\nbslib      (0.6.0  -&gt; 0.6.1 ) [CRAN]\nfansi      (1.0.5  -&gt; 1.0.6 ) [CRAN]\nwithr      (2.5.2  -&gt; 3.0.0 ) [CRAN]\nvctrs      (0.6.4  -&gt; 0.6.5 ) [CRAN]\nscales     (1.2.1  -&gt; 1.3.0 ) [CRAN]\nggplot2    (3.4.4  -&gt; 3.5.0 ) [CRAN]\nstringi    (1.8.2  -&gt; 1.8.3 ) [CRAN]\nrmarkdown  (2.25   -&gt; 2.26  ) [CRAN]\ncheckmate  (2.3.0  -&gt; 2.3.1 ) [CRAN]\nviridis    (0.6.4  -&gt; 0.6.5 ) [CRAN]\ndata.table (1.14.8 -&gt; 1.15.2) [CRAN]\npsych      (2.3.9  -&gt; 2.4.1 ) [CRAN]\npackage 'yaml' successfully unpacked and MD5 sums checked\npackage 'xfun' successfully unpacked and MD5 sums checked\npackage 'glue' successfully unpacked and MD5 sums checked\npackage 'cli' successfully unpacked and MD5 sums checked\npackage 'digest' successfully unpacked and MD5 sums checked\npackage 'sass' successfully unpacked and MD5 sums checked\npackage 'rlang' successfully unpacked and MD5 sums checked\npackage 'jsonlite' successfully unpacked and MD5 sums checked\npackage 'bslib' successfully unpacked and MD5 sums checked\npackage 'fansi' successfully unpacked and MD5 sums checked\npackage 'withr' successfully unpacked and MD5 sums checked\npackage 'vctrs' successfully unpacked and MD5 sums checked\npackage 'scales' successfully unpacked and MD5 sums checked\npackage 'stringi' successfully unpacked and MD5 sums checked\npackage 'rmarkdown' successfully unpacked and MD5 sums checked\npackage 'checkmate' successfully unpacked and MD5 sums checked\npackage 'viridis' successfully unpacked and MD5 sums checked\npackage 'data.table' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\kevin\\AppData\\Local\\Temp\\RtmpWYEV8s\\downloaded_packages\n── R CMD build ─────────────────────────────────────────────────────────────────\n* checking for file 'C:\\Users\\kevin\\AppData\\Local\\Temp\\RtmpWYEV8s\\remotes7acc38d17123\\jogrue-jogRu-c659fcd/DESCRIPTION' ... OK\n* preparing 'jogRu':\n* checking DESCRIPTION meta-information ... OK\n* checking for LF line-endings in source and make files and shell scripts\n* checking for empty or unneeded directories\nOmitted 'LazyData' from DESCRIPTION\n* building 'jogRu_2.0.tar.gz'\n\n\n\n\n\n\n\n\n\nNota\n\n\n\nSi pregunta These packages have more recent versions available. It is recommended to update all of them.Which would you like to update? SIEMPRE PONER 3: None."
  },
  {
    "objectID": "practicos/02-content.html#datos-y-variables",
    "href": "practicos/02-content.html#datos-y-variables",
    "title": "Práctico R 2. Construcción de escalas",
    "section": "Datos y variables",
    "text": "Datos y variables\nComo mencionamos, utilizaremos la base de datos del estudio Martin et al. (2003). Individual differences in uses of humor and and their relation to psychological well-being. Development of the Humor Styles Questionnaire.\nEn estos datos podemos ver una serie de ítems que corresponden a diferentes dimensiones de la escala, donde cada ítem tiene valores entre 1 y 5. De acuerdo con el paper, los ítems se ordenan de esta forma de acuerdo con los tipos de humor:\n\nafiliativo : Q1, Q5, Q9 , Q13, Q17, Q21, Q25, Q29\nautofortalecedor : Q2, Q6, Q10, Q14, Q18, Q22, Q26, Q30\nagresivo : Q3, Q7, Q11, Q15, Q19, Q23, Q27, Q31\nautodestructivo : Q4, Q8, Q12, Q16, Q20, Q24, Q28, Q32\n\n\nCargar base de datos\n\n\nCódigo\ndata &lt;- read.csv(url(\"https://github.com/cursos-metodos-facso/investigacion-cuantitativa/raw/main/files/data/data.csv\"))\n\n\n\n\nVisualización de datos\n\n\nCódigo\nhead(data)\n\n\n  Q1 Q2 Q3 Q4 Q5 Q6 Q7 Q8 Q9 Q10 Q11 Q12 Q13 Q14 Q15 Q16 Q17 Q18 Q19 Q20 Q21\n1  2  2  3  1  4  5  4  3  4   3   3   1   5   4   4   4   2   3   3   1   4\n2  2  3  2  2  4  4  4  3  4   3   4   3   3   4   5   4   2   2   3   2   3\n3  3  4  3  3  4  4  3  1  2   4   3   2   4   4   3   3   2   4   2   1   4\n4  3  3  3  4  3  5  4  3 -1   4   2   4   4   5   4   3   3   3   3   3   4\n5  1  4  2  2  3  5  4  1  4   4   2   2   5   4   4   4   2   3   2   1   5\n6  3  3  3  2  3  3  4  2  2   1   3   3   4   4   4   3   2   1   4   2   4\n  Q22 Q23 Q24 Q25 Q26 Q27 Q28 Q29 Q30 Q31 Q32 affiliative selfenhancing\n1   4   3   2   1   3   2   4   2   4   2   2         4.0           3.5\n2   3   4   2   2   5   1   2   4   4   3   1         3.3           3.5\n3   2   4   3   2   4   3   3   2   5   4   2         3.9           3.9\n4   3   2   4   2   4   2   2   4   5   3   3         3.6           4.0\n5   3   3   1   1   5   2   3   2   5   4   2         4.1           4.1\n6   4   4   2   2   3   2   4   3   4   3   3         3.6           2.9\n  agressive selfdefeating age gender accuracy\n1       3.0           2.3  25      2      100\n2       3.3           2.4  44      2       90\n3       3.1           2.3  50      1       75\n4       2.9           3.3  30      2       85\n5       2.9           2.0  52      1       80\n6       3.4           2.6  30      2       60\n\n\nCódigo\nstr(data)\n\n\n'data.frame':   1071 obs. of  39 variables:\n $ Q1           : int  2 2 3 3 1 3 4 2 2 4 ...\n $ Q2           : int  2 3 4 3 4 3 1 4 2 2 ...\n $ Q3           : int  3 2 3 3 2 3 2 4 1 4 ...\n $ Q4           : int  1 2 3 4 2 2 4 1 1 1 ...\n $ Q5           : int  4 4 4 3 3 3 2 5 3 3 ...\n $ Q6           : int  5 4 4 5 5 3 3 5 4 5 ...\n $ Q7           : int  4 4 3 4 4 4 3 4 3 4 ...\n $ Q8           : int  3 3 1 3 1 2 3 3 1 2 ...\n $ Q9           : int  4 4 2 -1 4 2 4 2 3 3 ...\n $ Q10          : int  3 3 4 4 4 1 4 4 3 1 ...\n $ Q11          : int  3 4 3 2 2 3 4 3 2 5 ...\n $ Q12          : int  1 3 2 4 2 3 1 3 2 3 ...\n $ Q13          : int  5 3 4 4 5 4 2 5 5 1 ...\n $ Q14          : int  4 4 4 5 4 4 1 4 3 3 ...\n $ Q15          : int  4 5 3 4 4 4 2 3 3 1 ...\n $ Q16          : int  4 4 3 3 4 3 4 3 4 5 ...\n $ Q17          : int  2 2 2 3 2 2 4 3 2 5 ...\n $ Q18          : int  3 2 4 3 3 1 1 4 2 1 ...\n $ Q19          : int  3 3 2 3 2 4 3 5 4 3 ...\n $ Q20          : int  1 2 1 3 1 2 1 3 1 1 ...\n $ Q21          : int  4 3 4 4 5 4 3 4 4 2 ...\n $ Q22          : int  4 3 2 3 3 4 2 3 4 1 ...\n $ Q23          : int  3 4 4 2 3 4 2 3 4 5 ...\n $ Q24          : int  2 2 3 4 1 2 3 1 2 2 ...\n $ Q25          : int  1 2 2 2 1 2 4 1 1 4 ...\n $ Q26          : int  3 5 4 4 5 3 3 4 3 5 ...\n $ Q27          : int  2 1 3 2 2 2 2 2 4 5 ...\n $ Q28          : int  4 2 3 2 3 4 2 4 4 2 ...\n $ Q29          : int  2 4 2 4 2 3 3 1 1 1 ...\n $ Q30          : int  4 4 5 5 5 4 3 5 5 5 ...\n $ Q31          : int  2 3 4 3 4 3 4 2 2 3 ...\n $ Q32          : int  2 1 2 3 2 3 4 2 1 2 ...\n $ affiliative  : num  4 3.3 3.9 3.6 4.1 3.6 2.3 4.4 4.1 2.4 ...\n $ selfenhancing: num  3.5 3.5 3.9 4 4.1 2.9 2.3 4.1 3.3 2.9 ...\n $ agressive    : num  3 3.3 3.1 2.9 2.9 3.4 2.8 3.3 2.9 3.8 ...\n $ selfdefeating: num  2.3 2.4 2.3 3.3 2 2.6 2.8 2.5 2 2.3 ...\n $ age          : int  25 44 50 30 52 30 27 34 30 18 ...\n $ gender       : int  2 2 1 2 1 2 1 1 2 1 ...\n $ accuracy     : int  100 90 75 85 80 60 60 88 95 85 ..."
  },
  {
    "objectID": "practicos/02-content.html#procesamiento",
    "href": "practicos/02-content.html#procesamiento",
    "title": "Práctico R 2. Construcción de escalas",
    "section": "Procesamiento",
    "text": "Procesamiento\n\nRecodificar\nPara que todas las escalas queden en el mismo orden jerárquico, es necesario invertir algunos ítems.\n\n\nCódigo\ndata = data %&gt;% \n  mutate_at(vars(Q1, Q9, Q17, Q25, Q29, # afiliativo\n                 Q22,                   # autofortalecedor\n                 Q7, Q15, Q23, Q31,     # agresivo\n                 Q16), ~(6-.)) %&gt;%      # autodestructivo\n  mutate(gender = car::recode(.$gender, \"0 = NA;\n                              1 = 'Hombre'; 2 = 'Mujer'; 3 = 'Otro'\")) %&gt;% \n  mutate_at(vars(1:32), ~(ifelse(. &lt; 1 | . &gt; 5, NA, .))) %&gt;% \n  na.omit()\n\n\n\n\nCrear objetos para dimensiones de la escala\nCreamos cuatro objetos que contienen los ítems de cada dimensión de la escala.\n\n\nCódigo\nafiliativo       &lt;- data %&gt;% select(Q1, Q5, Q9 , Q13, Q17, Q21, Q25, Q29)\nautofortalecedor &lt;- data %&gt;% select(Q2, Q6, Q10, Q14, Q18, Q22, Q26, Q30)\nagresivo         &lt;- data %&gt;% select(Q3, Q7, Q11, Q15, Q19, Q23, Q27, Q31)\nautodestructivo  &lt;- data %&gt;% select(Q4, Q8, Q12, Q16, Q20, Q24, Q28, Q32)"
  },
  {
    "objectID": "practicos/02-content.html#explorar-datos",
    "href": "practicos/02-content.html#explorar-datos",
    "title": "Práctico R 2. Construcción de escalas",
    "section": "Explorar datos",
    "text": "Explorar datos\n\nDescriptivos\n\n\nCódigo\n# Medias para cada dimensión\ndata %&gt;% \n  summarise(Afiliativo = mean(affiliative),\n            Autofortalecedor = mean(selfenhancing),\n            Agresivo = mean(agressive),\n            Autodestructivo = mean(selfdefeating))\n\n\n  Afiliativo Autofortalecedor Agresivo Autodestructivo\n1   4.010628         3.392308 2.968219        2.767308\n\n\nCódigo\n# Frecuencias por género\ntable(data$gender)\n\n\n\nHombre  Mujer   Otro \n   537    443      8 \n\n\nCódigo\n# Medias para cada dimensión por género\ndata %&gt;% group_by(gender) %&gt;% \n  summarise(Afiliativo = mean(affiliative),\n            Autofortalecedor = mean(selfenhancing),\n            Agresivo = mean(agressive),\n            Autodestructivo = mean(selfdefeating))\n\n\n# A tibble: 3 × 5\n  gender Afiliativo Autofortalecedor Agresivo Autodestructivo\n  &lt;chr&gt;       &lt;dbl&gt;            &lt;dbl&gt;    &lt;dbl&gt;           &lt;dbl&gt;\n1 Hombre       4.05             3.38     2.95            2.82\n2 Mujer        3.97             3.40     2.99            2.70\n3 Otro         3.52             3.45     2.89            2.6"
  },
  {
    "objectID": "practicos/02-content.html#análisis",
    "href": "practicos/02-content.html#análisis",
    "title": "Práctico R 2. Construcción de escalas",
    "section": "Análisis",
    "text": "Análisis\n\nEstimar correlación\nSe debe estimar la correlación de cada dimensión de la escala por separado.\n\n\nCódigo\n# Afiliativo\ncor(afiliativo)\n\n\n           Q1        Q5        Q9       Q13       Q17       Q21       Q25\nQ1  1.0000000 0.4219343 0.3171529 0.4266762 0.5290245 0.4568504 0.4618863\nQ5  0.4219343 1.0000000 0.3719656 0.3715378 0.4780982 0.4521887 0.3411674\nQ9  0.3171529 0.3719656 1.0000000 0.2707130 0.4179284 0.3144385 0.3202277\nQ13 0.4266762 0.3715378 0.2707130 1.0000000 0.4546202 0.4517790 0.6102194\nQ17 0.5290245 0.4780982 0.4179284 0.4546202 1.0000000 0.5817920 0.5061191\nQ21 0.4568504 0.4521887 0.3144385 0.4517790 0.5817920 1.0000000 0.4455769\nQ25 0.4618863 0.3411674 0.3202277 0.6102194 0.5061191 0.4455769 1.0000000\nQ29 0.3706320 0.4804055 0.3019961 0.2697704 0.3851621 0.3156306 0.3451300\n          Q29\nQ1  0.3706320\nQ5  0.4804055\nQ9  0.3019961\nQ13 0.2697704\nQ17 0.3851621\nQ21 0.3156306\nQ25 0.3451300\nQ29 1.0000000\n\n\nCódigo\n# Autofortalecedor\ncor(autofortalecedor)\n\n\n           Q2        Q6       Q10       Q14       Q18       Q22       Q26\nQ2  1.0000000 0.2741238 0.4379514 0.4405901 0.4886435 0.3370991 0.4080850\nQ6  0.2741238 1.0000000 0.2979399 0.3707698 0.2519714 0.1492299 0.3772628\nQ10 0.4379514 0.2979399 1.0000000 0.4806244 0.6198183 0.2680397 0.5483005\nQ14 0.4405901 0.3707698 0.4806244 1.0000000 0.4837968 0.3347620 0.5288270\nQ18 0.4886435 0.2519714 0.6198183 0.4837968 1.0000000 0.2669016 0.4605230\nQ22 0.3370991 0.1492299 0.2680397 0.3347620 0.2669016 1.0000000 0.2640024\nQ26 0.4080850 0.3772628 0.5483005 0.5288270 0.4605230 0.2640024 1.0000000\nQ30 0.2449183 0.4615775 0.2744784 0.3193377 0.2713470 0.1709110 0.2913439\n          Q30\nQ2  0.2449183\nQ6  0.4615775\nQ10 0.2744784\nQ14 0.3193377\nQ18 0.2713470\nQ22 0.1709110\nQ26 0.2913439\nQ30 1.0000000\n\n\nCódigo\n# Agresivo\ncor(agresivo)\n\n\n           Q3        Q7       Q11       Q15       Q19       Q23       Q27\nQ3  1.0000000 0.2839415 0.2631534 0.3945511 0.2853576 0.3608919 0.3484064\nQ7  0.2839415 1.0000000 0.3208911 0.3963730 0.2809997 0.2102096 0.2953999\nQ11 0.2631534 0.3208911 1.0000000 0.3051340 0.3479591 0.1701522 0.2974286\nQ15 0.3945511 0.3963730 0.3051340 1.0000000 0.2506681 0.4130468 0.3897974\nQ19 0.2853576 0.2809997 0.3479591 0.2506681 1.0000000 0.1999011 0.2452251\nQ23 0.3608919 0.2102096 0.1701522 0.4130468 0.1999011 1.0000000 0.2566352\nQ27 0.3484064 0.2953999 0.2974286 0.3897974 0.2452251 0.2566352 1.0000000\nQ31 0.3299510 0.4019467 0.3671049 0.4480359 0.3804564 0.3925590 0.2855325\n          Q31\nQ3  0.3299510\nQ7  0.4019467\nQ11 0.3671049\nQ15 0.4480359\nQ19 0.3804564\nQ23 0.3925590\nQ27 0.2855325\nQ31 1.0000000\n\n\nCódigo\n# Autodestructivo\ncor(autodestructivo)\n\n\n           Q4        Q8       Q12       Q16       Q20       Q24       Q28\nQ4  1.0000000 0.4659424 0.4125085 0.3313143 0.4417460 0.3942768 0.2305862\nQ8  0.4659424 1.0000000 0.4461332 0.4485728 0.6668889 0.3049158 0.2667078\nQ12 0.4125085 0.4461332 1.0000000 0.4302414 0.4807727 0.2612307 0.2578115\nQ16 0.3313143 0.4485728 0.4302414 1.0000000 0.4550186 0.2174461 0.1671081\nQ20 0.4417460 0.6668889 0.4807727 0.4550186 1.0000000 0.2981969 0.2213669\nQ24 0.3942768 0.3049158 0.2612307 0.2174461 0.2981969 1.0000000 0.1520322\nQ28 0.2305862 0.2667078 0.2578115 0.1671081 0.2213669 0.1520322 1.0000000\nQ32 0.4663633 0.5203096 0.4561579 0.4193331 0.4643564 0.3624751 0.2355325\n          Q32\nQ4  0.4663633\nQ8  0.5203096\nQ12 0.4561579\nQ16 0.4193331\nQ20 0.4643564\nQ24 0.3624751\nQ28 0.2355325\nQ32 1.0000000\n\n\nPodemos observar que todas las correlaciones son positivas, por lo que no quedaron ítems invertidos.\n\n\nEstimar consistencia interna\n\nAlfa de Chronbach\nPrimero, estimaremos la consistencia interna de cada dimensión con un alfa de Chronbach. El alfa de Chronbach, es un estadístico que permite estimar la fiabilidad de un test por consistencia interna. Su ventaja es que es fácil de estimar. Sus desventajas, sin embargo, son que:\n\nPuede aumentarse artificialmente incorporando ítems parecidos;\nAsume que el constructo es unidimensional;\nEs afectado por número de ítems, el número de alternativas de respuesta y la varianza del test (Domínguez-Lara & Merino-Soto, 2015).\n\nPara interpretarlo hay que considerar:\n\nMínimo para investigación básica exploratoria: &gt; .7\nMínimo para investigación asociativa: &gt; .8\nInvestigación con decisiones muy importantes: &gt; .9 (Nunnally & Bernstein, 1994).\n\nA mayor valor, más consistente es la escala:\n\nConsideraremos el 0.6 como punto de corte.\n\n\n\n\n\n\n\nNota\n\n\n\nADVERTENCIA: el alfa de Chronbarch es para variables con nivel de medición intervalar. Lo óptimo para variables ordinales es Alfa Ordinal u Omega (Ventura-León & Caycho-Rodríguez, 2017).\n\n\nAsimismo, esperamos que la correlación de cada ítem respecto del total sea al menos de .4 (media) y, ojalá, de al menos .6 (alta). Ítems con correlaciones muy bajas podrían eliminarse, especialmente si el alfa de Chronbach aumenta en caso de que el ítem sea eliminado.\n\n\nCódigo\npsych::alpha(afiliativo)\n\n\n\nReliability analysis   \nCall: psych::alpha(x = afiliativo)\n\n  raw_alpha std.alpha G6(smc) average_r S/N    ase mean  sd median_r\n      0.84      0.85    0.84      0.41 5.6 0.0077    4 0.7     0.42\n\n    95% confidence boundaries \n         lower alpha upper\nFeldt     0.82  0.84  0.85\nDuhachek  0.82  0.84  0.85\n\n Reliability if an item is dropped:\n    raw_alpha std.alpha G6(smc) average_r S/N alpha se  var.r med.r\nQ1       0.82      0.83    0.82      0.40 4.7   0.0089 0.0092  0.39\nQ5       0.82      0.83    0.82      0.41 4.8   0.0089 0.0097  0.42\nQ9       0.84      0.84    0.84      0.44 5.4   0.0078 0.0071  0.45\nQ13      0.82      0.83    0.82      0.41 4.9   0.0086 0.0065  0.42\nQ17      0.80      0.82    0.81      0.39 4.4   0.0095 0.0071  0.37\nQ21      0.82      0.83    0.82      0.40 4.7   0.0088 0.0079  0.39\nQ25      0.82      0.82    0.81      0.40 4.7   0.0088 0.0071  0.42\nQ29      0.83      0.84    0.83      0.43 5.3   0.0081 0.0078  0.45\n\n Item statistics \n      n raw.r std.r r.cor r.drop mean   sd\nQ1  988  0.72  0.72  0.66   0.60  4.0 1.06\nQ5  988  0.71  0.70  0.65   0.60  3.6 1.03\nQ9  988  0.62  0.60  0.50   0.46  3.4 1.21\nQ13 988  0.66  0.69  0.64   0.56  4.5 0.84\nQ17 988  0.79  0.78  0.76   0.69  4.1 1.10\nQ21 988  0.70  0.72  0.67   0.61  4.4 0.85\nQ25 988  0.70  0.72  0.69   0.61  4.4 0.84\nQ29 988  0.65  0.62  0.54   0.50  3.7 1.18\n\nNon missing response frequency for each item\n       1    2    3    4    5 miss\nQ1  0.03 0.08 0.16 0.35 0.37    0\nQ5  0.04 0.10 0.27 0.38 0.20    0\nQ9  0.09 0.16 0.20 0.37 0.18    0\nQ13 0.01 0.03 0.07 0.27 0.62    0\nQ17 0.04 0.07 0.14 0.30 0.45    0\nQ21 0.01 0.03 0.09 0.29 0.58    0\nQ25 0.01 0.03 0.06 0.29 0.60    0\nQ29 0.06 0.11 0.20 0.34 0.28    0\n\n\nCódigo\npsych::alpha(autofortalecedor)\n\n\n\nReliability analysis   \nCall: psych::alpha(x = autofortalecedor)\n\n  raw_alpha std.alpha G6(smc) average_r S/N    ase mean   sd median_r\n      0.82      0.82    0.82      0.36 4.5 0.0085  3.4 0.75     0.34\n\n    95% confidence boundaries \n         lower alpha upper\nFeldt      0.8  0.82  0.84\nDuhachek   0.8  0.82  0.84\n\n Reliability if an item is dropped:\n    raw_alpha std.alpha G6(smc) average_r S/N alpha se var.r med.r\nQ2       0.80      0.80    0.79      0.36 3.9   0.0098 0.016  0.32\nQ6       0.81      0.81    0.80      0.38 4.3   0.0091 0.015  0.34\nQ10      0.79      0.78    0.78      0.34 3.6   0.0103 0.011  0.33\nQ14      0.78      0.78    0.78      0.34 3.6   0.0104 0.015  0.29\nQ18      0.79      0.79    0.78      0.35 3.7   0.0102 0.012  0.33\nQ22      0.82      0.82    0.82      0.40 4.6   0.0084 0.012  0.41\nQ26      0.79      0.79    0.78      0.34 3.7   0.0102 0.014  0.32\nQ30      0.82      0.81    0.81      0.39 4.4   0.0088 0.014  0.38\n\n Item statistics \n      n raw.r std.r r.cor r.drop mean   sd\nQ2  988  0.68  0.68  0.62   0.57  3.3 1.09\nQ6  988  0.57  0.60  0.52   0.45  4.2 0.94\nQ10 988  0.75  0.74  0.71   0.64  2.9 1.18\nQ14 988  0.76  0.74  0.70   0.64  3.3 1.24\nQ18 988  0.73  0.72  0.69   0.62  2.8 1.17\nQ22 988  0.54  0.53  0.41   0.37  3.0 1.19\nQ26 988  0.73  0.73  0.69   0.62  3.6 1.13\nQ30 988  0.55  0.57  0.48   0.41  4.0 1.05\n\nNon missing response frequency for each item\n       1    2    3    4    5 miss\nQ2  0.06 0.16 0.30 0.33 0.15    0\nQ6  0.01 0.05 0.13 0.35 0.45    0\nQ10 0.14 0.25 0.29 0.23 0.09    0\nQ14 0.09 0.19 0.25 0.27 0.20    0\nQ18 0.16 0.28 0.28 0.21 0.07    0\nQ22 0.12 0.26 0.27 0.24 0.11    0\nQ26 0.06 0.12 0.26 0.35 0.22    0\nQ30 0.02 0.09 0.16 0.35 0.39    0\n\n\nCódigo\npsych::alpha(agresivo)\n\n\n\nReliability analysis   \nCall: psych::alpha(x = agresivo)\n\n  raw_alpha std.alpha G6(smc) average_r S/N  ase mean   sd median_r\n      0.79      0.79    0.78      0.32 3.7 0.01  2.9 0.78     0.31\n\n    95% confidence boundaries \n         lower alpha upper\nFeldt     0.77  0.79  0.81\nDuhachek  0.77  0.79  0.81\n\n Reliability if an item is dropped:\n    raw_alpha std.alpha G6(smc) average_r S/N alpha se  var.r med.r\nQ3       0.77      0.76    0.75      0.32 3.2    0.011 0.0061  0.31\nQ7       0.77      0.77    0.75      0.32 3.3    0.011 0.0054  0.33\nQ11      0.77      0.77    0.75      0.33 3.4    0.011 0.0053  0.33\nQ15      0.75      0.75    0.73      0.30 3.0    0.012 0.0041  0.30\nQ19      0.78      0.78    0.76      0.33 3.4    0.011 0.0051  0.33\nQ23      0.77      0.77    0.75      0.33 3.4    0.011 0.0033  0.32\nQ27      0.77      0.77    0.75      0.32 3.4    0.011 0.0059  0.33\nQ31      0.75      0.75    0.73      0.30 3.0    0.012 0.0046  0.30\n\n Item statistics \n      n raw.r std.r r.cor r.drop mean  sd\nQ3  988  0.64  0.64  0.57   0.50  3.1 1.2\nQ7  988  0.61  0.63  0.55   0.49  2.7 1.1\nQ11 988  0.61  0.60  0.52   0.46  2.7 1.2\nQ15 988  0.72  0.71  0.66   0.58  2.6 1.3\nQ19 988  0.59  0.59  0.49   0.44  3.2 1.2\nQ23 988  0.59  0.59  0.51   0.44  3.2 1.2\nQ27 988  0.62  0.61  0.53   0.47  2.3 1.3\nQ31 988  0.71  0.71  0.66   0.59  3.2 1.3\n\nNon missing response frequency for each item\n       1    2    3    4    5 miss\nQ3  0.10 0.21 0.30 0.27 0.11    0\nQ7  0.13 0.33 0.32 0.16 0.07    0\nQ11 0.17 0.32 0.19 0.22 0.09    0\nQ15 0.30 0.22 0.20 0.19 0.10    0\nQ19 0.10 0.19 0.24 0.30 0.17    0\nQ23 0.09 0.21 0.28 0.28 0.15    0\nQ27 0.36 0.28 0.15 0.13 0.07    0\nQ31 0.10 0.22 0.24 0.22 0.20    0\n\n\nCódigo\npsych::alpha(autodestructivo)\n\n\n\nReliability analysis   \nCall: psych::alpha(x = autodestructivo)\n\n  raw_alpha std.alpha G6(smc) average_r S/N    ase mean   sd median_r\n      0.82      0.82    0.82      0.37 4.6 0.0086  2.7 0.79      0.4\n\n    95% confidence boundaries \n         lower alpha upper\nFeldt      0.8  0.82  0.84\nDuhachek   0.8  0.82  0.84\n\n Reliability if an item is dropped:\n    raw_alpha std.alpha G6(smc) average_r S/N alpha se  var.r med.r\nQ4       0.79      0.80    0.79      0.36 3.9   0.0100 0.0179  0.36\nQ8       0.78      0.78    0.77      0.34 3.6   0.0107 0.0122  0.36\nQ12      0.79      0.80    0.79      0.36 3.9   0.0100 0.0175  0.36\nQ16      0.80      0.81    0.80      0.37 4.1   0.0096 0.0161  0.39\nQ20      0.78      0.79    0.77      0.35 3.7   0.0104 0.0123  0.36\nQ24      0.82      0.82    0.81      0.39 4.6   0.0089 0.0151  0.44\nQ28      0.83      0.83    0.82      0.42 5.0   0.0081 0.0096  0.44\nQ32      0.79      0.79    0.78      0.35 3.8   0.0104 0.0166  0.33\n\n Item statistics \n      n raw.r std.r r.cor r.drop mean  sd\nQ4  988  0.70  0.70  0.64   0.58  2.8 1.2\nQ8  988  0.77  0.77  0.76   0.67  2.5 1.2\nQ12 988  0.70  0.70  0.64   0.58  3.0 1.2\nQ16 988  0.65  0.65  0.57   0.52  2.9 1.2\nQ20 988  0.75  0.75  0.73   0.65  2.1 1.1\nQ24 988  0.55  0.56  0.45   0.41  2.4 1.1\nQ28 988  0.49  0.47  0.34   0.31  3.2 1.3\nQ32 988  0.74  0.73  0.69   0.63  2.8 1.2\n\nNon missing response frequency for each item\n       1    2    3    4    5 miss\nQ4  0.14 0.28 0.29 0.21 0.08    0\nQ8  0.23 0.31 0.22 0.19 0.06    0\nQ12 0.14 0.23 0.27 0.26 0.10    0\nQ16 0.14 0.28 0.25 0.24 0.09    0\nQ20 0.37 0.34 0.16 0.10 0.03    0\nQ24 0.21 0.36 0.25 0.12 0.06    0\nQ28 0.13 0.18 0.22 0.28 0.19    0\nQ32 0.18 0.22 0.29 0.23 0.09    0\n\n\nCódigo\n# Para toda la escala \npsych::alpha(data %&gt;% select(1:32))\n\n\n\nReliability analysis   \nCall: psych::alpha(x = data %&gt;% select(1:32))\n\n  raw_alpha std.alpha G6(smc) average_r S/N    ase mean  sd median_r\n      0.86      0.87     0.9      0.17 6.4 0.0063  3.2 0.5     0.14\n\n    95% confidence boundaries \n         lower alpha upper\nFeldt     0.85  0.86  0.87\nDuhachek  0.85  0.86  0.87\n\n Reliability if an item is dropped:\n    raw_alpha std.alpha G6(smc) average_r S/N alpha se var.r med.r\nQ1       0.86      0.86     0.9      0.17 6.1   0.0066 0.019  0.14\nQ2       0.86      0.86     0.9      0.17 6.2   0.0065 0.019  0.14\nQ3       0.86      0.86     0.9      0.17 6.2   0.0066 0.020  0.13\nQ4       0.86      0.86     0.9      0.17 6.3   0.0065 0.019  0.15\nQ5       0.86      0.86     0.9      0.16 6.1   0.0066 0.019  0.13\nQ6       0.86      0.86     0.9      0.17 6.2   0.0065 0.019  0.14\nQ7       0.86      0.87     0.9      0.17 6.4   0.0063 0.019  0.15\nQ8       0.86      0.86     0.9      0.17 6.2   0.0065 0.019  0.14\nQ9       0.86      0.86     0.9      0.17 6.2   0.0065 0.020  0.13\nQ10      0.86      0.86     0.9      0.17 6.1   0.0066 0.019  0.13\nQ11      0.86      0.87     0.9      0.17 6.4   0.0063 0.019  0.15\nQ12      0.86      0.86     0.9      0.17 6.2   0.0065 0.019  0.14\nQ13      0.86      0.86     0.9      0.17 6.1   0.0065 0.019  0.14\nQ14      0.86      0.86     0.9      0.16 6.1   0.0066 0.019  0.13\nQ15      0.86      0.86     0.9      0.17 6.3   0.0065 0.019  0.14\nQ16      0.86      0.86     0.9      0.17 6.2   0.0065 0.019  0.14\nQ17      0.86      0.86     0.9      0.16 6.1   0.0066 0.018  0.13\nQ18      0.86      0.86     0.9      0.17 6.2   0.0065 0.019  0.14\nQ19      0.86      0.86     0.9      0.16 6.1   0.0066 0.020  0.13\nQ20      0.86      0.86     0.9      0.17 6.2   0.0065 0.018  0.14\nQ21      0.86      0.86     0.9      0.17 6.2   0.0065 0.018  0.13\nQ22      0.86      0.86     0.9      0.17 6.3   0.0064 0.020  0.14\nQ23      0.86      0.86     0.9      0.17 6.3   0.0064 0.019  0.15\nQ24      0.86      0.87     0.9      0.17 6.5   0.0063 0.018  0.15\nQ25      0.86      0.86     0.9      0.17 6.2   0.0065 0.018  0.14\nQ26      0.86      0.86     0.9      0.16 6.1   0.0066 0.019  0.13\nQ27      0.86      0.86     0.9      0.17 6.4   0.0064 0.019  0.15\nQ28      0.86      0.86     0.9      0.17 6.2   0.0065 0.020  0.13\nQ29      0.86      0.86     0.9      0.17 6.3   0.0064 0.019  0.14\nQ30      0.86      0.87     0.9      0.17 6.4   0.0063 0.019  0.15\nQ31      0.86      0.86     0.9      0.17 6.3   0.0064 0.019  0.15\nQ32      0.86      0.86     0.9      0.17 6.2   0.0066 0.019  0.13\n\n Item statistics \n      n raw.r std.r r.cor r.drop mean   sd\nQ1  988  0.49  0.51  0.49   0.44  4.0 1.06\nQ2  988  0.47  0.47  0.45   0.41  3.3 1.09\nQ3  988  0.49  0.48  0.45   0.43  3.1 1.16\nQ4  988  0.43  0.42  0.39   0.36  2.8 1.16\nQ5  988  0.52  0.53  0.52   0.47  3.6 1.03\nQ6  988  0.45  0.48  0.45   0.41  4.2 0.94\nQ7  988  0.30  0.28  0.24   0.23  2.7 1.09\nQ8  988  0.49  0.48  0.47   0.43  2.5 1.19\nQ9  988  0.44  0.45  0.42   0.38  3.4 1.21\nQ10 988  0.51  0.51  0.50   0.45  2.9 1.18\nQ11 988  0.31  0.29  0.25   0.24  2.7 1.24\nQ12 988  0.45  0.45  0.43   0.39  3.0 1.21\nQ13 988  0.48  0.51  0.50   0.44  4.5 0.84\nQ14 988  0.52  0.53  0.52   0.46  3.3 1.24\nQ15 988  0.44  0.41  0.39   0.36  2.6 1.34\nQ16 988  0.45  0.44  0.42   0.39  2.9 1.19\nQ17 988  0.54  0.56  0.56   0.49  4.1 1.10\nQ18 988  0.45  0.45  0.44   0.39  2.8 1.17\nQ19 988  0.54  0.54  0.52   0.49  3.2 1.23\nQ20 988  0.45  0.44  0.43   0.40  2.1 1.09\nQ21 988  0.46  0.49  0.48   0.42  4.4 0.85\nQ22 988  0.38  0.38  0.34   0.31  3.0 1.19\nQ23 988  0.37  0.36  0.32   0.30  3.2 1.18\nQ24 988  0.23  0.22  0.18   0.16  2.4 1.12\nQ25 988  0.46  0.49  0.48   0.42  4.4 0.84\nQ26 988  0.52  0.52  0.51   0.46  3.6 1.13\nQ27 988  0.35  0.33  0.29   0.28  2.3 1.27\nQ28 988  0.49  0.48  0.45   0.42  3.2 1.30\nQ29 988  0.38  0.39  0.36   0.31  3.7 1.18\nQ30 988  0.29  0.30  0.26   0.22  4.0 1.05\nQ31 988  0.40  0.38  0.36   0.33  3.2 1.28\nQ32 988  0.50  0.49  0.47   0.44  2.8 1.22\n\nNon missing response frequency for each item\n       1    2    3    4    5 miss\nQ1  0.03 0.08 0.16 0.35 0.37    0\nQ2  0.06 0.16 0.30 0.33 0.15    0\nQ3  0.10 0.21 0.30 0.27 0.11    0\nQ4  0.14 0.28 0.29 0.21 0.08    0\nQ5  0.04 0.10 0.27 0.38 0.20    0\nQ6  0.01 0.05 0.13 0.35 0.45    0\nQ7  0.13 0.33 0.32 0.16 0.07    0\nQ8  0.23 0.31 0.22 0.19 0.06    0\nQ9  0.09 0.16 0.20 0.37 0.18    0\nQ10 0.14 0.25 0.29 0.23 0.09    0\nQ11 0.17 0.32 0.19 0.22 0.09    0\nQ12 0.14 0.23 0.27 0.26 0.10    0\nQ13 0.01 0.03 0.07 0.27 0.62    0\nQ14 0.09 0.19 0.25 0.27 0.20    0\nQ15 0.30 0.22 0.20 0.19 0.10    0\nQ16 0.14 0.28 0.25 0.24 0.09    0\nQ17 0.04 0.07 0.14 0.30 0.45    0\nQ18 0.16 0.28 0.28 0.21 0.07    0\nQ19 0.10 0.19 0.24 0.30 0.17    0\nQ20 0.37 0.34 0.16 0.10 0.03    0\nQ21 0.01 0.03 0.09 0.29 0.58    0\nQ22 0.12 0.26 0.27 0.24 0.11    0\nQ23 0.09 0.21 0.28 0.28 0.15    0\nQ24 0.21 0.36 0.25 0.12 0.06    0\nQ25 0.01 0.03 0.06 0.29 0.60    0\nQ26 0.06 0.12 0.26 0.35 0.22    0\nQ27 0.36 0.28 0.15 0.13 0.07    0\nQ28 0.13 0.18 0.22 0.28 0.19    0\nQ29 0.06 0.11 0.20 0.34 0.28    0\nQ30 0.02 0.09 0.16 0.35 0.39    0\nQ31 0.10 0.22 0.24 0.22 0.20    0\nQ32 0.18 0.22 0.29 0.23 0.09    0\n\n\n\n\nAlfa Ordinal\nComo se señaló, el alfa de Chronbach está diseñado para variables continuas. Por ello, podemos calcular el alfa ordinal para las puntuaciones de cada ítem. Para esto, utilizaremos la función ordinal_alpha()de jogRu, que estima el alfa ordinal a partir de correlación policórica (según lo propuesto por Zumbo et al.(2007)).\n\n\nCódigo\njogRu::ordinal_alpha(afiliativo)\n\n\n\nReliability analysis   \nCall: psych::alpha(x = psych::polychoric(x)$rho)\n\n  raw_alpha std.alpha G6(smc) average_r S/N median_r\n      0.89      0.89    0.89       0.5   8     0.49\n\n    95% confidence boundaries \n      lower alpha upper\nFeldt  0.71  0.89  0.97\n\n Reliability if an item is dropped:\n    raw_alpha std.alpha G6(smc) average_r S/N  var.r med.r\nQ1       0.87      0.87    0.87      0.49 6.8 0.0120  0.47\nQ5       0.88      0.88    0.87      0.50 7.0 0.0133  0.49\nQ9       0.89      0.89    0.89      0.53 7.9 0.0090  0.55\nQ13      0.87      0.87    0.87      0.50 6.9 0.0085  0.49\nQ17      0.86      0.86    0.86      0.48 6.3 0.0100  0.45\nQ21      0.87      0.87    0.87      0.49 6.7 0.0104  0.47\nQ25      0.87      0.87    0.86      0.48 6.5 0.0086  0.49\nQ29      0.88      0.88    0.88      0.52 7.7 0.0106  0.55\n\n Item statistics \n       r r.cor r.drop\nQ1  0.77  0.72   0.68\nQ5  0.74  0.69   0.65\nQ9  0.63  0.55   0.52\nQ13 0.76  0.73   0.67\nQ17 0.83  0.81   0.77\nQ21 0.79  0.76   0.71\nQ25 0.81  0.79   0.73\nQ29 0.67  0.60   0.56\n\n\nCódigo\njogRu::ordinal_alpha(autofortalecedor)\n\n\n\nReliability analysis   \nCall: psych::alpha(x = psych::polychoric(x)$rho)\n\n  raw_alpha std.alpha G6(smc) average_r S/N median_r\n      0.85      0.85    0.85      0.41 5.5     0.37\n\n    95% confidence boundaries \n      lower alpha upper\nFeldt   0.6  0.85  0.96\n\n Reliability if an item is dropped:\n    raw_alpha std.alpha G6(smc) average_r S/N var.r med.r\nQ2       0.83      0.83    0.83      0.40 4.7 0.019  0.37\nQ6       0.84      0.84    0.83      0.42 5.1 0.016  0.37\nQ10      0.82      0.82    0.81      0.39 4.4 0.014  0.37\nQ14      0.81      0.81    0.82      0.38 4.4 0.018  0.34\nQ18      0.82      0.82    0.81      0.39 4.5 0.014  0.37\nQ22      0.85      0.85    0.85      0.45 5.6 0.013  0.45\nQ26      0.82      0.82    0.82      0.39 4.4 0.016  0.37\nQ30      0.84      0.84    0.84      0.43 5.3 0.016  0.43\n\n Item statistics \n       r r.cor r.drop\nQ2  0.71  0.65   0.60\nQ6  0.64  0.57   0.51\nQ10 0.77  0.74   0.67\nQ14 0.77  0.74   0.68\nQ18 0.75  0.72   0.65\nQ22 0.54  0.43   0.40\nQ26 0.76  0.73   0.67\nQ30 0.61  0.53   0.47\n\n\nCódigo\njogRu::ordinal_alpha(agresivo)\n\n\n\nReliability analysis   \nCall: psych::alpha(x = psych::polychoric(x)$rho)\n\n  raw_alpha std.alpha G6(smc) average_r S/N median_r\n      0.82      0.82    0.81      0.36 4.5     0.35\n\n    95% confidence boundaries \n      lower alpha upper\nFeldt  0.53  0.82  0.96\n\n Reliability if an item is dropped:\n    raw_alpha std.alpha G6(smc) average_r S/N  var.r med.r\nQ3       0.80      0.80    0.78      0.36 3.9 0.0078  0.35\nQ7       0.80      0.80    0.79      0.36 4.0 0.0068  0.37\nQ11      0.80      0.80    0.79      0.37 4.0 0.0067  0.37\nQ15      0.78      0.78    0.77      0.34 3.6 0.0051  0.34\nQ19      0.81      0.81    0.79      0.37 4.1 0.0065  0.37\nQ23      0.81      0.81    0.79      0.37 4.1 0.0040  0.36\nQ27      0.80      0.80    0.79      0.36 4.0 0.0076  0.37\nQ31      0.78      0.78    0.77      0.34 3.6 0.0062  0.34\n\n Item statistics \n       r r.cor r.drop\nQ3  0.67  0.60   0.54\nQ7  0.65  0.58   0.52\nQ11 0.63  0.55   0.49\nQ15 0.74  0.71   0.64\nQ19 0.61  0.52   0.47\nQ23 0.61  0.53   0.47\nQ27 0.65  0.57   0.52\nQ31 0.74  0.70   0.63\n\n\nCódigo\njogRu::ordinal_alpha(autodestructivo)\n\n\n\nReliability analysis   \nCall: psych::alpha(x = psych::polychoric(x)$rho)\n\n  raw_alpha std.alpha G6(smc) average_r S/N median_r\n      0.85      0.85    0.85      0.41 5.6     0.45\n\n    95% confidence boundaries \n      lower alpha upper\nFeldt  0.61  0.85  0.96\n\n Reliability if an item is dropped:\n    raw_alpha std.alpha G6(smc) average_r S/N var.r med.r\nQ4       0.83      0.83    0.82      0.40 4.8 0.022  0.42\nQ8       0.81      0.81    0.80      0.38 4.4 0.015  0.42\nQ12      0.83      0.83    0.82      0.40 4.8 0.022  0.42\nQ16      0.83      0.83    0.83      0.42 5.0 0.020  0.44\nQ20      0.81      0.81    0.80      0.39 4.4 0.015  0.42\nQ24      0.85      0.85    0.84      0.44 5.5 0.019  0.50\nQ28      0.86      0.86    0.85      0.47 6.2 0.011  0.50\nQ32      0.82      0.82    0.82      0.39 4.6 0.021  0.37\n\n Item statistics \n       r r.cor r.drop\nQ4  0.73  0.68   0.62\nQ8  0.80  0.80   0.73\nQ12 0.73  0.68   0.63\nQ16 0.68  0.61   0.56\nQ20 0.80  0.79   0.72\nQ24 0.59  0.49   0.45\nQ28 0.49  0.36   0.33\nQ32 0.77  0.73   0.67\n\n\nCódigo\n# Para toda la escala \njogRu::ordinal_alpha(data %&gt;% select(1:32))\n\n\n\nReliability analysis   \nCall: psych::alpha(x = psych::polychoric(x)$rho)\n\n  raw_alpha std.alpha G6(smc) average_r S/N median_r\n      0.88      0.88    0.93      0.19 7.7     0.16\n\n    95% confidence boundaries \n      lower alpha upper\nFeldt  0.82  0.88  0.94\n\n Reliability if an item is dropped:\n    raw_alpha std.alpha G6(smc) average_r S/N var.r med.r\nQ1       0.88      0.88    0.92      0.19 7.3 0.025  0.16\nQ2       0.88      0.88    0.92      0.19 7.4 0.026  0.16\nQ3       0.88      0.88    0.92      0.19 7.4 0.027  0.16\nQ4       0.88      0.88    0.92      0.19 7.5 0.026  0.17\nQ5       0.88      0.88    0.92      0.19 7.3 0.026  0.16\nQ6       0.88      0.88    0.92      0.19 7.3 0.026  0.16\nQ7       0.89      0.89    0.93      0.20 7.7 0.025  0.17\nQ8       0.88      0.88    0.92      0.19 7.4 0.025  0.16\nQ9       0.88      0.88    0.92      0.19 7.4 0.026  0.16\nQ10      0.88      0.88    0.92      0.19 7.3 0.026  0.16\nQ11      0.88      0.88    0.93      0.20 7.7 0.026  0.17\nQ12      0.88      0.88    0.92      0.19 7.4 0.026  0.16\nQ13      0.88      0.88    0.92      0.19 7.2 0.025  0.16\nQ14      0.88      0.88    0.92      0.19 7.3 0.025  0.16\nQ15      0.88      0.88    0.92      0.19 7.5 0.026  0.17\nQ16      0.88      0.88    0.92      0.19 7.4 0.026  0.16\nQ17      0.88      0.88    0.92      0.19 7.2 0.025  0.16\nQ18      0.88      0.88    0.92      0.19 7.4 0.026  0.16\nQ19      0.88      0.88    0.92      0.19 7.3 0.027  0.15\nQ20      0.88      0.88    0.92      0.19 7.4 0.025  0.17\nQ21      0.88      0.88    0.92      0.19 7.3 0.025  0.16\nQ22      0.88      0.88    0.93      0.20 7.5 0.027  0.17\nQ23      0.88      0.88    0.92      0.20 7.6 0.026  0.17\nQ24      0.89      0.89    0.93      0.20 7.8 0.025  0.17\nQ25      0.88      0.88    0.92      0.19 7.3 0.024  0.16\nQ26      0.88      0.88    0.92      0.19 7.3 0.026  0.16\nQ27      0.88      0.88    0.93      0.20 7.6 0.026  0.17\nQ28      0.88      0.88    0.92      0.19 7.4 0.027  0.16\nQ29      0.88      0.88    0.92      0.19 7.5 0.025  0.16\nQ30      0.88      0.88    0.92      0.20 7.6 0.026  0.17\nQ31      0.88      0.88    0.92      0.20 7.5 0.026  0.17\nQ32      0.88      0.88    0.92      0.19 7.4 0.026  0.16\n\n Item statistics \n       r r.cor r.drop\nQ1  0.56  0.55   0.51\nQ2  0.49  0.47   0.44\nQ3  0.51  0.49   0.46\nQ4  0.43  0.41   0.38\nQ5  0.56  0.55   0.51\nQ6  0.52  0.51   0.47\nQ7  0.29  0.25   0.22\nQ8  0.50  0.49   0.45\nQ9  0.48  0.45   0.43\nQ10 0.53  0.52   0.48\nQ11 0.31  0.28   0.25\nQ12 0.46  0.44   0.41\nQ13 0.58  0.58   0.53\nQ14 0.56  0.55   0.51\nQ15 0.43  0.41   0.37\nQ16 0.46  0.44   0.40\nQ17 0.62  0.62   0.58\nQ18 0.47  0.46   0.42\nQ19 0.57  0.55   0.52\nQ20 0.46  0.45   0.40\nQ21 0.56  0.56   0.51\nQ22 0.39  0.36   0.33\nQ23 0.37  0.34   0.31\nQ24 0.22  0.19   0.16\nQ25 0.57  0.58   0.53\nQ26 0.55  0.54   0.50\nQ27 0.34  0.31   0.28\nQ28 0.50  0.47   0.45\nQ29 0.42  0.39   0.36\nQ30 0.32  0.29   0.26\nQ31 0.40  0.38   0.34\nQ32 0.51  0.50   0.46"
  },
  {
    "objectID": "practicos/index.html",
    "href": "practicos/index.html",
    "title": "Actividades en R",
    "section": "",
    "text": "En construcción"
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Programa",
    "section": "",
    "text": "Kevin Carrasco\n   ?var:instructor.office\n   kevin.carrasco@ug.uchile.cl\n   kevincarrascoq1\n\n\n\n\n\n   Martes\n   Marzo 12 - Julio 15 2024\n   16:00 a 17:20 y 17:30 a 18:50\n   Sala E67"
  },
  {
    "objectID": "syllabus.html#propósito-general-del-curso",
    "href": "syllabus.html#propósito-general-del-curso",
    "title": "Programa",
    "section": "Propósito general del curso",
    "text": "Propósito general del curso\nSe espera que al término del curso los y las estudiantes puedan elaborar y analizar diseños de investigación social de carácter cuantitativo, así como describir cuantitativamente un conjunto de datos utilizando el lenguaje R. En ese sentido, se profundizará el uso de R y la interfaz de RStudio para su uso en contextos académicos, así como el uso de otros sistemas de publicaciones como Quarto. Al mismo tiempo, el curso profundiza en temas relevantes para las ciencias sociales como el análisis estadístico, pero con un foco específico en la presentación de resultados (visualización de datos) a través de documentos dinámicos.\n\nObjetivos específicos\n\nConocer y aplicar instrumentos de medición y tipos de estudios cuantitativos.\nInterpretar y analizar los elementos centrales de una base de datos con información social.\nPresentar resultados a partir de la visualización de datos y construcción de documentos dinámicos en R (Quarto).\nAplicar, interpretar y visualizar técnicas de estadística descriptiva según las distintas características de los datos en R.\nAplicar e interpretar técnicas de estadística correlacional e inferencia estadística para muestras complejas en R.\nAplicar, interpretar y visualizar técnicas de regresión lineal y logística para variables numéricas y variables categóricas en R."
  },
  {
    "objectID": "syllabus.html#contenidos",
    "href": "syllabus.html#contenidos",
    "title": "Programa",
    "section": "Contenidos",
    "text": "Contenidos\n\nUnidad 1: Elementos y herramientas de R\n1.1 R enviroment: interfaz de RStudio, elementos de script, workspace\n1.2 Herramientas para la colaboración y comunicación: Rproject, GitHub, Zotero y Slack\n1.3 Protocolo IPO para la reproducibilidad de investigaciones sociales\n1.4 Construcción de reportes automáticos, reproducibles e integrados con código: Quarto\n\n\nUnidad 2: Operacionalización y análisis descriptivo de datos\n2.1 Operacionalización y niveles de medición\n2.2 Tidy data: unir, dividir, filtrar, ordenar y exportar datos en R\n2.3 Recodificación de variables: descriptivos básicos, casos perdidos, etiquetamiento de variables\n2.4 Agrupación de datos y construcción de variables a partir de datos existentes\n2.5 Tablas descriptivas y tablas de contingencia\n2.6 ggplot2: gráficos de barra, de caja, dispersión e histograma\n\n\nUnidad 3: Análisis estadístico inferencial en R\n3.1 Análisis bivariado: Correlación de Pearson y ANOVA\n3.2 Muestras complejas e inferencia estadística con survey y srvyr\n\n\nUnidad 4: Regresión lineal y regresión logística\n4.2 Regresiones lineales de mínimos cuadrados ordinarios\n4.3 Interpretación de coeficientes (variables cuantitativas y cualitativas)\n4.4 Aspectos básicos de regresión logística\n4.5 Representación gráfica de coeficientes de regresión lineal y logística (probabilidades predichas)"
  },
  {
    "objectID": "syllabus.html#metodología",
    "href": "syllabus.html#metodología",
    "title": "Programa",
    "section": "Metodología",
    "text": "Metodología\nSe tendrán tres espacios principales de aprendizaje:\n\nSesiones de clases lectivas, donde se presentarán los aspectos centrales de los contenidos correspondientes a la semana. Estas se desarrollarán en el primer bloque del martes.\nPrácticas guiadas: cada tema de las sesiones se acompaña de una guía práctica de aplicación de contenidos. Estas guías están diseñadas para ser desarrolladas de manera autónoma por cada estudiante semana a semana. También serán desarrolladas y revisadas cada semana por el profesor y/o ayudantes para dar mayor oportunidad de participación y resolver las dudas respectivas. Estas se desarrollan en el segundo bloque del martes.\nEvaluaciones: se desarrollarán trabajos periódicos que permitirán a las/os estudiantes aplicar contenidos y replicar lo aprendido en los prácticos en base a una base de datos seleccionada por ellas/os a inicio de semestre. Esto permitirá no solo recibir retroalimentación constante, sino que aprender con datos que puedan ser útiles para otros proyectos de investigación. Al finalizar el curso, el/la estudiante deberá entregar un proyecto de investigación que incluya todo el trabajo de estas tareas, así como la incorporación de comentarios y sugerencias de retroalimentación de las evaluaciones. Además, el/la estudiante deberá realizar una presentación de resultados en formato académico/conferencia.\n\nLas instrucciones de las tareas serán publicadas con una semana de anticipación a su entrega."
  },
  {
    "objectID": "syllabus.html#recursos-principales-de-aprendizaje-y-comunicación",
    "href": "syllabus.html#recursos-principales-de-aprendizaje-y-comunicación",
    "title": "Programa",
    "section": "Recursos principales de aprendizaje y comunicación",
    "text": "Recursos principales de aprendizaje y comunicación\n\nSitio web\n\nEl curso estará disponible en un sitio web programado por el docente, en tanto permite integrar texto y código de R.\n\nR, RStudio y RStudio Cloud\n\nEl software que se utilizará principalmente será R y su interfaz RStudio. Ahora bien, muchos usuario/as de R presentan problemas de instalación dada la capacidad de sus computadores y sistemas operativos. Por ello, para quienes tengan estos problemas se promoverá el uso del servicio gratuito de RStudio.cloud\n\nSlack\n\nSlack es una herramienta de uso frecuente en equipos de trabajo que utilizan R pues permite integrar script de distintos lenguajes en el chat. Se tendrá un espacio de trabajo en la app Slack que permite que cualquier persona del curso pueda hacer preguntas y cualquiera pueda responder. Esta es una de las prácticas que se promoverán en el curso pues es probable que los/as estudiantes tengan dudas similares a las de sus compañeros, por lo que las respuestas del docente, ayudantes y otros compañeros/as serán de libre disposición de todo el curso. Dentro de Slack se tendrán canales específicos para hacer preguntas sobre las sesiones, tareas y proyectos, y el link que permite unirse a este estará disponible en el sitio del curso.\n\nGitHub\n\nGithub es una plataforma online que permite depositar archivos y el control de versiones (VCS), por lo que se ha transformado en una herramienta fácil y popular para corregir, colaborar y compartir códigos de distintos lenguajes (no solo R). Utilizaremos esta plataforma para subir las tareas, ayudarlos/as de manera directa con su código y darles feedback."
  },
  {
    "objectID": "syllabus.html#evaluación-de-aprendizaje",
    "href": "syllabus.html#evaluación-de-aprendizaje",
    "title": "Programa",
    "section": "Evaluación de aprendizaje",
    "text": "Evaluación de aprendizaje\nLas evaluaciones del curso se componen de tareas (60% de la nota final), la entrega de una investigación (30% de la nota final) y una presentación (10% de la nota final), en dónde en todos los casos la/el estudiante deberá seleccionar datos y temas de interés de modo de acercar la aplicación del software a contextos de investigación propios de la/el estudiante. En concreto, cada evaluación consiste en:\n\nTrabajos (60% de la nota final): consisten en evaluaciones parciales temáticas que buscan poner en práctica los aprendizajes expuestos en la sesión de clases y herramientas reforzadas en los prácticos. Durante el semestre se realizarán 4 tareas (15% c/u).\nPresentación final (10% de la nota final): Consiste en una presentación final individual que resuma el trabajo realizado en el proyecto de investigación. Al tratarse de un curso metodológico, más que los fundamentos teóricos de la investigación, el foco de la presentación debe estar centrado en los resultados de la investigación (visualización de resultados) y en reflexiones de toma de decisiones metodológicas en términos de apertura y reproducibilidad.\nInvestigación final (examen) (30% de la nota final): consiste en una evaluación final individual que aplica los conocimientos y herramientas entregadas a lo largo del curso y en las tareas realizadas, a un proyecto de investigación de elección por el/la estudiante. Se espera que este proyecto incluya todo el trabajo de estas tareas, así como la incorporación de comentarios y sugerencias de retroalimentación de las evaluaciones."
  },
  {
    "objectID": "syllabus.html#información-general",
    "href": "syllabus.html#información-general",
    "title": "Programa",
    "section": "Información general",
    "text": "Información general\nLos/as alumnas/os que no se presenten o entreguen una evaluación por enfermedad deben hacer llegar el certificado médico a coordinación en el plazo establecido por el reglamento. Quienes no lo hagan serán evaluados con nota 1,0. Las pruebas atrasadas serán reprogramadas la primera semana de junio.\nNingún curso podrá ser aprobado si no cuenta con el mínimo del 70% de asistencia. Tendrán derecho a rendir los exámenes todos los/as estudiantes que hayan cumplido con la exigencia de asistencia mínima al curso y cuyo promedio de notas sea igual o superior a 3,5.\nLos/as estudiantes podrán eximirse de la obligación de rendir los exámenes finales de cada curso. Al iniciarse el semestre académico, cada profesor/a deberá indicar a los/as estudiantes en el programa del curso si existe la posibilidad de eximirse y bajo qué condiciones. Con todo, no será posible eximirse de examen alguno si el/a estudiante no tiene una nota promedio igual o superior a 5,5 y una asistencia igual o superior al 70% de las clases efectivamente realizadas en el respectivo curso."
  },
  {
    "objectID": "syllabus.html#reglamento-académico-del-estudiante-de-pregrado.",
    "href": "syllabus.html#reglamento-académico-del-estudiante-de-pregrado.",
    "title": "Programa",
    "section": "Reglamento Académico del Estudiante de Pregrado.",
    "text": "Reglamento Académico del Estudiante de Pregrado.\nArt. 23.- Cualquier conducta de un estudiante que tienda a viciar la evaluación de actividades académicas o que constituya fraude académico, figura que contempla irregularidades tales como copia, suplantación o alteración de evaluaciones, plagio, faltas a la ética profesional, sin que esta enumeración sea taxativa, dará origen a las siguientes sanciones, según la gravedad de la falta cometida: (i) nota mínima 1,0 (uno) en la respectiva evaluación; (ii) reprobación del curso respectivo; (iii) amonestación; (iv) permanencia condicional; (v) suspensión de actividades académicas por un período académico; (vi) expulsión de la Universidad.\nAsimismo, toda actividad de un estudiante que entorpezca gravemente y/o dificulte el normal desarrollo académico, podrá ser sancionada de conformidad a las disposiciones establecidas en el Reglamento de Conducta y Convivencia de la Universidad Alberto Hurtado.\nArt. 24.- Las dos primeras sanciones previstas en el artículo anterior, a saber (i) Nota mínima 1,0; y (ii) Reprobación del Curso respectivo, son prerrogativa del docente a cargo de la asignatura, quien deberá informarlas a la Dirección de la Carrera.\n***Para evitar el plagio todo trabajo, composición o material documental que los estudiantes realicen debe citar adecuadamente las fuentes utilizadas, ya sea a través del sistema APA (American Psychological Association) http://www.apastyle.org o MLA (Modern Language Association) http://www.mla.org/."
  }
]